import streamlit as st
import pandas as pd
import numpy as np
import re
import logging
from collections import Counter, defaultdict
from functools import lru_cache
import hashlib
import io
import warnings
import time
warnings.filterwarnings('ignore')

def normalize_spaces(text):
    """ç»Ÿä¸€å¤„ç†å„ç§ç©ºæ ¼å­—ç¬¦"""
    if not isinstance(text, str):
        text = str(text)
    
    # å¤„ç†æ™®é€šç©ºæ ¼ã€å…¨è§’ç©ºæ ¼ã€å¤šä¸ªè¿ç»­ç©ºæ ¼
    text = text.replace(' ', ' ')  # å…¨è§’ç©ºæ ¼è½¬åŠè§’
    text = text.replace('ã€€', ' ')  # å…¨è§’ç©ºæ ¼è½¬åŠè§’
    text = ' '.join(text.split())  # åˆå¹¶å¤šä¸ªè¿ç»­ç©ºæ ¼ä¸ºå•ä¸ªç©ºæ ¼
    return text.strip()

# è®¾ç½®é¡µé¢
st.set_page_config(
    page_title="æ™ºèƒ½å½©ç¥¨åˆ†ææ£€æµ‹ç³»ç»Ÿ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== é…ç½®å¸¸é‡ ====================
LOTTERY_CONFIGS = {
    'PK10': {
        'lotteries': [
            'åˆ†åˆ†PKæ‹¾', 'ä¸‰åˆ†PKæ‹¾', 'äº”åˆ†PKæ‹¾', 'æ–°å¹¸è¿é£è‰‡', 'æ¾³æ´²å¹¸è¿10',
            'ä¸€åˆ†PK10', 'å®¾æœPK10', 'æé€Ÿé£è‰‡', 'æ¾³æ´²é£è‰‡', 'å¹¸è¿èµ›è½¦',
            'åˆ†åˆ†èµ›è½¦', 'åŒ—äº¬PK10', 'æ—§åŒ—äº¬PK10', 'æé€Ÿèµ›è½¦', 'å¹¸è¿èµ›è»Š', 
            'åŒ—äº¬èµ›è½¦', 'æé€ŸPK10', 'å¹¸è¿PK10', 'èµ›è½¦', 'èµ›è»Š'
        ],
        'min_number': 1,
        'max_number': 10,
        'gyh_min': 3,
        'gyh_max': 19,
        'position_names': ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                          'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
    },
    'K3': {
        'lotteries': [
            'åˆ†åˆ†å¿«ä¸‰', 'ä¸‰åˆ†å¿«3', 'äº”åˆ†å¿«3', 'æ¾³æ´²å¿«ä¸‰', 'å®¾æœå¿«ä¸‰',
            '1åˆ†å¿«ä¸‰', '3åˆ†å¿«ä¸‰', '5åˆ†å¿«ä¸‰', '10åˆ†å¿«ä¸‰', 'åŠ å·å¿«ä¸‰',
            'å¹¸è¿å¿«ä¸‰', 'å¤§å‘å¿«ä¸‰', 'å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰', 
            'æ¾³é—¨å¿«ä¸‰', 'é¦™æ¸¯å¿«ä¸‰', 'æ±Ÿè‹å¿«ä¸‰'
        ],
        'min_number': 1,
        'max_number': 6,
        'hezhi_min': 3,
        'hezhi_max': 18
    },
    'LHC': {
        'lotteries': [
            'æ–°æ¾³é—¨å…­åˆå½©', 'æ¾³é—¨å…­åˆå½©', 'é¦™æ¸¯å…­åˆå½©', 'ä¸€åˆ†å…­åˆå½©',
            'äº”åˆ†å…­åˆå½©', 'ä¸‰åˆ†å…­åˆå½©', 'é¦™æ¸¯â‘¥åˆå½©', 'åˆ†åˆ†å…­åˆå½©',
            'å¿«ä¹6åˆå½©', 'æ¸¯â‘¥åˆå½©', 'å°æ¹¾å¤§ä¹é€', 'å…­åˆ', 'lhc', 'å…­åˆå½©',
            'â‘¥åˆ', '6åˆ', 'å¤§å‘å…­åˆå½©'
        ],
        'min_number': 1,
        'max_number': 49
    },
    '3D': {
        'lotteries': [
            'æ’åˆ—ä¸‰', 'æ’åˆ—3', 'å¹¸è¿æ’åˆ—3', 'ä¸€åˆ†æ’åˆ—3', 'äºŒåˆ†æ’åˆ—3', 'ä¸‰åˆ†æ’åˆ—3', 
            'äº”åˆ†æ’åˆ—3', 'ååˆ†æ’åˆ—3', 'å¤§å‘æ’åˆ—3', 'å¥½è¿æ’åˆ—3', 'ç¦å½©3D', 'æé€Ÿ3D',
            'æé€Ÿæ’åˆ—3', 'å¹¸è¿3D', 'ä¸€åˆ†3D', 'äºŒåˆ†3D', 'ä¸‰åˆ†3D', 'äº”åˆ†3D', 
            'ååˆ†3D', 'å¤§å‘3D', 'å¥½è¿3D'
        ],
        'min_number': 0,
        'max_number': 9,
        'dingwei_threshold': 7  # å®šä½èƒ†å¤šç é˜ˆå€¼
    },
    'SSC': {
        'lotteries': [
            'åˆ†åˆ†æ—¶æ—¶å½©', 'ä¸‰åˆ†æ—¶æ—¶å½©', 'äº”åˆ†æ—¶æ—¶å½©', 'å®¾æœæ—¶æ—¶å½©',
            '1åˆ†æ—¶æ—¶å½©', '3åˆ†æ—¶æ—¶å½©', '5åˆ†æ—¶æ—¶å½©', 'æ—§é‡åº†æ—¶æ—¶å½©',
            'å¹¸è¿æ—¶æ—¶å½©', 'è…¾è®¯åˆ†åˆ†å½©', 'æ–°ç–†æ—¶æ—¶å½©', 'å¤©æ´¥æ—¶æ—¶å½©',
            'é‡åº†æ—¶æ—¶å½©', 'ä¸Šæµ·æ—¶æ—¶å½©', 'å¹¿ä¸œæ—¶æ—¶å½©', 'åˆ†åˆ†å½©', 'æ—¶æ—¶å½©', 'æ™‚æ™‚å½©'
        ],
        'min_number': 0,
        'max_number': 9
    },
    'THREE_COLOR': {
        'lotteries': [
            'ä¸€åˆ†ä¸‰è‰²å½©', '30ç§’ä¸‰è‰²å½©', 'äº”åˆ†ä¸‰è‰²å½©', 'ä¸‰åˆ†ä¸‰è‰²å½©',
            'ä¸‰è‰²', 'ä¸‰è‰²å½©', 'ä¸‰è‰²çƒ'
        ],
        'min_number': 0,
        'max_number': 9
    }
}

THRESHOLD_CONFIG = {
    'PK10': {
        'multi_number': 8,
        'gyh_multi_number': 12,
        'position_multi': 8,
        'all_positions_bet': 10
    },
    'K3': {
        'multi_number': 5,
        'hezhi_multi_number': 13,
        'value_size_contradiction': 5,
        'dudan_multi_number': 5
    },
    'LHC': {
        'number_play': 31,
        'zodiac_play': 7,
        'tail_play': 7,
        'range_bet': 4,
        'lianxiao_threshold': 7,
        'lianwei_threshold': 7,
        'wave_bet': 3,
        'five_elements': 4
    },
    '3D': {
        'dingwei_multi': 7,  # å®šä½èƒ†å¤šç é˜ˆå€¼
        'two_sides_conflict': 2  # ä¸¤é¢çŸ›ç›¾æ£€æµ‹
    },
    'SSC': {
        'dingwei_multi': 8,
        'douniu_multi': 8,
        'two_sides_conflict': 2
    },
    'THREE_COLOR': {
        'zhengma_multi': 7,
        'two_sides_conflict': 2,
        'wave_conflict': 2
    }
}

# ==================== æ—¥å¿—è®¾ç½® ====================
def setup_logging():
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    logger = logging.getLogger('LotteryAnalysis')
    logger.setLevel(logging.INFO)
    
    if not logger.handlers:
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # æ ¼å¼å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        console_handler.setFormatter(formatter)
        
        logger.addHandler(console_handler)
    
    return logger

logger = setup_logging()

# ==================== æ•°æ®å¤„ç†ç±» ====================
class DataProcessor:
    def __init__(self):
        self.required_columns = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'ç©æ³•', 'å†…å®¹', 'é‡‘é¢']
        self.column_mapping = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·', 'ç©å®¶è´¦å·', 'ç”¨æˆ·ID', 'ç©å®¶ID'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹', 'å½©ç¥¨ç±»å‹', 'æ¸¸æˆå½©ç§', 'å½©ç¥¨åç§°'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ', 'å¥–æœŸ', 'æœŸå·ä¿¡æ¯', 'æœŸå·ç¼–å·'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹', 'æŠ•æ³¨ç©æ³•', 'ç©æ³•ç±»å‹', 'åˆ†ç±»'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹', 'æŠ•æ³¨å·ç ', 'å·ç å†…å®¹', 'æŠ•æ³¨ä¿¡æ¯'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é‡‘é¢æ•°å€¼']
        }
    
    def smart_column_identification(self, df_columns):
        """æ™ºèƒ½åˆ—è¯†åˆ«"""
        identified_columns = {}
        actual_columns = [str(col).strip() for col in df_columns]
        
        with st.expander("ğŸ” åˆ—åè¯†åˆ«è¯¦æƒ…", expanded=False):
            st.info(f"æ£€æµ‹åˆ°çš„åˆ—å: {actual_columns}")
            
            for standard_col, possible_names in self.column_mapping.items():
                found = False
                for actual_col in actual_columns:
                    actual_col_lower = actual_col.lower().replace(' ', '').replace('_', '').replace('-', '')
                    
                    for possible_name in possible_names:
                        possible_name_lower = possible_name.lower().replace(' ', '').replace('_', '').replace('-', '')
                        
                        # å¢å¼ºä¼šå‘˜è´¦å·è¯†åˆ«
                        if standard_col == 'ä¼šå‘˜è´¦å·':
                            # æ›´å®½æ¾çš„åŒ¹é…è§„åˆ™
                            account_keywords = ['ä¼šå‘˜', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·', 'ç©å®¶', 'id']
                            if any(keyword in actual_col_lower for keyword in account_keywords):
                                identified_columns[actual_col] = standard_col
                                st.success(f"âœ… è¯†åˆ«åˆ—å: {actual_col} -> {standard_col}")
                                found = True
                                break
                        else:
                            # å…¶ä»–åˆ—çš„åŸæœ‰åŒ¹é…é€»è¾‘
                            if (possible_name_lower in actual_col_lower or 
                                actual_col_lower in possible_name_lower or
                                len(set(possible_name_lower) & set(actual_col_lower)) / len(possible_name_lower) > 0.7):
                                identified_columns[actual_col] = standard_col
                                st.success(f"âœ… è¯†åˆ«åˆ—å: {actual_col} -> {standard_col}")
                                found = True
                                break
                    
                    if found:
                        break
                
                if not found:
                    st.warning(f"âš ï¸ æœªè¯†åˆ«åˆ° {standard_col} å¯¹åº”çš„åˆ—å")
        
        return identified_columns
    
    def find_data_start(self, df):
        """æ™ºèƒ½æ‰¾åˆ°æ•°æ®èµ·å§‹ä½ç½®"""
        for row_idx in range(min(20, len(df))):
            for col_idx in range(min(10, len(df.columns))):
                cell_value = str(df.iloc[row_idx, col_idx])
                if pd.notna(cell_value) and any(keyword in cell_value for keyword in ['ä¼šå‘˜', 'è´¦å·', 'æœŸå·', 'å½©ç§', 'ç©æ³•', 'å†…å®¹', 'è®¢å•', 'ç”¨æˆ·']):
                    return row_idx, col_idx
        return 0, 0
    
    def validate_data_quality(self, df):
        """æ•°æ®è´¨é‡éªŒè¯"""
        logger.info("æ­£åœ¨è¿›è¡Œæ•°æ®è´¨é‡éªŒè¯...")
        issues = []
        
        # æ£€æŸ¥å¿…è¦åˆ—
        missing_cols = [col for col in self.required_columns if col not in df.columns]
        if missing_cols:
            issues.append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        
        # æ£€æŸ¥ç©ºå€¼
        for col in self.required_columns:
            if col in df.columns:
                null_count = df[col].isnull().sum()
                if null_count > 0:
                    issues.append(f"åˆ— '{col}' æœ‰ {null_count} ä¸ªç©ºå€¼")
        
        # ç‰¹åˆ«æ£€æŸ¥ä¼šå‘˜è´¦å·çš„å®Œæ•´æ€§
        if 'ä¼šå‘˜è´¦å·' in df.columns:
            # æ£€æŸ¥æ˜¯å¦æœ‰è¢«æˆªæ–­çš„è´¦å·
            truncated_accounts = df[df['ä¼šå‘˜è´¦å·'].str.contains(r'\.\.\.|â€¦', na=False)]
            if len(truncated_accounts) > 0:
                issues.append(f"å‘ç° {len(truncated_accounts)} ä¸ªå¯èƒ½è¢«æˆªæ–­çš„ä¼šå‘˜è´¦å·")
            
            # æ£€æŸ¥è´¦å·é•¿åº¦å¼‚å¸¸çš„æƒ…å†µ
            account_lengths = df['ä¼šå‘˜è´¦å·'].str.len()
            if account_lengths.max() > 50:  # å‡è®¾æ­£å¸¸è´¦å·é•¿åº¦ä¸è¶…è¿‡50ä¸ªå­—ç¬¦
                issues.append("å‘ç°å¼‚å¸¸é•¿åº¦çš„ä¼šå‘˜è´¦å·")
            
            # æ˜¾ç¤ºè´¦å·æ ¼å¼æ ·æœ¬
            unique_accounts = df['ä¼šå‘˜è´¦å·'].unique()[:5]
            sample_info = " | ".join([f"'{acc}'" for acc in unique_accounts])
            st.info(f"ä¼šå‘˜è´¦å·æ ¼å¼æ ·æœ¬: {sample_info}")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        if 'æœŸå·' in df.columns:
            # ç¡®ä¿æœŸå·ä¸ºå­—ç¬¦ä¸²ç±»å‹
            df['æœŸå·'] = df['æœŸå·'].astype(str)
            # ä¿®å¤æœŸå·æ ¼å¼é—®é¢˜ï¼šå»æ‰.0
            df['æœŸå·'] = df['æœŸå·'].str.replace(r'\.0$', '', regex=True)
            # å…è®¸æœŸå·åŒ…å«å­—æ¯å’Œæ•°å­—
            invalid_periods = df[~df['æœŸå·'].str.match(r'^[\dA-Za-z]+$', na=True)]
            if len(invalid_periods) > 0:
                issues.append(f"å‘ç° {len(invalid_periods)} æ¡æ— æ•ˆæœŸå·è®°å½•")
        
        # æ£€æŸ¥é‡‘é¢åˆ—çš„æœ‰æ•ˆæ€§
        if 'é‡‘é¢' in df.columns:
            try:
                # å°è¯•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                df['é‡‘é¢'] = pd.to_numeric(df['é‡‘é¢'], errors='coerce')
                invalid_amounts = df['é‡‘é¢'].isnull().sum()
                if invalid_amounts > 0:
                    issues.append(f"å‘ç° {invalid_amounts} æ¡æ— æ•ˆé‡‘é¢è®°å½•")
            except Exception as e:
                issues.append(f"é‡‘é¢åˆ—è½¬æ¢å¤±è´¥: {str(e)}")
        
        # æ£€æŸ¥é‡å¤æ•°æ®
        duplicate_count = df.duplicated().sum()
        if duplicate_count > 0:
            issues.append(f"å‘ç° {duplicate_count} æ¡é‡å¤è®°å½•")
        
        if issues:
            with st.expander("âš ï¸ æ•°æ®è´¨é‡é—®é¢˜", expanded=True):
                for issue in issues:
                    st.warning(f"  - {issue}")
        else:
            st.success("âœ… æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡")
        
        return issues
    
    def clean_data(self, uploaded_file):
        """æ•°æ®æ¸…æ´—ä¸»å‡½æ•°"""
        try:
            # ç¬¬ä¸€æ¬¡è¯»å–ç”¨äºå®šä½
            df_temp = pd.read_excel(uploaded_file, header=None, nrows=50)
            st.info(f"åŸå§‹æ•°æ®ç»´åº¦: {df_temp.shape}")
            
            # æ‰¾åˆ°æ•°æ®èµ·å§‹ä½ç½®
            start_row, start_col = self.find_data_start(df_temp)
            st.info(f"æ•°æ®èµ·å§‹ä½ç½®: ç¬¬{start_row+1}è¡Œ, ç¬¬{start_col+1}åˆ—")
            
            # é‡æ–°è¯»å–æ•°æ® - ç‰¹åˆ«å¤„ç†å¸¸è§„æ ¼å¼å•å…ƒæ ¼
            df_clean = pd.read_excel(
                uploaded_file, 
                header=start_row,
                skiprows=range(start_row + 1) if start_row > 0 else None,
                dtype=str,  # å°†æ‰€æœ‰åˆ—è¯»å–ä¸ºå­—ç¬¦ä¸²
                na_filter=False,  # ä¸è¿‡æ»¤ç©ºå€¼
                keep_default_na=False,  # ä¸ä½¿ç”¨é»˜è®¤çš„NAå€¼å¤„ç†
                converters={}  # ä¸ºç©ºï¼Œè®©pandasä¸è¦è¿›è¡Œä»»ä½•è½¬æ¢
            )
            
            # åˆ é™¤èµ·å§‹åˆ—ä¹‹å‰çš„æ‰€æœ‰åˆ—
            if start_col > 0:
                df_clean = df_clean.iloc[:, start_col:]
            
            st.info(f"æ¸…ç†åæ•°æ®ç»´åº¦: {df_clean.shape}")
            
            # æ™ºèƒ½åˆ—è¯†åˆ«
            column_mapping = self.smart_column_identification(df_clean.columns)
            if column_mapping:
                df_clean = df_clean.rename(columns=column_mapping)
                st.success("âœ… åˆ—åè¯†åˆ«å®Œæˆ!")
                for old_col, new_col in column_mapping.items():
                    logger.info(f"  {old_col} -> {new_col}")
            
            # ç¡®ä¿å¿…è¦åˆ—å­˜åœ¨
            missing_columns = [col for col in self.required_columns if col not in df_clean.columns]
            if missing_columns and len(df_clean.columns) >= 4:
                st.warning("è‡ªåŠ¨æ˜ å°„åˆ—å...")
                manual_mapping = {}
                col_names = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'å†…å®¹', 'ç©æ³•', 'é‡‘é¢']
                for i, col_name in enumerate(col_names):
                    if i < len(df_clean.columns):
                        manual_mapping[df_clean.columns[i]] = col_name
                
                df_clean = df_clean.rename(columns=manual_mapping)
                st.info(f"æ‰‹åŠ¨é‡å‘½ååçš„åˆ—: {list(df_clean.columns)}")
            
            # æ•°æ®æ¸…ç† - å¢å¼ºç©ºæ ¼å¤„ç†
            initial_count = len(df_clean)
            df_clean = df_clean.dropna(subset=[col for col in self.required_columns if col in df_clean.columns])
            df_clean = df_clean.dropna(axis=1, how='all')
            
            # æ•°æ®ç±»å‹è½¬æ¢ - ç‰¹åˆ«å°å¿ƒå¤„ç†ä¼šå‘˜è´¦å·
            for col in self.required_columns:
                if col in df_clean.columns:
                    if col == 'ä¼šå‘˜è´¦å·':
                        # ç‰¹åˆ«å¤„ç†ä¼šå‘˜è´¦å·ï¼šç¡®ä¿ä¸ä¸¢å¤±ä»»ä½•å­—ç¬¦ï¼Œä½†å¤„ç†ç©ºæ ¼
                        df_clean[col] = df_clean[col].apply(
                            lambda x: normalize_spaces(str(x)) if pd.notna(x) else ''
                        )
                    else:
                        df_clean[col] = df_clean[col].astype(str).apply(normalize_spaces)
            
            # ä¿®å¤æœŸå·æ ¼å¼ï¼šå»æ‰.0 - æ”¹è¿›ï¼šç¡®ä¿è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            if 'æœŸå·' in df_clean.columns:
                df_clean['æœŸå·'] = df_clean['æœŸå·'].astype(str).str.replace(r'\.0$', '', regex=True)
            
            # éªŒè¯é‡‘é¢åˆ—çš„æœ‰æ•ˆæ€§
            if 'é‡‘é¢' in df_clean.columns:
                try:
                    # å°è¯•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                    df_clean['é‡‘é¢'] = pd.to_numeric(df_clean['é‡‘é¢'], errors='coerce')
                    invalid_amounts = df_clean['é‡‘é¢'].isnull().sum()
                    if invalid_amounts > 0:
                        st.warning(f"å‘ç° {invalid_amounts} æ¡æ— æ•ˆé‡‘é¢è®°å½•")
                except Exception as e:
                    st.warning(f"é‡‘é¢åˆ—è½¬æ¢å¤±è´¥: {str(e)}")
            
            # æ•°æ®è´¨é‡éªŒè¯ - æ·»åŠ ä¼šå‘˜è´¦å·å®Œæ•´æ€§æ£€æŸ¥
            self.validate_data_quality(df_clean)
            
            st.success(f"âœ… æ•°æ®æ¸…æ´—å®Œæˆ: {initial_count} -> {len(df_clean)} æ¡è®°å½•")
            
            # æ˜¾ç¤ºä¼šå‘˜è´¦å·æ ·æœ¬
            st.info(f"ğŸ“Š å”¯ä¸€ä¼šå‘˜è´¦å·æ•°: {df_clean['ä¼šå‘˜è´¦å·'].nunique()}")
            
            # å½©ç§åˆ†å¸ƒæ˜¾ç¤º
            lottery_dist = df_clean['å½©ç§'].value_counts()
            with st.expander("ğŸ¯ å½©ç§åˆ†å¸ƒ", expanded=False):
                st.dataframe(lottery_dist.reset_index().rename(columns={'index': 'å½©ç§', 'å½©ç§': 'æ•°é‡'}))
            
            return df_clean
            
        except Exception as e:
            st.error(f"âŒ æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            logger.error(f"æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")  # æ·»åŠ è¯¦ç»†é”™è¯¯æ—¥å¿—
            return None

# ==================== å†…å®¹è§£æå™¨ ====================
class ContentParser:
    """ç»Ÿä¸€çš„æŠ•æ³¨å†…å®¹è§£æå™¨"""

    @staticmethod
    def parse_pk10_vertical_format(content):
        """
        è§£æPK10ç«–çº¿åˆ†éš”çš„å®šä½èƒ†æ ¼å¼
        æ ¼å¼ï¼šå·ç 1,å·ç 2|å·ç 3|å·ç 4,å·ç 5|å·ç 6|å·ç 7,å·ç 8,å·ç 9|å·ç 10
        æˆ–è€…ï¼š_|05|_|_|_ è¡¨ç¤ºåªæœ‰ç¬¬äºŒä¸ªä½ç½®æœ‰æŠ•æ³¨
        """
        try:
            content_str = str(content).strip()
            bets_by_position = defaultdict(list)
            
            if not content_str:
                return bets_by_position
            
            # å®šä¹‰ä½ç½®æ˜ å°„ - ä¿®æ­£é‡å¤çš„ä½ç½®
            positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                        'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
            
            # æŒ‰ç«–çº¿åˆ†å‰²
            parts = content_str.split('|')
            
            for i, part in enumerate(parts):
                if i < len(positions):
                    position = positions[i]
                    part_clean = part.strip()
                    
                    # è·³è¿‡ç©ºä½æˆ–ä¸‹åˆ’çº¿
                    if not part_clean or part_clean == '_' or part_clean == '':
                        continue
                    
                    # æå–æ•°å­—ï¼ˆå¯èƒ½æ˜¯å•ä¸ªæ•°å­—æˆ–å¤šä¸ªé€—å·åˆ†éš”çš„æ•°å­—ï¼‰
                    numbers = []
                    if ',' in part_clean:
                        # é€—å·åˆ†éš”çš„å¤šä¸ªæ•°å­—
                        number_strs = part_clean.split(',')
                        for num_str in number_strs:
                            num_clean = num_str.strip()
                            if num_clean.isdigit():
                                numbers.append(int(num_clean))
                    else:
                        # å•ä¸ªæ•°å­— - ä¿®å¤ï¼šä½¿ç”¨part_clean
                        if part_clean.isdigit():
                            numbers.append(int(part_clean))
                    
                    # æ·»åŠ åˆ°å¯¹åº”ä½ç½®
                    bets_by_position[position].extend(numbers)
            
            return bets_by_position
        except Exception as e:
            logger.warning(f"è§£æPK10ç«–çº¿æ ¼å¼å¤±è´¥: {content}, é”™è¯¯: {str(e)}")
            return defaultdict(list)
    
    @staticmethod
    def parse_ssc_vertical_format(content):
        """
        è§£ææ—¶æ—¶å½©ç«–çº¿åˆ†éš”çš„å®šä½èƒ†æ ¼å¼
        æ ¼å¼ï¼šå·ç 1,å·ç 2|å·ç 3|å·ç 4,å·ç 5|å·ç 6|å·ç 7,å·ç 8,å·ç 9|å·ç 10
        æˆ–è€…ï¼š_|05|_|_|_ è¡¨ç¤ºåªæœ‰ç¬¬äºŒä¸ªä½ç½®æœ‰æŠ•æ³¨
        """
        try:
            content_str = str(content).strip()
            bets_by_position = defaultdict(list)
            
            if not content_str:
                return bets_by_position
            
            # å®šä¹‰ä½ç½®æ˜ å°„
            positions = ['ç¬¬1çƒ', 'ç¬¬2çƒ', 'ç¬¬3çƒ', 'ç¬¬4çƒ', 'ç¬¬5çƒ']
            
            # æŒ‰ç«–çº¿åˆ†å‰²
            parts = content_str.split('|')
            
            for i, part in enumerate(parts):
                if i < len(positions):
                    position = positions[i]
                    part_clean = part.strip()
                    
                    # è·³è¿‡ç©ºä½æˆ–ä¸‹åˆ’çº¿
                    if not part_clean or part_clean == '_' or part_clean == '':
                        continue
                    
                    # æå–æ•°å­—ï¼ˆå¯èƒ½æ˜¯å•ä¸ªæ•°å­—æˆ–å¤šä¸ªé€—å·åˆ†éš”çš„æ•°å­—ï¼‰
                    numbers = []
                    if ',' in part_clean:
                        # é€—å·åˆ†éš”çš„å¤šä¸ªæ•°å­—
                        number_strs = part_clean.split(',')
                        for num_str in number_strs:
                            num_clean = num_str.strip()
                            if num_clean.isdigit():
                                numbers.append(int(num_clean))
                    else:
                        # å•ä¸ªæ•°å­— - ä¿®å¤ï¼šä½¿ç”¨part_clean
                        if part_clean.isdigit():
                            numbers.append(int(part_clean))
                    
                    # æ·»åŠ åˆ°å¯¹åº”ä½ç½®
                    bets_by_position[position].extend(numbers)
            
            return bets_by_position
        except Exception as e:
            logger.warning(f"è§£ææ—¶æ—¶å½©ç«–çº¿æ ¼å¼å¤±è´¥: {content}, é”™è¯¯: {str(e)}")
            return defaultdict(list)

    @staticmethod
    def parse_ssc_vertical_format(content):
        """
        è§£ææ—¶æ—¶å½©ç«–çº¿åˆ†éš”çš„å®šä½èƒ†æ ¼å¼
        æ ¼å¼ï¼šå·ç 1,å·ç 2|å·ç 3|å·ç 4,å·ç 5|å·ç 6|å·ç 7,å·ç 8,å·ç 9|å·ç 10
        æˆ–è€…ï¼š_|05|_|_|_ è¡¨ç¤ºåªæœ‰ç¬¬äºŒä¸ªä½ç½®æœ‰æŠ•æ³¨
        """
        content_str = str(content).strip()
        bets_by_position = defaultdict(list)
        
        if not content_str:
            return bets_by_position
        
        # å®šä¹‰ä½ç½®æ˜ å°„
        positions = ['ç¬¬1çƒ', 'ç¬¬2çƒ', 'ç¬¬3çƒ', 'ç¬¬4çƒ', 'ç¬¬5çƒ']
        
        # æŒ‰ç«–çº¿åˆ†å‰²
        parts = content_str.split('|')
        
        for i, part in enumerate(parts):
            if i < len(positions):
                position = positions[i]
                part_clean = part.strip()
                
                # è·³è¿‡ç©ºä½æˆ–ä¸‹åˆ’çº¿
                if not part_clean or part_clean == '_' or part_clean == '':
                    continue
                
                # æå–æ•°å­—ï¼ˆå¯èƒ½æ˜¯å•ä¸ªæ•°å­—æˆ–å¤šä¸ªé€—å·åˆ†éš”çš„æ•°å­—ï¼‰
                numbers = []
                if ',' in part_clean:
                    # é€—å·åˆ†éš”çš„å¤šä¸ªæ•°å­—
                    number_strs = part_clean.split(',')
                    for num_str in number_strs:
                        num_clean = num_str.strip()
                        if num_clean.isdigit():
                            numbers.append(int(num_clean))
                else:
                    # å•ä¸ªæ•°å­—
                    if part_clean.isdigit():
                        numbers.append(int(part_clean))
                
                # æ·»åŠ åˆ°å¯¹åº”ä½ç½®
                bets_by_position[position].extend(numbers)
        
        return bets_by_position
    
    @staticmethod
    def parse_positional_bets(content, position_keywords=None):
        """
        è§£æä½ç½®æŠ•æ³¨å†…å®¹
        æ ¼å¼ï¼šä½ç½®1-æŠ•æ³¨é¡¹1,æŠ•æ³¨é¡¹2,ä½ç½®2-æŠ•æ³¨é¡¹1,æŠ•æ³¨é¡¹2,...
        """
        content_str = str(content).strip()
        bets_by_position = defaultdict(list)
        
        if not content_str:
            return bets_by_position
        
        # æŒ‰é€—å·åˆ†å‰²æ‰€æœ‰éƒ¨åˆ†
        parts = [part.strip() for part in content_str.split(',')]
        
        current_position = None
        
        for part in parts:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä½ç½®å…³é”®è¯
            is_position = False
            if position_keywords:
                for keyword in position_keywords:
                    if keyword in part and '-' in part:
                        is_position = True
                        break
            
            # å¦‚æœåŒ…å«ä½ç½®ä¿¡æ¯æˆ–è€…æ˜¯æ˜ç¡®çš„"ä½ç½®-å†…å®¹"æ ¼å¼
            if '-' in part and (is_position or position_keywords is None):
                try:
                    position_part, bet_value = part.split('-', 1)
                    current_position = position_part.strip()
                    bets_by_position[current_position].append(bet_value.strip())
                except ValueError:
                    # åˆ†å‰²å¤±è´¥ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„ä½ç½®æ ¼å¼
                    if current_position:
                        bets_by_position[current_position].append(part)
            elif current_position:
                # å±äºå½“å‰ä½ç½®çš„æŠ•æ³¨é¡¹
                bets_by_position[current_position].append(part)
            else:
                # æ²¡æœ‰å½“å‰ä½ç½®ï¼Œå¯èƒ½æ˜¯ç‹¬ç«‹çš„æŠ•æ³¨é¡¹
                bets_by_position['æœªçŸ¥ä½ç½®'].append(part)
        
        return bets_by_position
    
    @staticmethod
    def parse_pk10_content(content):
        """è§£æPK10æŠ•æ³¨å†…å®¹ - å¢å¼ºç‰ˆï¼Œæ”¯æŒç«–çº¿æ ¼å¼"""
        pk10_positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                         'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå',
                         'ç¬¬1å', 'ç¬¬2å', 'ç¬¬3å', 'ç¬¬4å', 'ç¬¬5å',
                         'ç¬¬6å', 'ç¬¬7å', 'ç¬¬8å', 'ç¬¬9å', 'ç¬¬10å',
                         'å‰ä¸€', 'å‰äºŒ', 'å‰ä¸‰']
        
        content_str = str(content).strip()
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ç«–çº¿åˆ†éš”æ ¼å¼
        if '|' in content_str and any(char.isdigit() or char == '_' or char == ',' for char in content_str):
            vertical_result = ContentParser.parse_pk10_vertical_format(content_str)
            if any(vertical_result.values()):  # å¦‚æœæœ‰è§£æç»“æœ
                return vertical_result
        
        # ç‰¹æ®Šå¤„ç†"ä½ç½®:å·ç "æ ¼å¼
        if ':' in content_str and re.search(r'\d{2}', content_str):
            match = re.match(r'^(.+?):([\d,]+)$', content_str)
            if match:
                position = match.group(1).strip()
                numbers_str = match.group(2)
                bets_by_position = defaultdict(list)
                
                normalized_position = position
                if 'ä¹' in position or '9' in position:
                    normalized_position = 'ç¬¬ä¹å'
                
                numbers = re.findall(r'\d{2}', numbers_str)
                bets_by_position[normalized_position].extend([int(num) for num in numbers])
                return bets_by_position
        
        # åŸæœ‰çš„è§£æé€»è¾‘
        return ContentParser.parse_positional_bets(content, pk10_positions)
    
    @staticmethod
    def parse_lhc_zhengma_content(content):
        """
        è§£æå…­åˆå½©æ­£ç æŠ•æ³¨å†…å®¹ - å¢å¼ºç‰ˆæœ¬
        æ ¼å¼ï¼šä½ç½®1-æŠ•æ³¨é¡¹1,æŠ•æ³¨é¡¹2,ä½ç½®2-æŠ•æ³¨é¡¹1,æŠ•æ³¨é¡¹2,...
        """
        content_str = str(content).strip()
        bets_by_position = defaultdict(list)
        
        if not content_str:
            return bets_by_position
        
        # æŒ‰é€—å·åˆ†å‰²æ‰€æœ‰éƒ¨åˆ†
        parts = [part.strip() for part in content_str.split(',')]
        
        current_position = None
        
        for part in parts:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä½ç½®å…³é”®è¯
            is_position = False
            position_keywords = ['æ­£ç ä¸€', 'æ­£ç äºŒ', 'æ­£ç ä¸‰', 'æ­£ç å››', 'æ­£ç äº”', 'æ­£ç å…­',
                               'æ­£1', 'æ­£2', 'æ­£3', 'æ­£4', 'æ­£5', 'æ­£6',
                               'æ­£ç 1', 'æ­£ç 2', 'æ­£ç 3', 'æ­£ç 4', 'æ­£ç 5', 'æ­£ç 6']
            
            for keyword in position_keywords:
                if keyword in part and '-' in part:
                    is_position = True
                    break
            
            # å¦‚æœåŒ…å«ä½ç½®ä¿¡æ¯æˆ–è€…æ˜¯æ˜ç¡®çš„"ä½ç½®-å†…å®¹"æ ¼å¼
            if '-' in part and is_position:
                try:
                    position_part, bet_value = part.split('-', 1)
                    current_position = position_part.strip()
                    bets_by_position[current_position].append(bet_value.strip())
                except ValueError:
                    # åˆ†å‰²å¤±è´¥ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„ä½ç½®æ ¼å¼
                    if current_position:
                        bets_by_position[current_position].append(part)
            elif current_position:
                # å±äºå½“å‰ä½ç½®çš„æŠ•æ³¨é¡¹
                bets_by_position[current_position].append(part)
            else:
                # æ²¡æœ‰å½“å‰ä½ç½®ï¼Œå¯èƒ½æ˜¯ç‹¬ç«‹çš„æŠ•æ³¨é¡¹
                bets_by_position['æœªçŸ¥ä½ç½®'].append(part)
        
        return bets_by_position
    
    @staticmethod
    def parse_ssc_content(content):
        """è§£ææ—¶æ—¶å½©æŠ•æ³¨å†…å®¹ - å¢å¼ºç«–çº¿æ ¼å¼æ”¯æŒ"""
        ssc_positions = ['ç¬¬1çƒ', 'ç¬¬2çƒ', 'ç¬¬3çƒ', 'ç¬¬4çƒ', 'ç¬¬5çƒ',
                        'ä¸‡ä½', 'åƒä½', 'ç™¾ä½', 'åä½', 'ä¸ªä½']
        
        content_str = str(content).strip()
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ç«–çº¿åˆ†éš”æ ¼å¼
        if '|' in content_str and any(char.isdigit() or char == '_' or char == ',' for char in content_str):
            vertical_result = ContentParser.parse_ssc_vertical_format(content_str)
            if any(vertical_result.values()):  # å¦‚æœæœ‰è§£æç»“æœ
                return vertical_result
        
        # åŸæœ‰çš„è§£æé€»è¾‘
        return ContentParser.parse_positional_bets(content, ssc_positions)

    @staticmethod
    def parse_3d_vertical_format(content):
        """
        è§£æ3D/æ’åˆ—3ç«–çº¿åˆ†éš”çš„å®šä½èƒ†æ ¼å¼
        æ ¼å¼ï¼šå·ç 1,å·ç 2|å·ç 3|å·ç 4,å·ç 5,å·ç 6
        æˆ–è€…ï¼š_|05|_ è¡¨ç¤ºåªæœ‰ç¬¬äºŒä¸ªä½ç½®æœ‰æŠ•æ³¨
        """
        try:
            content_str = str(content).strip()
            bets_by_position = defaultdict(list)
            
            if not content_str:
                return bets_by_position
            
            # å®šä¹‰ä½ç½®æ˜ å°„ - 3Dé€šå¸¸æ˜¯ç™¾ä½ã€åä½ã€ä¸ªä½
            positions = ['ç™¾ä½', 'åä½', 'ä¸ªä½']
            
            # æŒ‰ç«–çº¿åˆ†å‰²
            parts = content_str.split('|')
            
            for i, part in enumerate(parts):
                if i < len(positions):
                    position = positions[i]
                    part_clean = part.strip()
                    
                    # è·³è¿‡ç©ºä½æˆ–ä¸‹åˆ’çº¿
                    if not part_clean or part_clean == '_' or part_clean == '':
                        continue
                    
                    # æå–æ•°å­—ï¼ˆå¯èƒ½æ˜¯å•ä¸ªæ•°å­—æˆ–å¤šä¸ªé€—å·åˆ†éš”çš„æ•°å­—ï¼‰
                    numbers = []
                    if ',' in part_clean:
                        # é€—å·åˆ†éš”çš„å¤šä¸ªæ•°å­—
                        number_strs = part_clean.split(',')
                        for num_str in number_strs:
                            num_clean = num_str.strip()
                            if num_clean.isdigit():
                                numbers.append(int(num_clean))
                    else:
                        # å•ä¸ªæ•°å­— - ä¿®å¤ï¼šä½¿ç”¨part_clean
                        if part_clean.isdigit():
                            numbers.append(int(part_clean))
                    
                    # æ·»åŠ åˆ°å¯¹åº”ä½ç½®
                    bets_by_position[position].extend(numbers)
            
            return bets_by_position
        except Exception as e:
            logger.warning(f"è§£æ3Dç«–çº¿æ ¼å¼å¤±è´¥: {content}, é”™è¯¯: {str(e)}")
            return defaultdict(list)

    @staticmethod
    def infer_position_from_content(content, lottery_type):
        """ä»å†…å®¹å’Œå½©ç§ç±»å‹æ¨æ–­ä½ç½®"""
        content_str = str(content)
        
        if lottery_type == 'PK10':
            # PK10ä½ç½®æ¨æ–­é€»è¾‘
            pk10_positions = {
                'å† å†›': ['å† å†›', 'ç¬¬1å', 'ç¬¬ä¸€å', 'å‰ä¸€'],
                'äºšå†›': ['äºšå†›', 'ç¬¬2å', 'ç¬¬äºŒå'],
                'ç¬¬ä¸‰å': ['ç¬¬ä¸‰å', 'å­£å†›', 'ç¬¬3å'],
                'ç¬¬å››å': ['ç¬¬å››å', 'ç¬¬4å'],
                'ç¬¬äº”å': ['ç¬¬äº”å', 'ç¬¬5å'],
                'ç¬¬å…­å': ['ç¬¬å…­å', 'ç¬¬6å'],
                'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå', 'ç¬¬7å'],
                'ç¬¬å…«å': ['ç¬¬å…«å', 'ç¬¬8å'],
                'ç¬¬ä¹å': ['ç¬¬ä¹å', 'ç¬¬9å'],
                'ç¬¬åå': ['ç¬¬åå', 'ç¬¬10å']
            }
            for position, keywords in pk10_positions.items():
                for keyword in keywords:
                    if keyword in content_str:
                        return position
        
        elif lottery_type == 'SSC':
            # æ—¶æ—¶å½©ä½ç½®æ¨æ–­é€»è¾‘
            ssc_positions = {
                'ç¬¬1çƒ': ['ç¬¬1çƒ', 'ä¸‡ä½', 'ç¬¬ä¸€ä½'],
                'ç¬¬2çƒ': ['ç¬¬2çƒ', 'åƒä½', 'ç¬¬äºŒä½'],
                'ç¬¬3çƒ': ['ç¬¬3çƒ', 'ç™¾ä½', 'ç¬¬ä¸‰ä½'],
                'ç¬¬4çƒ': ['ç¬¬4çƒ', 'åä½', 'ç¬¬å››ä½'],
                'ç¬¬5çƒ': ['ç¬¬5çƒ', 'ä¸ªä½', 'ç¬¬äº”ä½']
            }
            for position, keywords in ssc_positions.items():
                for keyword in keywords:
                    if keyword in content_str:
                        return position
        
        elif lottery_type == 'LHC':
            # å…­åˆå½©ä½ç½®æ¨æ–­é€»è¾‘
            lhc_positions = {
                'æ­£ç 1': ['æ­£ç ä¸€', 'æ­£1', 'æ­£ç 1'],
                'æ­£ç 2': ['æ­£ç äºŒ', 'æ­£2', 'æ­£ç 2'],
                'æ­£ç 3': ['æ­£ç ä¸‰', 'æ­£3', 'æ­£ç 3'],
                'æ­£ç 4': ['æ­£ç å››', 'æ­£4', 'æ­£ç 4'],
                'æ­£ç 5': ['æ­£ç äº”', 'æ­£5', 'æ­£ç 5'],
                'æ­£ç 6': ['æ­£ç å…­', 'æ­£6', 'æ­£ç 6']
            }
            for position, keywords in lhc_positions.items():
                for keyword in keywords:
                    if keyword in content_str:
                        return position
        
        return 'æœªçŸ¥ä½ç½®'

    @staticmethod
    def infer_position_comprehensive(content, category, lottery_type):
        """ç»¼åˆè€ƒè™‘ç©æ³•å’ŒæŠ•æ³¨å†…å®¹çš„ä½ç½®æ¨æ–­ - å¢å¼ºç©ºæ ¼å¤„ç†"""
        # ç»Ÿä¸€å¤„ç†ç©ºæ ¼
        content_str = normalize_spaces(content)
        category_str = normalize_spaces(category)
        
        # ä¿®æ­£çš„å½©ç§ç‰¹å®šä½ç½®å…³é”®è¯æ˜ å°„
        position_mappings = {
            'LHC': {
                # æ­£ç ä½ç½®æ˜ å°„
                'æ­£ç ä¸€': ['æ­£ç ä¸€', 'æ­£1', 'æ­£ç 1', 'æ­£ä¸€'],
                'æ­£ç äºŒ': ['æ­£ç äºŒ', 'æ­£2', 'æ­£ç 2', 'æ­£äºŒ'],
                'æ­£ç ä¸‰': ['æ­£ç ä¸‰', 'æ­£3', 'æ­£ç 3', 'æ­£ä¸‰'],
                'æ­£ç å››': ['æ­£ç å››', 'æ­£4', 'æ­£ç 4', 'æ­£å››'],
                'æ­£ç äº”': ['æ­£ç äº”', 'æ­£5', 'æ­£ç 5', 'æ­£äº”'],
                'æ­£ç å…­': ['æ­£ç å…­', 'æ­£6', 'æ­£ç 6', 'æ­£å…­'],
                
                # æ­£ç‰¹ä½ç½®æ˜ å°„ - ç‹¬ç«‹
                'æ­£1ç‰¹': ['æ­£ç ä¸€ç‰¹', 'æ­£1ç‰¹'],
                'æ­£2ç‰¹': ['æ­£ç äºŒç‰¹', 'æ­£2ç‰¹'],
                'æ­£3ç‰¹': ['æ­£ç ä¸‰ç‰¹', 'æ­£3ç‰¹'],
                'æ­£4ç‰¹': ['æ­£ç å››ç‰¹', 'æ­£4ç‰¹'],
                'æ­£5ç‰¹': ['æ­£ç äº”ç‰¹', 'æ­£5ç‰¹'],
                'æ­£6ç‰¹': ['æ­£ç å…­ç‰¹', 'æ­£6ç‰¹']
            },
            'PK10': {
                'å† å†›': ['å† å†›', 'å†  å†›', 'å†   å†›', 'ç¬¬1å', 'ç¬¬ä¸€å', 'å‰ä¸€', '1st', '1'],
                'äºšå†›': ['äºšå†›', 'äºš å†›', 'äºš  å†›', 'ç¬¬2å', 'ç¬¬äºŒå', '2nd', '2'],
                'ç¬¬ä¸‰å': ['ç¬¬ä¸‰å', 'ç¬¬3å', 'å­£å†›', '3rd', '3'],
                'ç¬¬å››å': ['ç¬¬å››å', 'ç¬¬4å', '4th', '4'],
                'ç¬¬äº”å': ['ç¬¬äº”å', 'ç¬¬5å', '5th', '5'],
                'ç¬¬å…­å': ['ç¬¬å…­å', 'ç¬¬6å', '6th', '6'],
                'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå', 'ç¬¬7å', '7th', '7'],
                'ç¬¬å…«å': ['ç¬¬å…«å', 'ç¬¬8å', '8th', '8'],
                'ç¬¬ä¹å': ['ç¬¬ä¹å', 'ç¬¬9å', '9th', '9'],
                'ç¬¬åå': ['ç¬¬åå', 'ç¬¬10å', '10th', '10']
            }
        }
        
        mapping = position_mappings.get(lottery_type, {})
        
        # ç­–ç•¥1ï¼šä¼˜å…ˆä»ç©æ³•åˆ†ç±»ä¸­æå–ä½ç½®ï¼ˆæ›´å¯é ï¼‰
        for position, keywords in mapping.items():
            for keyword in keywords:
                # ä½¿ç”¨æ ‡å‡†åŒ–åçš„å…³é”®è¯è¿›è¡Œæ¯”è¾ƒ
                normalized_keyword = normalize_spaces(keyword)
                if normalized_keyword in category_str:
                    return position
        
        # ç­–ç•¥2ï¼šä»æŠ•æ³¨å†…å®¹ä¸­æå–ä½ç½®
        for position, keywords in mapping.items():
            for keyword in keywords:
                normalized_keyword = normalize_spaces(keyword)
                if normalized_keyword in content_str:
                    return position
        
        # ç­–ç•¥3ï¼šä½¿ç”¨åŸæœ‰çš„æ¨æ–­æ–¹æ³•
        return ContentParser.infer_position_from_content(content, lottery_type)

# ==================== æ•°æ®åˆ†æç±» ====================
class DataAnalyzer:
    def __init__(self):
        self.cache = {}
        self.content_parser = ContentParser()  # æ·»åŠ ç»Ÿä¸€è§£æå™¨
    
    @lru_cache(maxsize=10000)
    def extract_numbers_cached(self, content, min_num, max_num, is_pk10=False):
        """å¸¦ç¼“å­˜çš„å·ç æå–å‡½æ•°"""
        return self.extract_numbers_from_content(content, min_num, max_num, is_pk10)
    
    def extract_numbers_from_content(self, content, min_num=0, max_num=49, is_pk10=False):
        """ä»å†…å®¹ä¸­æå–æ•°å­— - å¢å¼ºä¸‰å†›æ ¼å¼å¤„ç†"""
        numbers = []
        content_str = str(content)
        
        try:
            # ç‰¹æ®Šå¤„ç†ä¸‰å†›æ ¼å¼ï¼š1,2,3,4,5,6
            if re.match(r'^(\d,)*\d$', content_str.strip()):
                numbers = [int(x.strip()) for x in content_str.split(',') if x.strip().isdigit()]
                # è¿‡æ»¤èŒƒå›´
                numbers = [num for num in numbers if min_num <= num <= max_num]
                return list(set(numbers))
            
            if is_pk10:
                # PKæ‹¾/èµ›è½¦ç‰¹æ®Šå¤„ç†ï¼šè¿‡æ»¤æ‰"ç¬¬Xå"ç­‰ç©æ³•æè¿°
                content_str = re.sub(r'ç¬¬\d+å-?', '', content_str)
            
            # æå–æ•°å­—
            number_matches = re.findall(r'\b\d{1,2}\b', content_str)
            for match in number_matches:
                num = int(match)
                if min_num <= num <= max_num:
                    numbers.append(num)
            
            return list(set(numbers))
        except Exception as e:
            logger.warning(f"å·ç æå–å¤±è´¥: {content}, é”™è¯¯: {str(e)}")
            return []
    
    def extract_zodiacs_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–ç”Ÿè‚–"""
        zodiacs = ['é¼ ', 'ç‰›', 'è™', 'å…”', 'é¾™', 'è›‡', 'é©¬', 'ç¾Š', 'çŒ´', 'é¸¡', 'ç‹—', 'çŒª']
        found_zodiacs = []
        
        content_str = str(content)
        for zodiac in zodiacs:
            if zodiac in content_str:
                found_zodiacs.append(zodiac)
        
        return list(set(found_zodiacs))
    
    def extract_tails_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–å°¾æ•°ï¼ˆè¿å°¾ä¸“ç”¨ï¼‰"""
        tails = []
        content_str = str(content)
        
        # åŒ¹é…å°¾æ•°æ¨¡å¼ï¼šå°¾0ã€å°¾1ã€0å°¾ã€1å°¾ç­‰
        tail_patterns = [
            r'å°¾([0-9])',  # å°¾0,å°¾1,...,å°¾9
            r'([0-9])å°¾',  # 0å°¾,1å°¾,...,9å°¾
        ]
        
        for pattern in tail_patterns:
            matches = re.findall(pattern, content_str)
            tails.extend([int(tail) for tail in matches])
        
        return list(set(tails))
    
    def extract_size_parity_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–å¤§å°å•åŒ - å¢å¼ºç©ºæ ¼å¤„ç†"""
        content_str = normalize_spaces(str(content))
        size_parity = []
        
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„åŒ¹é…ï¼Œé¿å…è¯¯åŒ¹é…
        if re.search(r'(?<!åˆ)å¤§(?![å°å°¾])', content_str) or 'ç‰¹å¤§' in content_str:
            size_parity.append('å¤§')
        if re.search(r'(?<!åˆ)å°(?![å¤§å°¾])', content_str) or 'ç‰¹å°' in content_str:
            size_parity.append('å°')
        if re.search(r'(?<!åˆ)å•(?![åŒ])', content_str) or 'ç‰¹å•' in content_str:
            size_parity.append('å•')
        if re.search(r'(?<!åˆ)åŒ(?![å•])', content_str) or 'ç‰¹åŒ' in content_str:
            size_parity.append('åŒ')
        
        return list(set(size_parity))
    
    def extract_dragon_tiger_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–é¾™è™ - å¢å¼ºç©ºæ ¼å¤„ç†"""
        content_str = normalize_spaces(str(content))
        dragon_tiger = []
        
        if 'é¾™' in content_str and 'è™' not in content_str:
            dragon_tiger.append('é¾™')
        if 'è™' in content_str and 'é¾™' not in content_str:
            dragon_tiger.append('è™')
        
        return list(set(dragon_tiger))
    
    def extract_wave_color_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–æ³¢è‰² - å¢å¼ºç‰ˆï¼Œæ”¯æŒåŠæ³¢é¡¹è¯†åˆ«"""
        content_str = str(content)
        found_waves = []
        
        # æ³¢è‰²æ˜ å°„ï¼ˆåŒ…æ‹¬ä¸ƒè‰²æ³¢çš„æ‰€æœ‰é¢œè‰²ï¼‰
        wave_mappings = {
            'çº¢æ³¢': ['çº¢æ³¢', 'ç´…è‰²æ³¢', 'çº¢'],
            'è“æ³¢': ['è“æ³¢', 'è—æ³¢', 'è“', 'è—'],
            'ç»¿æ³¢': ['ç»¿æ³¢', 'ç¶ æ³¢', 'ç»¿', 'ç¶ '],
            'ç´«æ³¢': ['ç´«æ³¢', 'ç´«'],
            'æ©™æ³¢': ['æ©™æ³¢', 'æ©™'],
            'é»„æ³¢': ['é»„æ³¢', 'é»ƒæ³¢', 'é»„', 'é»ƒ'],
            'é’æ³¢': ['é’æ³¢', 'é’']
        }
        
        for wave_name, keywords in wave_mappings.items():
            for keyword in keywords:
                if keyword in content_str:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å¤åˆæŠ•æ³¨ï¼Œå¦‚"çº¢æ³¢-çº¢åŒ"
                    if '-' in content_str and f"{keyword}-" in content_str:
                        # è¿™ç§æƒ…å†µ"çº¢æ³¢"æ˜¯ç©æ³•éƒ¨åˆ†ï¼Œä¸æ˜¯å®é™…æŠ•æ³¨å†…å®¹
                        pass  # æ·»åŠ passè¯­å¥ï¼Œé¿å…ç©ºçš„ifåˆ†æ”¯
                    else:
                        # æ£€æŸ¥æ˜¯å¦è¢«åŠæ³¢é¡¹åŒ…å«ï¼ˆå¦‚"çº¢å¤§"åŒ…å«"çº¢"ï¼Œä½†ä¸æ˜¯æˆ‘ä»¬è¦çš„æ³¢è‰²ï¼‰
                        is_banbo_item = False
                        banbo_indicators = ['å¤§', 'å°', 'å•', 'åŒ']
                        for indicator in banbo_indicators:
                            if f"{keyword}{indicator}" in content_str or f"{keyword} {indicator}" in content_str:
                                is_banbo_item = True
                                break
                        
                        if not is_banbo_item:
                            found_waves.append(wave_name)
                    break  # æ‰¾åˆ°ä¸€ä¸ªå…³é”®è¯å°±è·³å‡ºå†…å±‚å¾ªç¯
        
        return list(set(found_waves))

    def extract_three_color_wave_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–ä¸‰è‰²å½©çš„æ³¢è‰² - åªæå–çº¢æ³¢ã€ç»¿æ³¢ã€ç´«æ³¢"""
        content_str = str(content)
        found_waves = []
        
        # å¤„ç†ç¹ä½“å­—å’Œç®€ä½“å­—
        if 'çº¢æ³¢' in content_str or 'ç´…æ³¢' in content_str:
            found_waves.append('çº¢æ³¢')
        if 'ç»¿æ³¢' in content_str or 'ç¶ æ³¢' in content_str:
            found_waves.append('ç»¿æ³¢')
        if 'ç´«æ³¢' in content_str:
            found_waves.append('ç´«æ³¢')
        
        return list(set(found_waves))
    
    def extract_five_elements_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–äº”è¡Œ"""
        content_str = str(content)
        elements = ['é‡‘', 'æœ¨', 'æ°´', 'ç«', 'åœŸ']
        found_elements = []
        
        for element in elements:
            if element in content_str:
                found_elements.append(element)
        
        return list(set(found_elements))
    
    def extract_douniu_types(self, content):
        """æå–æ–—ç‰›ç±»å‹"""
        content_str = str(content)
        bull_types = []
        
        # ç§»é™¤"æ–—ç‰›-"å‰ç¼€
        clean_content = content_str.replace('æ–—ç‰›-', '')
        
        # æ–—ç‰›ç±»å‹åˆ—è¡¨
        all_types = ['æ— ç‰›', 'ç‰›ä¸€', 'ç‰›äºŒ', 'ç‰›ä¸‰', 'ç‰›å››', 'ç‰›äº”', 
                    'ç‰›å…­', 'ç‰›ä¸ƒ', 'ç‰›å…«', 'ç‰›ä¹', 'ç‰›ç‰›']
        
        for bull_type in all_types:
            if bull_type in clean_content:
                bull_types.append(bull_type)
        
        return list(set(bull_types))
    
    def parse_pk10_gyh_content(self, content):
        """è§£æPK10å† äºšå’Œç©æ³•å†…å®¹"""
        content_str = str(content)
        result = {
            'numbers': set(),    # å’Œå€¼å·ç 
            'size_parity': set() # å¤§å°å•åŒ
        }
        
        # æå–å·ç ï¼ˆ3-19ï¼‰
        numbers = re.findall(r'\b(1[0-9]|[3-9])\b', content_str)
        result['numbers'].update([int(num) for num in numbers])
        
        # æå–å¤§å°å•åŒ
        content_lower = content_str.lower()
        if 'å¤§' in content_lower or 'å† äºšå¤§' in content_lower:
            result['size_parity'].add('å¤§')
        if 'å°' in content_lower or 'å† äºšå°' in content_lower:
            result['size_parity'].add('å°')
        if 'å•' in content_lower or 'å† äºšå•' in content_lower:
            result['size_parity'].add('å•')
        if 'åŒ' in content_lower or 'å† äºšåŒ' in content_lower:
            result['size_parity'].add('åŒ')
        
        return result
    
    def parse_pk10_number_content(self, content):
        """è§£æPK10å·ç ç±»ç©æ³•å†…å®¹ - å¢å¼ºç«–çº¿æ ¼å¼æ”¯æŒ"""
        content_str = str(content)
        numbers_by_position = defaultdict(list)
        
        # é¦–å…ˆå°è¯•ç«–çº¿åˆ†éš”æ ¼å¼
        if '|' in content_str and any(char.isdigit() or char == '_' or char == ',' for char in content_str):
            vertical_result = ContentParser.parse_pk10_vertical_format(content_str)
            if any(vertical_result.values()):
                return vertical_result
        
        # å¤„ç†ç«–çº¿åˆ†éš”çš„æ ¼å¼ï¼š01,02,03,04,05|07,08,06,09,10|...
        if '|' in content_str and re.search(r'\d{2}', content_str):
            positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å']
            parts = content_str.split('|')
            
            for i, part in enumerate(parts):
                if i < len(positions):
                    position = positions[i]
                    numbers = re.findall(r'\d{2}', part)
                    numbers_by_position[position].extend([int(num) for num in numbers])
        
        # å¤„ç†"ç¬¬ä¹å:01,02,05,06,07,08,09,03"è¿™ç§æ ¼å¼
        elif ':' in content_str and re.search(r'\d{2}', content_str):
            match = re.match(r'^(.+?):([\d,]+)$', content_str)
            if match:
                position = match.group(1).strip()
                numbers_str = match.group(2)
                position = self._normalize_pk10_position(position)
                if position:
                    numbers = re.findall(r'\d{2}', numbers_str)
                    numbers_by_position[position].extend([int(num) for num in numbers])
            else:
                parts = content_str.split(',')
                for part in parts:
                    if ':' in part:
                        position, numbers_str = part.split(':', 1)
                        position = self._normalize_pk10_position(position)
                        if position:
                            numbers = re.findall(r'\d{2}', numbers_str)
                            numbers_by_position[position].extend([int(num) for num in numbers])
        
        # å¤„ç†å† å†›-01,02,03æ ¼å¼
        elif '-' in content_str and re.search(r'\d{2}', content_str):
            parts = content_str.split(',')
            for part in parts:
                if '-' in part:
                    position, numbers_str = part.split('-', 1)
                    position = self._normalize_pk10_position(position)
                    numbers = re.findall(r'\d{2}', numbers_str)
                    numbers_by_position[position].extend([int(num) for num in numbers])
        
        # å¤„ç†çº¯æ•°å­—æ ¼å¼
        else:
            numbers = self.extract_numbers_from_content(content_str, 1, 10, is_pk10=True)
            if numbers:
                position = self._infer_pk10_position_from_content(content_str)
                numbers_by_position[position].extend(numbers)
        
        # å»é‡
        for position in numbers_by_position:
            numbers_by_position[position] = list(set(numbers_by_position[position]))
        
        return numbers_by_position
    
    def _infer_pk10_position_from_content(self, content):
        """æ¨æ–­PK10ä½ç½®"""
        content_str = str(content)
        
        position_mapping = {
            'å† å†›': ['å† å†›', 'ç¬¬1å', 'ç¬¬ä¸€å'],
            'äºšå†›': ['äºšå†›', 'ç¬¬2å', 'ç¬¬äºŒå'],
            'ç¬¬ä¸‰å': ['ç¬¬ä¸‰å', 'ç¬¬3å', 'å­£å†›'],
            'ç¬¬å››å': ['ç¬¬å››å', 'ç¬¬4å'],
            'ç¬¬äº”å': ['ç¬¬äº”å', 'ç¬¬5å'],
            'ç¬¬å…­å': ['ç¬¬å…­å', 'ç¬¬6å'],
            'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå', 'ç¬¬7å'],
            'ç¬¬å…«å': ['ç¬¬å…«å', 'ç¬¬8å'],
            'ç¬¬ä¹å': ['ç¬¬ä¹å', 'ç¬¬9å'],
            'ç¬¬åå': ['ç¬¬åå', 'ç¬¬10å']
        }
        
        for position, keywords in position_mapping.items():
            for keyword in keywords:
                if keyword in content_str:
                    return position
        
        return 'å† å†›'
    
    def _normalize_pk10_position(self, position):
        """å¢å¼ºçš„PK10ä½ç½®æ ‡å‡†åŒ–"""
        position_mapping = {
            'å† å†›': 'å† å†›', 'ç¬¬1å': 'å† å†›', 'ç¬¬ä¸€å': 'å† å†›', '1': 'å† å†›', '1st': 'å† å†›',
            'å‰ä¸€': 'å† å†›',
            'äºšå†›': 'äºšå†›', 'ç¬¬2å': 'äºšå†›', 'ç¬¬äºŒå': 'äºšå†›', '2': 'äºšå†›', '2nd': 'äºšå†›',
            'å­£å†›': 'ç¬¬ä¸‰å', 'ç¬¬3å': 'ç¬¬ä¸‰å', 'ç¬¬ä¸‰å': 'ç¬¬ä¸‰å', 'ä¸‰å': 'ç¬¬ä¸‰å', '3': 'ç¬¬ä¸‰å', '3rd': 'ç¬¬ä¸‰å',
            'ç¬¬4å': 'ç¬¬å››å', 'ç¬¬å››å': 'ç¬¬å››å', 'å››å': 'ç¬¬å››å', '4': 'ç¬¬å››å', '4th': 'ç¬¬å››å',
            'ç¬¬5å': 'ç¬¬äº”å', 'ç¬¬äº”å': 'ç¬¬äº”å', 'äº”å': 'ç¬¬äº”å', '5': 'ç¬¬äº”å', '5th': 'ç¬¬äº”å',
            'ç¬¬6å': 'ç¬¬å…­å', 'ç¬¬å…­å': 'ç¬¬å…­å', 'å…­å': 'ç¬¬å…­å', '6': 'ç¬¬å…­å', '6th': 'ç¬¬å…­å',
            'ç¬¬7å': 'ç¬¬ä¸ƒå', 'ç¬¬ä¸ƒå': 'ç¬¬ä¸ƒå', 'ä¸ƒå': 'ç¬¬ä¸ƒå', '7': 'ç¬¬ä¸ƒå', '7th': 'ç¬¬ä¸ƒå',
            'ç¬¬8å': 'ç¬¬å…«å', 'ç¬¬å…«å': 'ç¬¬å…«å', 'å…«å': 'ç¬¬å…«å', '8': 'ç¬¬å…«å', '8th': 'ç¬¬å…«å',
            'ç¬¬9å': 'ç¬¬ä¹å', 'ç¬¬ä¹å': 'ç¬¬ä¹å', 'ä¹å': 'ç¬¬ä¹å', '9': 'ç¬¬ä¹å', '9th': 'ç¬¬ä¹å',
            'ç¬¬10å': 'ç¬¬åå', 'ç¬¬åå': 'ç¬¬åå', 'åå': 'ç¬¬åå', '10': 'ç¬¬åå', '10th': 'ç¬¬åå'
        }
        
        position = position.strip()
        
        # ç›´æ¥æ˜ å°„
        if position in position_mapping:
            return position_mapping[position]
        
        # æ¨¡ç³ŠåŒ¹é… - å¢å¼ºé€»è¾‘
        for key, value in position_mapping.items():
            if key in position:
                return value
        
        # å¤„ç†å¸¦å†’å·çš„æ ¼å¼ï¼ˆå¦‚"ç¬¬ä¹å:"ï¼‰
        if position.endswith(':'):
            clean_position = position[:-1].strip()
            if clean_position in position_mapping:
                return position_mapping[clean_position]
            for key, value in position_mapping.items():
                if key in clean_position:
                    return value
        
        # å¦‚æœè¿˜æ˜¯æ— æ³•è¯†åˆ«ï¼Œå°è¯•æ›´å®½æ¾çš„åŒ¹é…
        position_lower = position.lower()
        if 'ä¹' in position_lower or '9' in position_lower:
            return 'ç¬¬ä¹å'
        
        return position  # è¿”å›åŸä½ç½®è€Œä¸æ˜¯æœªçŸ¥

    def parse_3d_content(self, content):
        """è§£æ3DæŠ•æ³¨å†…å®¹ - å¢å¼ºç«–çº¿æ ¼å¼æ”¯æŒ"""
        content_str = str(content).strip()
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ç«–çº¿åˆ†éš”æ ¼å¼
        if '|' in content_str and any(char.isdigit() or char == '_' or char == ',' for char in content_str):
            vertical_result = ContentParser.parse_3d_vertical_format(content_str)
            if any(vertical_result.values()):  # å¦‚æœæœ‰è§£æç»“æœ
                return vertical_result
        
        # åŸæœ‰çš„è§£æé€»è¾‘
        return ContentParser.parse_positional_bets(content, ['ç™¾ä½', 'åä½', 'ä¸ªä½'])
    
    def parse_lhc_special_content(self, content):
        """è§£æå…­åˆå½©ç‰¹æ®Šç©æ³•å†…å®¹ï¼ŒæŒ‰ç…§ç©æ³•-æŠ•æ³¨å†…å®¹æ ¼å¼è§£æ"""
        content_str = str(content)
        
        # æ–°çš„è§£æé€»è¾‘ï¼šæŒ‰ç…§"ç©æ³•-æŠ•æ³¨å†…å®¹"æ ¼å¼è§£æ
        if '-' in content_str:
            parts = content_str.split('-', 1)  # åªåˆ†å‰²ç¬¬ä¸€ä¸ª"-"
            play_method = parts[0].strip()      # ç©æ³•éƒ¨åˆ†
            bet_content = parts[1].strip()      # æŠ•æ³¨å†…å®¹éƒ¨åˆ†
            
            # è°ƒè¯•ä¿¡æ¯ - æ˜¾ç¤ºè§£æè¿‡ç¨‹
            
            # è¿”å›æŠ•æ³¨å†…å®¹éƒ¨åˆ†ï¼Œè¿™æ‰æ˜¯å®é™…çš„ä¸‹æ³¨å†…å®¹
            return bet_content
        else:
            # å¦‚æœæ²¡æœ‰"-"ï¼Œæ•´ä¸ªå†…å®¹ä½œä¸ºæŠ•æ³¨å†…å®¹
            return content_str.strip()
    
    def extract_lhc_two_sides_content(self, content):
        """ä¸“é—¨æå–å…­åˆå½©ä¸¤é¢ç©æ³•çš„å„ç§æŠ•æ³¨ç±»å‹"""
        content_str = str(content)
        result = {
            'normal_size': set(),    # æ™®é€šå¤§å°ï¼šå¤§/å°
            'tail_size': set(),      # å°¾å¤§å°ï¼šå°¾å¤§/å°¾å°
            'parity': set(),         # å•åŒï¼šå•/åŒ
            'sum_parity': set(),     # åˆæ•°å•åŒï¼šåˆå•/åˆåŒ
            'range_bet': set(),      # åŒºé—´ï¼š1-10,11-20,21-30,31-40,41-49
            'animal_type': set(),    # å®¶ç¦½é‡å…½ï¼šå®¶ç¦½/é‡å…½
            'zodiac': set(),         # ç”Ÿè‚–
            'wave': set(),           # æ³¢è‰²ï¼šçº¢æ³¢/è“æ³¢/ç»¿æ³¢
            'other': set()           # å…¶ä»–
        }
    
        # é¦–å…ˆè§£æç©æ³•-æŠ•æ³¨å†…å®¹æ ¼å¼
        clean_content = content_str
        if '-' in content_str:
            parts = content_str.split('-', 1)
            clean_content = parts[1].strip()  # åªä½¿ç”¨æŠ•æ³¨å†…å®¹éƒ¨åˆ†
    
        # æ–°å¢ï¼šç‰¹å•ã€ç‰¹åŒæ˜ å°„åˆ°æ™®é€šå•åŒ
        if 'ç‰¹å•' in clean_content:
            result['parity'].add('å•')
        if 'ç‰¹åŒ' in clean_content:
            result['parity'].add('åŒ')
        
        # æ–°å¢ï¼šç‰¹å®¶è‚–æ˜ å°„åˆ°å®¶ç¦½ï¼Œç‰¹é‡è‚–æ˜ å°„åˆ°é‡å…½
        if 'ç‰¹å®¶è‚–' in clean_content or 'å®¶è‚–' in clean_content:
            result['animal_type'].add('å®¶ç¦½')
        if 'ç‰¹é‡è‚–' in clean_content or 'é‡è‚–' in clean_content:
            result['animal_type'].add('é‡å…½')
    
        # æ³¢è‰²æ£€æµ‹
        if 'çº¢æ³¢' in clean_content and 'çº¢æ³¢-' not in content_str:
            result['wave'].add('çº¢æ³¢')
        if 'è“æ³¢' in clean_content and 'è“æ³¢-' not in content_str:
            result['wave'].add('è“æ³¢')
        if 'ç»¿æ³¢' in clean_content and 'ç»¿æ³¢-' not in content_str:
            result['wave'].add('ç»¿æ³¢')
    
        # æ™®é€šå¤§å°æ£€æµ‹
        if 'å¤§' in clean_content and 'å°¾å¤§' not in clean_content and 'åˆå¤§' not in clean_content and 'ç‰¹å¤§' not in clean_content:
            result['normal_size'].add('å¤§')
        if 'å°' in clean_content and 'å°¾å°' not in clean_content and 'åˆå°' not in clean_content and 'ç‰¹å°' not in clean_content:
            result['normal_size'].add('å°')
    
        # å°¾å¤§å°æ£€æµ‹
        if 'å°¾å¤§' in clean_content:
            result['tail_size'].add('å°¾å¤§')
        if 'å°¾å°' in clean_content:
            result['tail_size'].add('å°¾å°')
    
        # å•åŒæ£€æµ‹ï¼ˆç‰¹å•ç‰¹åŒå·²ç»åœ¨ä¸Šé¢å¤„ç†äº†ï¼Œè¿™é‡Œå¤„ç†æ™®é€šå•åŒï¼‰
        if 'å•' in clean_content and 'åˆå•' not in clean_content and 'ç‰¹å•' not in clean_content:
            result['parity'].add('å•')
        if 'åŒ' in clean_content and 'åˆåŒ' not in clean_content and 'ç‰¹åŒ' not in clean_content:
            result['parity'].add('åŒ')
    
        # åˆæ•°å•åŒæ£€æµ‹
        if 'åˆå•' in clean_content:
            result['sum_parity'].add('åˆå•')
        if 'åˆåŒ' in clean_content:
            result['sum_parity'].add('åˆåŒ')
    
        # åŒºé—´æ£€æµ‹
        range_keywords = ['1-10', '11-20', '21-30', '31-40', '41-49']
        for range_keyword in range_keywords:
            if range_keyword in clean_content:
                result['range_bet'].add(range_keyword)
    
        # å®¶ç¦½é‡å…½æ£€æµ‹ï¼ˆç‰¹å®¶è‚–ç‰¹é‡è‚–å·²ç»åœ¨ä¸Šé¢å¤„ç†äº†ï¼Œè¿™é‡Œå¤„ç†æ™®é€šçš„å®¶ç¦½é‡å…½ï¼‰
        if 'å®¶ç¦½' in clean_content:
            result['animal_type'].add('å®¶ç¦½')
        if 'é‡å…½' in clean_content:
            result['animal_type'].add('é‡å…½')
    
        # ç”Ÿè‚–æ£€æµ‹
        zodiacs = ['é¼ ', 'ç‰›', 'è™', 'å…”', 'é¾™', 'è›‡', 'é©¬', 'ç¾Š', 'çŒ´', 'é¸¡', 'ç‹—', 'çŒª']
        for zodiac in zodiacs:
            if zodiac in clean_content:
                result['zodiac'].add(zodiac)
    
        # æ¸…ç†ç©ºé›†åˆ
        for key in list(result.keys()):
            if not result[key]:
                del result[key]
    
        return result

# ==================== ç©æ³•åˆ†ç±»ç»Ÿä¸€ ====================
class PlayCategoryNormalizer:
    def __init__(self):
        self.category_mapping = self._create_category_mapping()
    
    def _create_category_mapping(self):
        """åˆ›å»ºç©æ³•åˆ†ç±»æ˜ å°„çš„å®Œæ•´æ˜ å°„"""
        mapping = {
            # å¿«ä¸‰ç©æ³•
            'å’Œå€¼': 'å’Œå€¼',
            'å’Œå€¼_å¤§å°å•åŒ': 'å’Œå€¼',
            'ä¸¤é¢': 'ä¸¤é¢',
            'äºŒä¸åŒå·': 'äºŒä¸åŒå·',
            'ä¸‰ä¸åŒå·': 'ä¸‰ä¸åŒå·',
            # æ³¨é‡Šæ‰åŒå·ç©æ³•
            # 'äºŒåŒå·': 'äºŒåŒå·',
            # 'ä¸‰åŒå·': 'ä¸‰åŒå·',
            'ç‹¬èƒ†': 'ç‹¬èƒ†',
            # æ–°å¢ç‚¹æ•°æ˜ å°„
            'ç‚¹æ•°': 'å’Œå€¼',
            # å¢å¼ºä¸‰å†›æ˜ å°„
            'ä¸‰å†›': 'ç‹¬èƒ†',
            'ä¸‰è»': 'ç‹¬èƒ†',
            'ä¸‰å†›_å¤§å°': 'ç‹¬èƒ†',
            'ä¸‰å†›_å•åŒ': 'ç‹¬èƒ†',
            
            # å…­åˆå½©ç©æ³•å®Œæ•´æ˜ å°„ - å°¾æ•°ç‹¬ç«‹æ˜ å°„
            'ç‰¹ç ': 'ç‰¹ç ',
            'æ­£1ç‰¹': 'æ­£1ç‰¹',
            'æ­£ç ç‰¹_æ­£ä¸€ç‰¹': 'æ­£1ç‰¹',
            'æ­£2ç‰¹': 'æ­£2ç‰¹',
            'æ­£ç ç‰¹_æ­£äºŒç‰¹': 'æ­£2ç‰¹',
            'æ­£3ç‰¹': 'æ­£3ç‰¹',
            'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹': 'æ­£3ç‰¹',
            'æ­£4ç‰¹': 'æ­£4ç‰¹',
            'æ­£ç ç‰¹_æ­£å››ç‰¹': 'æ­£4ç‰¹',
            'æ­£5ç‰¹': 'æ­£5ç‰¹',
            'æ­£ç ç‰¹_æ­£äº”ç‰¹': 'æ­£5ç‰¹',
            'æ­£6ç‰¹': 'æ­£6ç‰¹',
            'æ­£ç ç‰¹_æ­£å…­ç‰¹': 'æ­£6ç‰¹',
            'æ­£ç ': 'æ­£ç ',
            'æ­£ç‰¹': 'æ­£ç‰¹',
            'æ­£ç›ç‰¹': 'æ­£ç‰¹',
            'æ­£ç 1-6': 'æ­£ç ',

            # å…­åˆå½©æ­£ç å¢å¼ºæ˜ å°„
            'æ­£ç ä¸€': 'æ­£ç ä¸€',
            'æ­£ç äºŒ': 'æ­£ç äºŒ', 
            'æ­£ç ä¸‰': 'æ­£ç ä¸‰',
            'æ­£ç å››': 'æ­£ç å››',
            'æ­£ç äº”': 'æ­£ç äº”',
            'æ­£ç å…­': 'æ­£ç å…­',
            'æ­£1': 'æ­£ç ä¸€',
            'æ­£2': 'æ­£ç äºŒ',
            'æ­£3': 'æ­£ç ä¸‰', 
            'æ­£4': 'æ­£ç å››',
            'æ­£5': 'æ­£ç äº”',
            'æ­£6': 'æ­£ç å…­',
            'æ­£ä¸€': 'æ­£ç ä¸€',
            'æ­£äºŒ': 'æ­£ç äºŒ',
            'æ­£ä¸‰': 'æ­£ç ä¸‰',
            'æ­£å››': 'æ­£ç å››',
            'æ­£äº”': 'æ­£ç äº”',
            'æ­£å…­': 'æ­£ç å…­',
            
            # å°¾æ•°ç›¸å…³ç©æ³•ç‹¬ç«‹æ˜ å°„
            'å°¾æ•°': 'å°¾æ•°',
            'å°¾æ•°_å¤´å°¾æ•°': 'å°¾æ•°_å¤´å°¾æ•°',  # ç‹¬ç«‹æ˜ å°„
            'ç‰¹å°¾': 'ç‰¹å°¾',              # ç‹¬ç«‹æ˜ å°„
            'å…¨å°¾': 'å…¨å°¾',              # ç‹¬ç«‹æ˜ å°„
            'å°¾æ•°_æ­£ç‰¹å°¾æ•°': 'å°¾æ•°',
            
            # å…¶ä»–å…­åˆå½©ç©æ³•
            'ç‰¹è‚–': 'ç‰¹è‚–',
            'ç”Ÿè‚–_ç‰¹è‚–': 'ç‰¹è‚–',
            'å¹³ç‰¹': 'å¹³ç‰¹',
            'ç”Ÿè‚–_æ­£è‚–': 'å¹³ç‰¹',
            'ç”Ÿè‚–_ä¸€è‚–': 'ä¸€è‚–',
            'è¿è‚–': 'è¿è‚–',
            'è¿å°¾': 'è¿å°¾',
            'é¾™è™': 'é¾™è™',
            'äº”è¡Œ': 'äº”è¡Œ',

            # è¿è‚–ç©æ³•æ˜ å°„
            'äºŒè¿è‚–': 'äºŒè¿è‚–',
            'ä¸‰è¿è‚–': 'ä¸‰è¿è‚–', 
            'å››è¿è‚–': 'å››è¿è‚–',
            'äº”è¿è‚–': 'äº”è¿è‚–',
            'äºŒè¿è‚–(ä¸­)': 'äºŒè¿è‚–',
            'ä¸‰è¿è‚–(ä¸­)': 'ä¸‰è¿è‚–',
            'å››è¿è‚–(ä¸­)': 'å››è¿è‚–', 
            'äº”è¿è‚–(ä¸­)': 'äº”è¿è‚–',
            'è¿è‚–è¿å°¾_äºŒè¿è‚–': 'äºŒè¿è‚–',
            'è¿è‚–è¿å°¾_ä¸‰è¿è‚–': 'ä¸‰è¿è‚–',
            'è¿è‚–è¿å°¾_å››è¿è‚–': 'å››è¿è‚–',
            'è¿è‚–è¿å°¾_äº”è¿è‚–': 'äº”è¿è‚–',
            'è¿è‚–': 'è¿è‚–',  # é€šç”¨è¿è‚–
            
            # è¿å°¾ç©æ³•æ˜ å°„
            'äºŒè¿å°¾': 'äºŒè¿å°¾',
            'ä¸‰è¿å°¾': 'ä¸‰è¿å°¾',
            'å››è¿å°¾': 'å››è¿å°¾',
            'äº”è¿å°¾': 'äº”è¿å°¾',
            'è¿è‚–è¿å°¾_äºŒè¿å°¾': 'äºŒè¿å°¾',
            'è¿è‚–è¿å°¾_ä¸‰è¿å°¾': 'ä¸‰è¿å°¾',
            'è¿è‚–è¿å°¾_å››è¿å°¾': 'å››è¿å°¾',
            'è¿è‚–è¿å°¾_äº”è¿å°¾': 'äº”è¿å°¾',
            'è¿å°¾': 'è¿å°¾',  # é€šç”¨è¿å°¾

            # æ³¢è‰²ç›¸å…³ç©æ³•
            'è‰²æ³¢': 'è‰²æ³¢',
            'ä¸ƒè‰²æ³¢': 'è‰²æ³¢',
            'æ³¢è‰²': 'è‰²æ³¢',

            #åŠæ³¢ç›¸å…³ç©æ³•æ˜ å°„
            'åŠæ³¢': 'åŠæ³¢',
            'è“æ³¢': 'åŠæ³¢',
            'ç»¿æ³¢': 'åŠæ³¢',
            'çº¢æ³¢': 'åŠæ³¢',
            'åŠæ³¢_çº¢æ³¢': 'åŠæ³¢',
            'åŠæ³¢_è“æ³¢': 'åŠæ³¢',
            'åŠæ³¢_ç»¿æ³¢': 'åŠæ³¢',

            # æ­£ç 1-6ç›¸å…³æ˜ å°„
            'æ­£ç 1-6': 'æ­£ç 1-6',
            'æ­£ç 1~6': 'æ­£ç 1-6',
            'æ­£ç 1-6ç‰¹': 'æ­£ç 1-6',
            'æ­£ç 1~6ç‰¹': 'æ­£ç 1-6',

            # 3Dç³»åˆ—ç©æ³•æ˜ å°„
            'ä¸¤é¢': 'ä¸¤é¢',
            'å¤§å°å•åŒ': 'ä¸¤é¢',
            'ç™¾ä½': 'ç™¾ä½',
            'åä½': 'åä½', 
            'ä¸ªä½': 'ä¸ªä½',
            'ç™¾å': 'ç™¾å',
            'ç™¾ä¸ª': 'ç™¾ä¸ª',
            'åä¸ª': 'åä¸ª',
            'ç™¾åä¸ª': 'ç™¾åä¸ª',
            'å®šä½èƒ†': 'å®šä½èƒ†',
            'å®šä½èƒ†_ç™¾ä½': 'å®šä½èƒ†_ç™¾ä½',
            'å®šä½èƒ†_åä½': 'å®šä½èƒ†_åä½',
            'å®šä½èƒ†_ä¸ªä½': 'å®šä½èƒ†_ä¸ªä½',
            'ç™¾ä½(å®šä½)': 'å®šä½èƒ†_ç™¾ä½',
            'åä½(å®šä½)': 'å®šä½èƒ†_åä½',
            'ä¸ªä½(å®šä½)': 'å®šä½èƒ†_ä¸ªä½',
            
            # æ—¶æ—¶å½©ç©æ³•
            'æ–—ç‰›': 'æ–—ç‰›',
            '1-5çƒ': '1-5çƒ',
            'ç¬¬1çƒ': 'ç¬¬1çƒ',
            'ç¬¬2çƒ': 'ç¬¬2çƒ',
            'ç¬¬3çƒ': 'ç¬¬3çƒ',
            'ç¬¬4çƒ': 'ç¬¬4çƒ',
            'ç¬¬5çƒ': 'ç¬¬5çƒ',
            'æ€»å’Œ': 'æ€»å’Œ',
            'æ­£ç ': 'æ­£ç ',
            'æ­£ç ç‰¹': 'æ­£ç ',
            'æ­£ç _ç‰¹': 'æ­£ç ',
            'å®šä½èƒ†': 'å®šä½èƒ†',
            'å®šä½_ä¸‡ä½': 'å®šä½_ä¸‡ä½',
            'å®šä½_åƒä½': 'å®šä½_åƒä½',
            'å®šä½_ç™¾ä½': 'å®šä½_ç™¾ä½',
            'å®šä½_åä½': 'å®šä½_åä½',
            'å®šä½_ä¸ªä½': 'å®šä½_ä¸ªä½',
            'ä¸¤é¢': 'ä¸¤é¢',
            
            # PKæ‹¾/èµ›è½¦ç©æ³•
            'å‰ä¸€': 'å† å†›',  # å‰ä¸€å°±æ˜¯å† å†›
            'å®šä½èƒ†': 'å®šä½èƒ†',
            '1-5å': '1-5å',
            '6-10å': '6-10å',
            'å† å†›': 'å† å†›',
            'äºšå†›': 'äºšå†›',
            'å­£å†›': 'ç¬¬ä¸‰å',
            'ç¬¬3å': 'ç¬¬ä¸‰å',
            'ç¬¬4å': 'ç¬¬å››å',
            'ç¬¬5å': 'ç¬¬äº”å',
            'ç¬¬6å': 'ç¬¬å…­å',
            'ç¬¬7å': 'ç¬¬ä¸ƒå',
            'ç¬¬8å': 'ç¬¬å…«å',
            'ç¬¬9å': 'ç¬¬ä¹å',
            'ç¬¬10å': 'ç¬¬åå',
            'åŒé¢': 'ä¸¤é¢',
            'å† äºšå’Œ': 'å† äºšå’Œ',
            'å† äºšå’Œ_å¤§å°å•åŒ': 'å† äºšå’Œ_å¤§å°å•åŒ',
            'å† äºšå’Œ_å’Œå€¼': 'å† äºšå’Œ_å’Œå€¼',
            
            # å¤§å°å•åŒç‹¬ç«‹ç©æ³•
            'å¤§å°_å† å†›': 'å¤§å°_å† å†›',
            'å¤§å°_äºšå†›': 'å¤§å°_äºšå†›',
            'å¤§å°_å­£å†›': 'å¤§å°_å­£å†›',
            'å•åŒ_å† å†›': 'å•åŒ_å† å†›',
            'å•åŒ_äºšå†›': 'å•åŒ_äºšå†›',
            'å•åŒ_å­£å†›': 'å•åŒ_å­£å†›',
            
            # é¾™è™ç‹¬ç«‹ç©æ³•
            'é¾™è™_å† å†›': 'é¾™è™_å† å†›',
            'é¾™è™_å†  å†›': 'é¾™è™_å† å†›',
            'é¾™è™_äºšå†›': 'é¾™è™_äºšå†›',
            'é¾™è™_äºš å†›': 'é¾™è™_äºšå†›',
            'é¾™è™_å­£å†›': 'é¾™è™_å­£å†›',
            'é¾™è™_å­£ å†›': 'é¾™è™_å­£å†›',

            # PK10é¾™è™å¢å¼ºæ˜ å°„
            'é¾™è™_å† å†›': 'é¾™è™_å† å†›',
            'é¾™è™_äºšå†›': 'é¾™è™_äºšå†›',
            'é¾™è™_å­£å†›': 'é¾™è™_å­£å†›',
            'å† å†›é¾™è™': 'é¾™è™_å† å†›',
            'äºšå†›é¾™è™': 'é¾™è™_äºšå†›',
            'å­£å†›é¾™è™': 'é¾™è™_å­£å†›',
            'å† äºšé¾™è™': 'é¾™è™_å† å†›',  # å† äºšé¾™è™é€šå¸¸æŒ‡å† å†›ä½ç½®
            'é¾™è™å† å†›': 'é¾™è™_å† å†›',
            'é¾™è™äºšå†›': 'é¾™è™_äºšå†›',
            'é¾™è™å­£å†›': 'é¾™è™_å­£å†›',
            
            # å®šä½èƒ†ç»†åˆ†
            'å®šä½èƒ†_ç¬¬1~5å': 'å®šä½èƒ†_ç¬¬1~5å',
            'å®šä½èƒ†_ç¬¬6~10å': 'å®šä½èƒ†_ç¬¬6~10å',
            'å®šä½èƒ†_1~5': 'å®šä½èƒ†_ç¬¬1~5å',
            'å®šä½èƒ†_6~10': 'å®šä½èƒ†_ç¬¬6~10å',
            'å®šä½èƒ†_1-5': 'å®šä½èƒ†_ç¬¬1~5å', 
            'å®šä½èƒ†_6-10': 'å®šä½èƒ†_ç¬¬6~10å',
            'å®šä½èƒ†_1~5å': 'å®šä½èƒ†_ç¬¬1~5å',
            'å®šä½èƒ†_6~10å': 'å®šä½èƒ†_ç¬¬6~10å',
            
            # å¤§å°å•åŒç©æ³•å˜ä½“
            'å¤§å°å•åŒ': 'ä¸¤é¢',
            'å¤§å°': 'å¤§å°',
            'å•åŒ': 'å•åŒ',
            
            # é¾™è™ç©æ³•å˜ä½“
            'é¾™è™æ–—': 'é¾™è™',
            'å† äºšé¾™è™': 'é¾™è™_å† å†›',
            'å† å†›é¾™è™': 'é¾™è™_å† å†›',
            
            # æ—¶æ—¶å½©å®šä½èƒ†å˜ä½“
            'å®šä½_ä¸‡ä½': 'å®šä½_ä¸‡ä½',
            'å®šä½_åƒä½': 'å®šä½_åƒä½', 
            'å®šä½_ç™¾ä½': 'å®šä½_ç™¾ä½',
            'å®šä½_åä½': 'å®šä½_åä½',
            'å®šä½_ä¸ªä½': 'å®šä½_ä¸ªä½',
            'ä¸‡ä½': 'å®šä½_ä¸‡ä½',
            'åƒä½': 'å®šä½_åƒä½',
            'ç™¾ä½': 'å®šä½_ç™¾ä½',
            'åä½': 'å®šä½_åä½',
            'ä¸ªä½': 'å®šä½_ä¸ªä½',
            
            # å…­åˆå½©ç©æ³•å˜ä½“
            'ç‰¹ç A': 'ç‰¹ç ',
            'ç‰¹ç B': 'ç‰¹ç ', 
            'æ­£ç A': 'æ­£ç ',
            'æ­£ç B': 'æ­£ç ',
            'æ­£ç 1': 'æ­£1ç‰¹',
            'æ­£ç 2': 'æ­£2ç‰¹',
            'æ­£ç 3': 'æ­£3ç‰¹',
            'æ­£ç 4': 'æ­£4ç‰¹',
            'æ­£ç 5': 'æ­£5ç‰¹',
            'æ­£ç 6': 'æ­£6ç‰¹',
            
            # ä¸‰è‰²å½©
            'æ­£ç ': 'æ­£ç ',
            'ä¸¤é¢': 'ä¸¤é¢',
            'è‰²æ³¢': 'è‰²æ³¢',
            'ç‰¹ç ': 'ç‰¹ç '
        }
        return mapping

    def normalize_category_enhanced(self, category, content):
        """å¢å¼ºç‰ˆç©æ³•åˆ†ç±»æ ‡å‡†åŒ– - ç»“åˆå†…å®¹ä¿¡æ¯"""
        category_str = str(category).strip()
        content_str = str(content)
        
        # é¦–å…ˆä½¿ç”¨åŸºæœ¬æ ‡å‡†åŒ–
        basic_normalized = self.normalize_category(category_str)
        
        # å¦‚æœåŸºæœ¬æ ‡å‡†åŒ–ç»“æœä¸å¤Ÿå…·ä½“ï¼Œå°è¯•ä»å†…å®¹ä¸­æ¨æ–­
        if basic_normalized in ['æ­£ç ', 'æ­£ç‰¹', 'é¾™è™']:
            # ä»å†…å®¹ä¸­æå–æ›´å…·ä½“çš„ä¿¡æ¯
            if 'æ­£ç ä¸€' in content_str or 'æ­£1' in content_str:
                return 'æ­£ç ä¸€'
            elif 'æ­£ç äºŒ' in content_str or 'æ­£2' in content_str:
                return 'æ­£ç äºŒ'
            elif 'æ­£ç ä¸‰' in content_str or 'æ­£3' in content_str:
                return 'æ­£ç ä¸‰'
            elif 'æ­£ç å››' in content_str or 'æ­£4' in content_str:
                return 'æ­£ç å››'
            elif 'æ­£ç äº”' in content_str or 'æ­£5' in content_str:
                return 'æ­£ç äº”'
            elif 'æ­£ç å…­' in content_str or 'æ­£6' in content_str:
                return 'æ­£ç å…­'
            elif 'å† å†›' in content_str or 'ç¬¬1å' in content_str:
                return 'é¾™è™_å† å†›'
            elif 'äºšå†›' in content_str or 'ç¬¬2å' in content_str:
                return 'é¾™è™_äºšå†›'
            elif 'å­£å†›' in content_str or 'ç¬¬3å' in content_str:
                return 'é¾™è™_å­£å†›'
        
        return basic_normalized
    
    def normalize_category(self, category):
        """ç»Ÿä¸€ç©æ³•åˆ†ç±»åç§°"""
        category_str = str(category).strip()
        
        # ç›´æ¥æ˜ å°„
        if category_str in self.category_mapping:
            return self.category_mapping[category_str]
        
        # å…³é”®è¯åŒ¹é…
        for key, value in self.category_mapping.items():
            if key in category_str:
                return value
        
        category_lower = category_str.lower()
        
        # PK10/èµ›è½¦æ™ºèƒ½åŒ¹é… - è¡¥å……æ›´å¤šå˜ä½“
        if any(word in category_lower for word in ['å®šä½èƒ†_ç¬¬1~5å', 'å®šä½èƒ†1~5', 'å®šä½èƒ†1-5']):
            return 'å®šä½èƒ†_ç¬¬1~5å'
        elif any(word in category_lower for word in ['å®šä½èƒ†_ç¬¬6~10å', 'å®šä½èƒ†6~10', 'å®šä½èƒ†6-10']):
            return 'å®šä½èƒ†_ç¬¬6~10å'
        elif any(word in category_lower for word in ['1-5å', '1~5å', '1-5', '1~5']):
            return '1-5å'
        elif any(word in category_lower for word in ['6-10å', '6~10å', '6-10', '6~10']):
            return '6-10å'
        elif any(word in category_lower for word in ['å† å†›', 'ç¬¬ä¸€å', 'ç¬¬1å', '1st']):
            return 'å† å†›'
        elif any(word in category_lower for word in ['äºšå†›', 'ç¬¬äºŒå', 'ç¬¬2å', '2nd']):
            return 'äºšå†›'
        elif any(word in category_lower for word in ['ç¬¬ä¸‰å', 'ç¬¬3å', 'å­£å†›', '3rd']):
            return 'ç¬¬ä¸‰å'
        elif any(word in category_lower for word in ['ç¬¬å››å', 'ç¬¬4å', '4th']):
            return 'ç¬¬å››å'
        elif any(word in category_lower for word in ['ç¬¬äº”å', 'ç¬¬5å', '5th']):
            return 'ç¬¬äº”å'
        elif any(word in category_lower for word in ['ç¬¬å…­å', 'ç¬¬6å', '6th']):
            return 'ç¬¬å…­å'
        elif any(word in category_lower for word in ['ç¬¬ä¸ƒå', 'ç¬¬7å', '7th']):
            return 'ç¬¬ä¸ƒå'
        elif any(word in category_lower for word in ['ç¬¬å…«å', 'ç¬¬8å', '8th']):
            return 'ç¬¬å…«å'
        elif any(word in category_lower for word in ['ç¬¬ä¹å', 'ç¬¬9å', '9th']):
            return 'ç¬¬ä¹å'
        elif any(word in category_lower for word in ['ç¬¬åå', 'ç¬¬10å', '10th']):
            return 'ç¬¬åå'
        elif any(word in category_lower for word in ['å‰ä¸€']):
            return 'å† å†›'  # å‰ä¸€å°±æ˜¯å† å†›
        
        # æ—¶æ—¶å½©å®šä½èƒ†æ™ºèƒ½åŒ¹é…
        elif any(word in category_lower for word in ['ä¸‡ä½', 'ç¬¬ä¸€ä½', 'ç¬¬ä¸€çƒ']):
            return 'å®šä½_ä¸‡ä½'
        elif any(word in category_lower for word in ['åƒä½', 'ç¬¬äºŒä½', 'ç¬¬äºŒçƒ']):
            return 'å®šä½_åƒä½'
        elif any(word in category_lower for word in ['ç™¾ä½', 'ç¬¬ä¸‰ä½', 'ç¬¬ä¸‰çƒ']):
            return 'å®šä½_ç™¾ä½'
        elif any(word in category_lower for word in ['åä½', 'ç¬¬å››ä½', 'ç¬¬å››çƒ']):
            return 'å®šä½_åä½'
        elif any(word in category_lower for word in ['ä¸ªä½', 'ç¬¬äº”ä½', 'ç¬¬äº”çƒ']):
            return 'å®šä½_ä¸ªä½'
        elif any(word in category_lower for word in ['å®šä½èƒ†']):
            return 'å®šä½èƒ†'
        
        # å…­åˆå½©æ™ºèƒ½åŒ¹é…
        elif any(word in category_lower for word in ['ç‰¹ç ']):
            return 'ç‰¹ç '
        elif any(word in category_lower for word in ['æ­£ç ']):
            return 'æ­£ç '
        elif any(word in category_lower for word in ['æ­£ç‰¹', 'æ­£ç›ç‰¹']):
            return 'æ­£ç‰¹'
        elif any(word in category_lower for word in ['å°¾æ•°']):
            return 'å°¾æ•°'
        elif any(word in category_lower for word in ['å¹³ç‰¹']):
            return 'å¹³ç‰¹'
        elif any(word in category_lower for word in ['ç‰¹è‚–']):
            return 'ç‰¹è‚–'
        elif any(word in category_lower for word in ['ä¸€è‚–']):
            return 'ä¸€è‚–'
        elif any(word in category_lower for word in ['è¿è‚–']):
            return 'è¿è‚–'
        elif any(word in category_lower for word in ['è¿å°¾']):
            return 'è¿å°¾'
        elif any(word in category_lower for word in ['é¾™è™']):
            return 'é¾™è™'
        elif any(word in category_lower for word in ['äº”è¡Œ']):
            return 'äº”è¡Œ'
        elif any(word in category_lower for word in ['è‰²æ³¢', 'ä¸ƒè‰²æ³¢', 'æ³¢è‰²']):  # ç»Ÿä¸€è‰²æ³¢è¯†åˆ«
            return 'è‰²æ³¢'
        elif any(word in category_lower for word in ['åŠæ³¢']):
            return 'åŠæ³¢'
        
        # å¿«ä¸‰æ™ºèƒ½åŒ¹é… - å¢å¼ºä¸‰å†›è¯†åˆ«
        elif any(word in category_lower for word in ['å’Œå€¼', 'ç‚¹æ•°']):
            return 'å’Œå€¼'
        elif any(word in category_lower for word in ['ç‹¬èƒ†', 'ä¸‰å†›', 'ä¸‰è»']):  # å¢å¼ºä¸‰å†›è¯†åˆ«
            return 'ç‹¬èƒ†'
        elif any(word in category_lower for word in ['äºŒä¸åŒå·']):
            return 'äºŒä¸åŒå·'
        elif any(word in category_lower for word in ['ä¸‰ä¸åŒå·']):
            return 'ä¸‰ä¸åŒå·'
        
        return category_str

    def normalize_category_comprehensive(self, category, content, lottery_type):
        """ç»¼åˆè€ƒè™‘ç©æ³•å’Œå†…å®¹çš„åˆ†ç±»æ ‡å‡†åŒ– - å¢å¼ºç©ºæ ¼å¤„ç†"""
        # ç»Ÿä¸€å¤„ç†ç©ºæ ¼
        category_str = normalize_spaces(category)
        content_str = normalize_spaces(content)
        
        # é¦–å…ˆä½¿ç”¨åŸºæœ¬æ ‡å‡†åŒ–
        basic_normalized = self.normalize_category(category_str)
        
        # å¯¹äºå…­åˆå½©ï¼Œè¿›è¡Œæ›´ç²¾ç¡®çš„åˆ†ç±»
        if lottery_type == 'LHC':
            # å¤„ç†æ­£ç 1-6æ ¼å¼
            if basic_normalized == 'æ­£ç 1-6' and '_' in category_str:
                parts = category_str.split('_')
                if len(parts) > 1:
                    position_part = normalize_spaces(parts[1])
                    # æ˜ å°„åˆ°å…·ä½“çš„æ­£ç ä½ç½®
                    if 'æ­£ç ä¸€' in position_part or 'æ­£1' in position_part:
                        return 'æ­£ç ä¸€'
                    elif 'æ­£ç äºŒ' in position_part or 'æ­£2' in position_part:
                        return 'æ­£ç äºŒ'
                    elif 'æ­£ç ä¸‰' in position_part or 'æ­£3' in position_part:
                        return 'æ­£ç ä¸‰'
                    elif 'æ­£ç å››' in position_part or 'æ­£4' in position_part:
                        return 'æ­£ç å››'
                    elif 'æ­£ç äº”' in position_part or 'æ­£5' in position_part:
                        return 'æ­£ç äº”'
                    elif 'æ­£ç å…­' in position_part or 'æ­£6' in position_part:
                        return 'æ­£ç å…­'
            
            # å¤„ç†æ­£ç‰¹ - ä¿æŒåŸæœ‰åˆ†ç±»ï¼Œä¸è¿›è¡Œé¢å¤–æ˜ å°„
            if basic_normalized in ['æ­£1ç‰¹', 'æ­£2ç‰¹', 'æ­£3ç‰¹', 'æ­£4ç‰¹', 'æ­£5ç‰¹', 'æ­£6ç‰¹']:
                return basic_normalized  # ç›´æ¥è¿”å›ï¼Œä¸è¿›è¡Œé¢å¤–å¤„ç†
        
        elif lottery_type == 'PK10':
            # å¤„ç†é¾™è™ä½ç½®
            if basic_normalized.startswith('é¾™è™_'):
                return basic_normalized  # ä¿æŒåŸæœ‰
            elif basic_normalized == 'é¾™è™':
                # ä»å†…å®¹ä¸­æ¨æ–­å…·ä½“ä½ç½®
                if 'å† å†›' in content_str or 'ç¬¬1å' in content_str:
                    return 'é¾™è™_å† å†›'
                elif 'äºšå†›' in content_str or 'ç¬¬2å' in content_str:
                    return 'é¾™è™_äºšå†›'
                elif 'å­£å†›' in content_str or 'ç¬¬3å' in content_str:
                    return 'é¾™è™_å­£å†›'
        
        return basic_normalized

# ==================== åˆ†æå¼•æ“ ====================
class AnalysisEngine:
    def __init__(self):
        self.data_analyzer = DataAnalyzer()
        self.normalizer = PlayCategoryNormalizer()
        self.seen_records = set()  # ç”¨äºè®°å½•å·²æ£€æµ‹çš„è®°å½•

    def parse_play_content_enhanced(self, content, current_category, lottery_type):
        """å¢å¼ºç‰ˆå†…å®¹è§£æ - è¿”å›å®é™…ç©æ³•åˆ†ç±»å’ŒæŠ•æ³¨å†…å®¹"""
        content_str = str(content)
        
        # æ ¹æ®å½©ç§ç±»å‹å®šä¹‰ç©æ³•å…³é”®å­—æ˜ å°„
        play_keywords_mapping = {
            'LHC': {
                # å°¾æ•°ç©æ³•
                'ç‰¹å°¾': 'ç‰¹å°¾',
                'å…¨å°¾': 'å…¨å°¾',
                'å¤´å°¾æ•°': 'å°¾æ•°_å¤´å°¾æ•°',
                'å°¾æ•°': 'å°¾æ•°',
                # æ­£ç ç‰¹ç©æ³•
                'æ­£ç ä¸€ç‰¹': 'æ­£1ç‰¹',
                'æ­£ç äºŒç‰¹': 'æ­£2ç‰¹', 
                'æ­£ç ä¸‰ç‰¹': 'æ­£3ç‰¹',
                'æ­£ç å››ç‰¹': 'æ­£4ç‰¹',
                'æ­£ç äº”ç‰¹': 'æ­£5ç‰¹',
                'æ­£ç å…­ç‰¹': 'æ­£6ç‰¹',
                # è¿è‚–ç©æ³•
                'äºŒè¿è‚–': 'è¿è‚–è¿å°¾_äºŒè¿è‚–',
                'ä¸‰è¿è‚–': 'è¿è‚–è¿å°¾_ä¸‰è¿è‚–',
                'å››è¿è‚–': 'è¿è‚–è¿å°¾_å››è¿è‚–', 
                'äº”è¿è‚–': 'è¿è‚–è¿å°¾_äº”è¿è‚–',
                # è¿å°¾ç©æ³•
                'äºŒè¿å°¾': 'è¿è‚–è¿å°¾_äºŒè¿å°¾',
                'ä¸‰è¿å°¾': 'è¿è‚–è¿å°¾_ä¸‰è¿å°¾',
                'å››è¿å°¾': 'è¿è‚–è¿å°¾_å››è¿å°¾',
                'äº”è¿å°¾': 'è¿è‚–è¿å°¾_äº”è¿å°¾'
            },
            'PK10': {
                # ä½ç½®ä¿¡æ¯
                'å† å†›': 'å† å†›',
                'äºšå†›': 'äºšå†›',
                'ç¬¬ä¸‰å': 'ç¬¬ä¸‰å',
                'ç¬¬å››å': 'ç¬¬å››å',
                'ç¬¬äº”å': 'ç¬¬äº”å',
                'ç¬¬å…­å': 'ç¬¬å…­å', 
                'ç¬¬ä¸ƒå': 'ç¬¬ä¸ƒå',
                'ç¬¬å…«å': 'ç¬¬å…«å',
                'ç¬¬ä¹å': 'ç¬¬ä¹å',
                'ç¬¬åå': 'ç¬¬åå',
                'å‰ä¸€': 'å† å†›'
            },
            'SSC': {
                # ä½ç½®ä¿¡æ¯
                'ç¬¬1çƒ': 'ç¬¬1çƒ',
                'ç¬¬2çƒ': 'ç¬¬2çƒ',
                'ç¬¬3çƒ': 'ç¬¬3çƒ',
                'ç¬¬4çƒ': 'ç¬¬4çƒ', 
                'ç¬¬5çƒ': 'ç¬¬5çƒ',
                'ä¸‡ä½': 'ç¬¬1çƒ',
                'åƒä½': 'ç¬¬2çƒ',
                'ç™¾ä½': 'ç¬¬3çƒ',
                'åä½': 'ç¬¬4çƒ',
                'ä¸ªä½': 'ç¬¬5çƒ'
            },
            '3D': {
                # ä½ç½®ä¿¡æ¯
                'ç™¾ä½': 'ç™¾ä½',
                'åä½': 'åä½',
                'ä¸ªä½': 'ä¸ªä½'
            }
        }
        
        # è·å–å¯¹åº”å½©ç§çš„ç©æ³•æ˜ å°„
        play_keywords = play_keywords_mapping.get(lottery_type, {})
        
        # æ£€æŸ¥å†…å®¹ä¸­æ˜¯å¦åŒ…å«ç©æ³•å…³é”®å­—
        detected_play_method = None
        for keyword, play_method in play_keywords.items():
            if keyword in content_str:
                detected_play_method = play_method
                break
        
        # æå–æŠ•æ³¨å†…å®¹
        bet_content = content_str
        if '-' in content_str:
            parts = content_str.split('-', 1)
            if len(parts) == 2:
                bet_content = parts[1].strip()
        
        return detected_play_method, bet_content

    def normalize_play_category_from_content(self, content, current_category, lottery_type):
        """åŸºäºå†…å®¹ç»Ÿä¸€æ ‡å‡†åŒ–ç©æ³•åˆ†ç±»"""
        detected_play_method, _ = self.parse_play_content_enhanced(content, current_category, lottery_type)
        
        if detected_play_method:
            return detected_play_method
        else:
            return current_category
    
    def _get_record_hash(self, record):
        """ç”Ÿæˆè®°å½•çš„å”¯ä¸€å“ˆå¸Œå€¼"""
        key_parts = [
            record['ä¼šå‘˜è´¦å·'],
            record['å½©ç§'], 
            record['æœŸå·'],
            record.get('ç©æ³•åˆ†ç±»', ''),
            record.get('è¿è§„ç±»å‹', ''),
            record.get('ä½ç½®', ''),
            str(record.get('å·ç æ•°é‡', 0)),
            record.get('çŸ›ç›¾ç±»å‹', '')
        ]
        return hashlib.md5('|'.join(key_parts).encode()).hexdigest()
    
    def _add_unique_result(self, results, result_type, record):
        """æ·»åŠ å”¯ä¸€çš„ç»“æœè®°å½•"""
        record_hash = self._get_record_hash(record)
        
        if record_hash not in self.seen_records:
            self.seen_records.add(record_hash)
            results[result_type].append(record)
            return True
        return False
    
    def normalize_play_categories(self, df):
        """ç»Ÿä¸€ç©æ³•åˆ†ç±» - ä½¿ç”¨ç»¼åˆæ–¹æ³•"""
        logger.info("æ­£åœ¨ç»Ÿä¸€ç©æ³•åˆ†ç±»...")
        
        if 'ç©æ³•' in df.columns:
            # === æ›¿æ¢è¿™ä¸€è¡Œï¼šä½¿ç”¨ç»¼åˆçš„ç©æ³•åˆ†ç±»æ ‡å‡†åŒ– ===
            df['ç©æ³•åˆ†ç±»'] = df.apply(
                lambda row: self.normalizer.normalize_category_comprehensive(
                    row['ç©æ³•'], 
                    row['å†…å®¹'],
                    self.identify_lottery_type(row['å½©ç§'])
                ), 
                axis=1
            )
                
            with st.expander("ğŸ¯ ç©æ³•åˆ†ç±»ç»Ÿè®¡", expanded=False):
                category_counts = df['ç©æ³•åˆ†ç±»'].value_counts()
                st.write("ç©æ³•åˆ†ç±»åˆ†å¸ƒ:")
                st.dataframe(category_counts.reset_index().rename(columns={'index': 'ç©æ³•åˆ†ç±»', 'ç©æ³•åˆ†ç±»': 'æ•°é‡'}))
                    
                if len(category_counts) > 15:
                    st.info(f"è¿˜æœ‰{len(category_counts) - 15}ä¸ªåˆ†ç±»æœªæ˜¾ç¤º")
        
        return df 
    
    def identify_lottery_type(self, lottery_name):
        """è¯†åˆ«å½©ç§ç±»å‹"""
        lottery_str = str(lottery_name).strip()
        
        for lottery_type, config in LOTTERY_CONFIGS.items():
            for lottery in config['lotteries']:
                if lottery in lottery_str:
                    return lottery_type
        
        lottery_lower = lottery_str.lower()
        
        # æ›´ç²¾ç¡®çš„å½©ç§è¯†åˆ«
        if any(word in lottery_lower for word in ['pk', 'é£è‰‡', 'èµ›è½¦', 'å¹¸è¿10', 'pk10', 'pkæ‹¾', 'èµ›è»Š']):
            return 'PK10'
        elif any(word in lottery_lower for word in ['å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰']):
            return 'K3'
        elif any(word in lottery_lower for word in ['å…­åˆ', 'lhc', 'å…­åˆå½©', 'â‘¥åˆ', '6åˆ']):
            return 'LHC'
        elif any(word in lottery_lower for word in ['æ—¶æ—¶å½©', 'ssc', 'åˆ†åˆ†å½©', 'æ—¶æ—¶å½©', 'æ™‚æ™‚å½©']):
            return 'SSC'
        elif any(word in lottery_lower for word in ['ä¸‰è‰²', 'ä¸‰è‰²å½©', 'ä¸‰è‰²çƒ']):
            return 'THREE_COLOR'
        # å¢å¼º3Dç³»åˆ—è¯†åˆ«
        elif any(word in lottery_lower for word in ['æ’åˆ—ä¸‰', 'æ’åˆ—3', 'ç¦å½©3d', '3d', 'æé€Ÿ3d', 'æ’åˆ—', 'p3', 'pä¸‰']):
            return '3D'
        
        return None

    def normalize_tail_play_category(self, content, current_category):
        """ç»Ÿä¸€æ ‡å‡†åŒ–å°¾æ•°ç©æ³•åˆ†ç±»"""
        content_str = str(content)
        
        # ç©æ³•å…³é”®å­—ä¼˜å…ˆçº§ï¼ˆä»å…·ä½“åˆ°ä¸€èˆ¬ï¼‰
        play_keywords = [
            ('ç‰¹å°¾', 'ç‰¹å°¾'),
            ('å…¨å°¾', 'å…¨å°¾'),
            ('å¤´å°¾æ•°', 'å°¾æ•°_å¤´å°¾æ•°'),
            ('å°¾æ•°', 'å°¾æ•°')
        ]
        
        for keyword, normalized_category in play_keywords:
            if keyword in content_str:
                return normalized_category
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…å…³é”®å­—ï¼Œè¿”å›åŸå§‹åˆ†ç±»
        return current_category

    # =============== PK10åˆ†ææ–¹æ³• ===============
    def analyze_pk10_patterns(self, df):
        """åˆ†æPKæ‹¾/èµ›è½¦ç³»åˆ—æŠ•æ³¨æ¨¡å¼ - å¸¦è°ƒè¯•ä¿¡æ¯"""
        st.info("ğŸ” å¼€å§‹åˆ†æPK10æ¨¡å¼...")
        results = defaultdict(list)
        
        df_target = df[df['å½©ç§'].apply(self.identify_lottery_type) == 'PK10']
        
        if len(df_target) == 0:
            st.warning("æ²¡æœ‰PK10æ•°æ®")
            return results
        
        grouped = df_target.groupby(['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·'])
        
        for (account, lottery, period), group in grouped:
            st.write(f"ğŸ“Š åˆ†æPK10: {account} {period}")
            self._analyze_pk10_two_sides(account, lottery, period, group, results)
            self._analyze_pk10_gyh(account, lottery, period, group, results)
            self._analyze_pk10_number_plays(account, lottery, period, group, results)
            self._analyze_pk10_independent_plays(account, lottery, period, group, results)
            self._analyze_pk10_qianyi_plays(account, lottery, period, group, results)
            self._analyze_pk10_dragon_tiger_comprehensive(account, lottery, period, group, results)
            self._analyze_pk10_all_positions_bet(account, lottery, period, group, results)
        
        return results
    
    def analyze_lhc_patterns(self, df):
        """åˆ†æå…­åˆå½©æŠ•æ³¨æ¨¡å¼ - å¸¦è°ƒè¯•ä¿¡æ¯"""
        st.info("ğŸ” å¼€å§‹åˆ†æå…­åˆå½©æ¨¡å¼...")
        results = defaultdict(list)
        
        df_target = df[df['å½©ç§'].apply(self.identify_lottery_type) == 'LHC']
        
        if len(df_target) == 0:
            st.warning("æ²¡æœ‰å…­åˆå½©æ•°æ®")
            return results
        
        # ä½¿ç”¨ç‹¬ç«‹çš„å°¾æ•°æ£€æµ‹æ–¹æ³•
        self._analyze_lhc_tail_plays(df_target, results)
        
        # å…¶ä»–æ£€æµ‹æ–¹æ³•
        grouped = df_target.groupby(['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·'])
        
        for (account, lottery, period), group in grouped:
            st.write(f"ğŸ“Š åˆ†æå…­åˆå½©: {account} {period}")
            self._analyze_lhc_zhengma_wave_comprehensive(account, lottery, period, group, results)
            self._analyze_lhc_lianxiao(account, lottery, period, group, results)
            self._analyze_lhc_lianwei(account, lottery, period, group, results)
            self._analyze_lhc_tema(account, lottery, period, group, results)
            self._analyze_lhc_two_sides(account, lottery, period, group, results)
            self._analyze_lhc_zhengma(account, lottery, period, group, results)
            self._analyze_lhc_zhengte(account, lottery, period, group, results)
            self._analyze_lhc_pingte(account, lottery, period, group, results)
            self._analyze_lhc_texiao(account, lottery, period, group, results)
            self._analyze_lhc_yixiao(account, lottery, period, group, results)
            self._analyze_lhc_wave(account, lottery, period, group, results)
            self._analyze_lhc_five_elements(account, lottery, period, group, results)
            self._analyze_lhc_banbo(account, lottery, period, group, results)
        
        return results
    
    def _analyze_pk10_two_sides(self, account, lottery, period, group, results):
        """åˆ†æPK10ä¸¤é¢ç©æ³•"""
        two_sides_categories = ['ä¸¤é¢', 'åŒé¢']
        
        two_sides_group = group[group['ç©æ³•åˆ†ç±»'].isin(two_sides_categories)]
        
        position_bets = defaultdict(set)
        
        for _, row in two_sides_group.iterrows():
            content = str(row['å†…å®¹'])
            
            if '-' in content:
                parts = content.split(',')
                for part in parts:
                    if '-' in part:
                        try:
                            position, bet_option = part.split('-', 1)
                            position = self.data_analyzer._normalize_pk10_position(position)
                            bet_option = bet_option.strip()
                            
                            if bet_option in ['å¤§', 'å°', 'å•', 'åŒ', 'é¾™', 'è™']:
                                position_bets[position].add(bet_option)
                        except ValueError:
                            continue
        
        for position, bets in position_bets.items():
            conflicts = []
            
            if 'å¤§' in bets and 'å°' in bets:
                conflicts.append('å¤§å°')
            if 'å•' in bets and 'åŒ' in bets:
                conflicts.append('å•åŒ')
            if 'é¾™' in bets and 'è™' in bets:
                conflicts.append('é¾™è™')
            
            if conflicts:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': 'ä¸¤é¢',
                    'ä½ç½®': position,
                    'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                    'æŠ•æ³¨å†…å®¹': f"{position}-{','.join(sorted(bets))}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'ä¸¤é¢çŸ›ç›¾')
                }
                self._add_unique_result(results, 'ä¸¤é¢çŸ›ç›¾', record)
    
    def _analyze_pk10_gyh(self, account, lottery, period, group, results):
        """åˆ†æPK10å† äºšå’Œç©æ³•"""
        gyh_categories = ['å† äºšå’Œ', 'å† äºšå’Œ_å¤§å°å•åŒ', 'å† äºšå’Œ_å’Œå€¼']
        
        gyh_group = group[group['ç©æ³•åˆ†ç±»'].isin(gyh_categories)]
        
        all_numbers = set()
        all_size_parity = set()
        
        for _, row in gyh_group.iterrows():
            content = str(row['å†…å®¹'])
            
            # æ”¹è¿›ï¼šæå–æ‰€æœ‰æ•°å­—ï¼Œä¸é™åˆ¶èŒƒå›´
            numbers = re.findall(r'\b\d{1,2}\b', content)
            numbers = [int(num) for num in numbers if 1 <= int(num) <= 19]  # å† äºšå’ŒèŒƒå›´3-19ï¼Œä½†å…è®¸æå–1-19
            all_numbers.update(numbers)
            
            size_parity = self.data_analyzer.extract_size_parity_from_content(content)
            all_size_parity.update(size_parity)
        
        # å† äºšå’Œå¤šç æ£€æµ‹ - ä½¿ç”¨æ‰€æœ‰æå–çš„æ•°å­—
        if len(all_numbers) >= THRESHOLD_CONFIG['PK10']['gyh_multi_number']:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'å† äºšå’Œ',
                'å·ç æ•°é‡': len(all_numbers),
                'æŠ•æ³¨å†…å®¹': ', '.join([str(num) for num in sorted(all_numbers)]),
                'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'å† äºšå’Œå¤šç ')
            }
            self._add_unique_result(results, 'å† äºšå’Œå¤šç ', record)
            return  # å¦‚æœæ£€æµ‹åˆ°å¤šå·ç ï¼Œä¸å†æ£€æµ‹å…¶ä»–ç±»å‹
        
        # åŸæœ‰çš„çŸ›ç›¾æ£€æµ‹é€»è¾‘ä¿æŒä¸å˜...
        conflicts = []
        if 'å¤§' in all_size_parity and 'å°' in all_size_parity:
            conflicts.append('å¤§å°')
        if 'å•' in all_size_parity and 'åŒ' in all_size_parity:
            conflicts.append('å•åŒ')
        
        if conflicts:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'å† äºšå’Œ',
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(all_size_parity)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'å† äºšå’ŒçŸ›ç›¾')
            }
            self._add_unique_result(results, 'å† äºšå’ŒçŸ›ç›¾', record)
        
        # å† äºšå’ŒçŸ›ç›¾æ£€æµ‹
        conflicts = []
        if 'å¤§' in all_size_parity and 'å°' in all_size_parity:
            conflicts.append('å¤§å°')
        if 'å•' in all_size_parity and 'åŒ' in all_size_parity:
            conflicts.append('å•åŒ')
        
        if conflicts:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'å† äºšå’Œ',
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(all_size_parity)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'å† äºšå’ŒçŸ›ç›¾')
            }
            self._add_unique_result(results, 'å† äºšå’ŒçŸ›ç›¾', record)
    
    def _analyze_pk10_number_plays(self, account, lottery, period, group, results):
        """åˆ†æPK10å·ç ç±»ç©æ³• - å¢å¼ºä½ç½®åˆ¤æ–­"""
        number_categories = [
            '1-5å', '6-10å', 'å† å†›', 'å‰ä¸€', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å',
            'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå', 'å®šä½èƒ†',
            'å®šä½èƒ†_ç¬¬1~5å', 'å®šä½èƒ†_ç¬¬6~10å'
        ]
        
        number_group = group[group['ç©æ³•åˆ†ç±»'].isin(number_categories)]
        
        all_numbers_by_position = defaultdict(set)
        
        # ä¿®å¤è¿™é‡Œçš„ç¼©è¿›ï¼šæ•´ä¸ªforå¾ªç¯åº”è¯¥ç¼©è¿›
        for _, row in number_group.iterrows():
            content = str(row['å†…å®¹'])
            category = str(row['ç©æ³•åˆ†ç±»'])
            
            # æ–°å¢ï¼šåŸºäºå†…å®¹é‡æ–°åˆ†ç±»
            actual_category = self.normalize_play_category_from_content(content, category, 'PK10')
            
            # å¢å¼ºä½ç½®åˆ¤æ–­ï¼šä»ç©æ³•åˆ†ç±»æ¨æ–­ä½ç½®
            inferred_position = self._infer_position_from_category(actual_category)  # ä½¿ç”¨ actual_category
        
            # ä½¿ç”¨ç»Ÿä¸€è§£æå™¨
            bets_by_position = ContentParser.parse_pk10_content(content)
            
            for position, bets in bets_by_position.items():
                # å¦‚æœè§£æå‡ºçš„ä½ç½®æ˜¯"æœªçŸ¥ä½ç½®"ï¼Œä½¿ç”¨ä»ç©æ³•åˆ†ç±»æ¨æ–­çš„ä½ç½®
                if position == 'æœªçŸ¥ä½ç½®' and inferred_position:
                    position = inferred_position
                
                # æå–æ¯ä¸ªä½ç½®çš„å·ç 
                for bet in bets:
                    numbers = self.data_analyzer.extract_numbers_from_content(bet, 1, 10, is_pk10=True)
                    all_numbers_by_position[position].update(numbers)
        
        # æ£€æŸ¥æ¯ä¸ªä½ç½®çš„è¶…ç 
        for position, numbers in all_numbers_by_position.items():
            if len(numbers) >= THRESHOLD_CONFIG['PK10']['multi_number']:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': f'{position}å¤šç ',  # æ”¹ä¸ºå…·ä½“ä½ç½®
                    'ä½ç½®': position,
                    'å·ç æ•°é‡': len(numbers),
                    'æŠ•æ³¨å†…å®¹': f"{position}: {', '.join([f'{num:02d}' for num in sorted(numbers)])}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(numbers)}, f'{position}å¤šç ')
                }
                self._add_unique_result(results, 'è¶…ç ', record)
    
    def _infer_position_from_category(self, category):
        """ä»ç©æ³•åˆ†ç±»æ¨æ–­ä½ç½®"""
        category_str = str(category).strip()
        
        position_mapping = {
            'å† å†›': ['å† å†›', 'å‰ä¸€', 'ç¬¬1å', 'ç¬¬ä¸€å'],
            'äºšå†›': ['äºšå†›', 'ç¬¬2å', 'ç¬¬äºŒå'],
            'ç¬¬ä¸‰å': ['ç¬¬ä¸‰å', 'å­£å†›', 'ç¬¬3å'],
            'ç¬¬å››å': ['ç¬¬å››å', 'ç¬¬4å'],
            'ç¬¬äº”å': ['ç¬¬äº”å', 'ç¬¬5å'],
            'ç¬¬å…­å': ['ç¬¬å…­å', 'ç¬¬6å'],
            'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå', 'ç¬¬7å'],
            'ç¬¬å…«å': ['ç¬¬å…«å', 'ç¬¬8å'],
            'ç¬¬ä¹å': ['ç¬¬ä¹å', 'ç¬¬9å'],
            'ç¬¬åå': ['ç¬¬åå', 'ç¬¬10å'],
            '1-5å': ['1-5å', 'å®šä½èƒ†_ç¬¬1~5å'],
            '6-10å': ['6-10å', 'å®šä½èƒ†_ç¬¬6~10å']
        }
        
        for position, keywords in position_mapping.items():
            for keyword in keywords:
                if keyword in category_str:
                    return position
        
        return None
    
    def _analyze_pk10_independent_plays(self, account, lottery, period, group, results):
        """åˆ†æPK10ç‹¬ç«‹ç©æ³•ï¼ˆå¤§å°å•åŒé¾™è™ï¼‰"""
        independent_categories = [
            'å¤§å°_å† å†›', 'å¤§å°_äºšå†›', 'å¤§å°_å­£å†›',
            'å•åŒ_å† å†›', 'å•åŒ_äºšå†›', 'å•åŒ_å­£å†›',
            'é¾™è™_å† å†›', 'é¾™è™_äºšå†›', 'é¾™è™_å­£å†›'
        ]
        
        independent_group = group[group['ç©æ³•åˆ†ç±»'].isin(independent_categories)]
        
        position_bets = defaultdict(set)
        
        for _, row in independent_group.iterrows():  # è¿™ä¸ªforå¾ªç¯éœ€è¦æ­£ç¡®ç¼©è¿›
            content = str(row['å†…å®¹'])
            category = str(row['ç©æ³•åˆ†ç±»'])
            
            # ç¡®å®šä½ç½®ï¼ˆå‰ä¸€å°±æ˜¯å† å†›ï¼‰
            if 'å† å†›' in category or 'å‰ä¸€' in category:
                position = 'å† å†›'
            elif 'äºšå†›' in category:
                position = 'äºšå†›'
            elif 'å­£å†›' in category:
                position = 'å­£å†›'
            else:
                continue
            
            if 'å¤§å°' in category:
                bets = self.data_analyzer.extract_size_parity_from_content(content)
            elif 'å•åŒ' in category:
                bets = self.data_analyzer.extract_size_parity_from_content(content)
            elif 'é¾™è™' in category:
                bets = self.data_analyzer.extract_dragon_tiger_from_content(content)
            else:
                bets = []
            
            position_bets[position].update(bets)
        
        for position, bets in position_bets.items():  # è¿™ä¸ªforå¾ªç¯ä¹Ÿéœ€è¦æ­£ç¡®ç¼©è¿›
            conflicts = []
            
            if 'å¤§' in bets and 'å°' in bets:
                conflicts.append('å¤§å°')
            if 'å•' in bets and 'åŒ' in bets:
                conflicts.append('å•åŒ')
            if 'é¾™' in bets and 'è™' in bets:
                conflicts.append('é¾™è™')
            
            if conflicts:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': 'ç‹¬ç«‹ç©æ³•',
                    'ä½ç½®': position,
                    'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                    'æŠ•æ³¨å†…å®¹': f"{position}-{','.join(sorted(bets))}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'ç‹¬ç«‹ç©æ³•çŸ›ç›¾')
                }
                self._add_unique_result(results, 'ç‹¬ç«‹ç©æ³•çŸ›ç›¾', record)
    
    def _analyze_pk10_qianyi_plays(self, account, lottery, period, group, results):
        """åˆ†æPK10å‰ä¸€ç©æ³•"""
        qianyi_categories = ['å‰ä¸€']
        
        qianyi_group = group[group['ç©æ³•åˆ†ç±»'].isin(qianyi_categories)]
        
        for _, row in qianyi_group.iterrows():
            content = str(row['å†…å®¹'])
            
            # æå–å·ç 
            numbers = self.data_analyzer.extract_numbers_from_content(
                content,
                LOTTERY_CONFIGS['PK10']['min_number'],
                LOTTERY_CONFIGS['PK10']['max_number']
            )
            
            # å‰ä¸€å¤šç æ£€æµ‹ï¼ˆå‰ä¸€å°±æ˜¯å† å†›ï¼Œæ‰€ä»¥ä½¿ç”¨å† å†›çš„é˜ˆå€¼ï¼‰
            if len(numbers) >= THRESHOLD_CONFIG['PK10']['multi_number']:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': 'å‰ä¸€',
                    'ä½ç½®': 'å† å†›',  # æ˜¾ç¤ºä¸ºå† å†›ä½ç½®
                    'å·ç æ•°é‡': len(numbers),
                    'æŠ•æ³¨å†…å®¹': ', '.join([f'{num:02d}' for num in sorted(numbers)]),
                    'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(numbers)}, 'è¶…ç ')
                }
                self._add_unique_result(results, 'è¶…ç ', record)
    
    def _analyze_pk10_dragon_tiger_detailed(self, account, lottery, period, group, results):
        """PK10é¾™è™è¯¦ç»†æ£€æµ‹ - ä¿®å¤ç‰ˆæœ¬"""
        dragon_tiger_categories = ['é¾™è™_å† å†›', 'é¾™è™_äºšå†›', 'é¾™è™_å­£å†›', 'é¾™è™']
        
        dragon_tiger_group = group[group['ç©æ³•åˆ†ç±»'].isin(dragon_tiger_categories)]
        
        position_bets = defaultdict(set)
        
        for _, row in dragon_tiger_group.iterrows():
            content = str(row['å†…å®¹'])
            category = str(row['ç©æ³•åˆ†ç±»'])
            
            # ä¿®å¤ï¼šç²¾ç¡®æå–ä½ç½®ï¼Œå¤„ç†ç©ºæ ¼é—®é¢˜
            position = self._extract_dragon_tiger_position(category)
            
            # æå–é¾™è™æŠ•æ³¨
            dragon_tiger = self.data_analyzer.extract_dragon_tiger_from_content(content)
            position_bets[position].update(dragon_tiger)
        
        # æ£€æŸ¥çŸ›ç›¾ - ä¿®å¤ï¼šç¡®ä¿åªæ£€æŸ¥å®é™…æœ‰æŠ•æ³¨çš„ä½ç½®
        for position, bets in position_bets.items():
            if position and 'é¾™' in bets and 'è™' in bets:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': 'é¾™è™',
                    'ä½ç½®': position,
                    'çŸ›ç›¾ç±»å‹': 'é¾™è™çŸ›ç›¾',
                    'æŠ•æ³¨å†…å®¹': f"{position}-{','.join(sorted(bets))}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'é¾™è™çŸ›ç›¾'}, 'é¾™è™çŸ›ç›¾')
                }
                self._add_unique_result(results, 'é¾™è™çŸ›ç›¾', record)
    
    def _extract_dragon_tiger_position(self, category):
        """ä»é¾™è™ç©æ³•åˆ†ç±»ä¸­ç²¾ç¡®æå–ä½ç½® - ä¿®å¤ç‰ˆæœ¬"""
        category_str = str(category).strip()
        
        # å¤„ç†ç©ºæ ¼é—®é¢˜ï¼šç§»é™¤æ‰€æœ‰ç©ºæ ¼
        category_clean = category_str.replace(' ', '').replace('Â ', '')  # æ™®é€šç©ºæ ¼å’Œå…¨è§’ç©ºæ ¼
        
        position_mapping = {
            'å† å†›': ['å† å†›', 'å† è»', 'å†  å†›', 'å†  è»', 'ç¬¬1å', 'ç¬¬ä¸€å'],
            'äºšå†›': ['äºšå†›', 'äºè»', 'äºš å†›', 'äº è»', 'ç¬¬2å', 'ç¬¬äºŒå'], 
            'å­£å†›': ['å­£å†›', 'å­£è»', 'å­£ å†›', 'å­£ è»', 'ç¬¬3å', 'ç¬¬ä¸‰å'],
            'ç¬¬å››å': ['ç¬¬å››å', 'ç¬¬4å'],
            'ç¬¬äº”å': ['ç¬¬äº”å', 'ç¬¬5å'],
            'ç¬¬å…­å': ['ç¬¬å…­å', 'ç¬¬6å'],
            'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå', 'ç¬¬7å'],
            'ç¬¬å…«å': ['ç¬¬å…«å', 'ç¬¬8å'],
            'ç¬¬ä¹å': ['ç¬¬ä¹å', 'ç¬¬9å'],
            'ç¬¬åå': ['ç¬¬åå', 'ç¬¬10å']
        }
        
        # ç²¾ç¡®åŒ¹é…
        for position, keywords in position_mapping.items():
            for keyword in keywords:
                # å¤„ç† "é¾™è™_å† å†›" æ ¼å¼
                if f"é¾™è™_{keyword}" == category_clean or f"é¾™è™{keyword}" == category_clean:
                    return position
                # ç›´æ¥åŒ¹é…å…³é”®è¯
                if keyword == category_clean:
                    return position
        
        # åŒ…å«åŒ¹é…
        for position, keywords in position_mapping.items():
            for keyword in keywords:
                if keyword in category_clean:
                    return position
        
        return None  # è¿”å›Noneè€Œä¸æ˜¯æœªçŸ¥ä½ç½®ï¼Œé¿å…è¯¯åˆ¤

    def _analyze_pk10_dragon_tiger_comprehensive(self, account, lottery, period, group, results):
        """ç»¼åˆè€ƒè™‘ç©æ³•å’Œå†…å®¹çš„PK10é¾™è™æ£€æµ‹ - å½»åº•ä¿®å¤ä½ç½®è¯†åˆ«"""
        dragon_tiger_categories = ['é¾™è™_å† å†›', 'é¾™è™_äºšå†›', 'é¾™è™_å­£å†›', 'é¾™è™', 'é¾™è™_ç¬¬å››å', 'é¾™è™_ç¬¬äº”å', 'é¾™è™_ç¬¬å…­å', 'é¾™è™_ç¬¬ä¸ƒå', 'é¾™è™_ç¬¬å…«å', 'é¾™è™_ç¬¬ä¹å', 'é¾™è™_ç¬¬åå']
        
        dragon_tiger_group = group[group['ç©æ³•åˆ†ç±»'].isin(dragon_tiger_categories)]
        
        if dragon_tiger_group.empty:
            return
        
        position_bets = defaultdict(set)
        
        # è°ƒè¯•ä¿¡æ¯
        debug_records = []
        
        for _, row in dragon_tiger_group.iterrows():
            content = normalize_spaces(str(row['å†…å®¹']))
            category = normalize_spaces(str(row['ç©æ³•åˆ†ç±»']))
            
            # è°ƒè¯•è®°å½•
            debug_record = {
                'account': account,
                'period': period,
                'category': category,
                'content': content,
                'position_found': None
            }
            
            # ç›´æ¥è§£æç©æ³•åˆ†ç±»ä¸­çš„ä½ç½®
            position = self._extract_position_from_dragon_tiger_category(category)
            
            debug_record['position_found'] = position
            
            # æå–é¾™è™æŠ•æ³¨
            dragon_tiger = self.data_analyzer.extract_dragon_tiger_from_content(content)
            
            if position and dragon_tiger:
                position_bets[position].update(dragon_tiger)
                debug_record['dragon_tiger'] = dragon_tiger
            else:
                debug_record['dragon_tiger'] = 'æœªæå–åˆ°æˆ–ä½ç½®ä¸ºç©º'
            
            debug_records.append(debug_record)
        
        # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
        if debug_records:
            st.write(f"ğŸ‰ é¾™è™æ£€æµ‹è°ƒè¯•ä¿¡æ¯ - {account} {period}:")
            for record in debug_records:
                st.write(f"  - ç©æ³•: {record['category']}, å†…å®¹: {record['content']}, ä½ç½®: {record['position_found']}, é¾™è™: {record.get('dragon_tiger', 'æ— ')}")
        
        # æ£€æŸ¥çŸ›ç›¾ - åªåœ¨åŒä¸€ä½ç½®åŒæ—¶æŠ•æ³¨é¾™å’Œè™æ—¶æ‰æŠ¥å‘Š
        for position, bets in position_bets.items():
            if position and 'é¾™' in bets and 'è™' in bets:
                st.success(f"ğŸ¯ æ£€æµ‹åˆ°é¾™è™çŸ›ç›¾: {position} - {bets}")
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': 'é¾™è™',
                    'ä½ç½®': position,
                    'çŸ›ç›¾ç±»å‹': 'é¾™è™çŸ›ç›¾',
                    'æŠ•æ³¨å†…å®¹': f"{position}-{','.join(sorted(bets))}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'é¾™è™çŸ›ç›¾'}, 'é¾™è™çŸ›ç›¾')
                }
                self._add_unique_result(results, 'é¾™è™çŸ›ç›¾', record)
    
    def _extract_position_from_dragon_tiger_category(self, category):
        """ä»é¾™è™ç©æ³•åˆ†ç±»ä¸­ç²¾ç¡®æå–ä½ç½® - å½»åº•ä¿®å¤ç‰ˆæœ¬"""
        category_str = str(category).strip()
        
        # å¤„ç†æ‰€æœ‰å¯èƒ½çš„ç©ºæ ¼å’Œæ ¼å¼é—®é¢˜
        category_clean = category_str.replace(' ', '').replace('Â ', '').replace('_', '').replace('-', '')
        
        # å®Œæ•´çš„ä½ç½®æ˜ å°„
        position_mapping = {
            'å† å†›': ['å† å†›', 'å†  å†›', 'å†   å†›', 'ç¬¬1å', 'ç¬¬ä¸€å', 'å‰ä¸€', '1st', '1'],
            'äºšå†›': ['äºšå†›', 'äºš å†›', 'äºš  å†›', 'ç¬¬2å', 'ç¬¬äºŒå', '2nd', '2'],
            'å­£å†›': ['å­£å†›', 'å­£ å†›', 'å­£  å†›', 'ç¬¬3å', 'ç¬¬ä¸‰å', '3rd', '3'],
            'ç¬¬å››å': ['ç¬¬å››å', 'ç¬¬4å', '4th', '4'],
            'ç¬¬äº”å': ['ç¬¬äº”å', 'ç¬¬5å', '5th', '5'],
            'ç¬¬å…­å': ['ç¬¬å…­å', 'ç¬¬6å', '6th', '6'],
            'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå', 'ç¬¬7å', '7th', '7'],
            'ç¬¬å…«å': ['ç¬¬å…«å', 'ç¬¬8å', '8th', '8'],
            'ç¬¬ä¹å': ['ç¬¬ä¹å', 'ç¬¬9å', '9th', '9'],
            'ç¬¬åå': ['ç¬¬åå', 'ç¬¬10å', '10th', '10']
        }
        
        # é¦–å…ˆæ£€æŸ¥å®Œæ•´åŒ¹é…
        for position, keywords in position_mapping.items():
            for keyword in keywords:
                keyword_clean = keyword.replace(' ', '')
                if keyword_clean == category_clean.replace('é¾™è™', ''):
                    return position
        
        # ç„¶åæ£€æŸ¥åŒ…å«å…³ç³»
        for position, keywords in position_mapping.items():
            for keyword in keywords:
                keyword_clean = keyword.replace(' ', '')
                if keyword_clean in category_clean:
                    return position
        
        # å¤„ç†"é¾™è™_ç¬¬å››å"è¿™ç§æ ¼å¼
        if 'é¾™è™' in category_clean:
            remaining = category_clean.replace('é¾™è™', '')
            for position, keywords in position_mapping.items():
                for keyword in keywords:
                    keyword_clean = keyword.replace(' ', '')
                    if keyword_clean in remaining:
                        return position
        
        st.warning(f"âš ï¸ æ— æ³•ä»ç©æ³•åˆ†ç±»ä¸­æå–ä½ç½®: {category_str} -> {category_clean}")
        return 'æœªçŸ¥ä½ç½®'

    def _analyze_pk10_all_positions_bet(self, account, lottery, period, group, results):
        """æ£€æµ‹PK10åä¸ªä½ç½®å…¨æŠ•æƒ…å†µ"""
        
        # å®šä¹‰åä¸ªæ ‡å‡†ä½ç½®
        standard_positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                             'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
        
        # æ”¶é›†æ‰€æœ‰ä½ç½®æŠ•æ³¨
        all_position_bets = defaultdict(set)
        
        # åˆ†æå„ç§ç©æ³•ä¸­çš„ä½ç½®æŠ•æ³¨
        self._collect_position_bets_from_plays(account, lottery, period, group, all_position_bets)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åä¸ªä½ç½®éƒ½æœ‰æŠ•æ³¨
        positions_with_bets = set()
        
        for position in standard_positions:
            if position in all_position_bets and all_position_bets[position]:
                positions_with_bets.add(position)
        
        # å¦‚æœåä¸ªä½ç½®éƒ½æœ‰æŠ•æ³¨
        if len(positions_with_bets) >= THRESHOLD_CONFIG['PK10']['all_positions_bet']:
            # åˆ†ææŠ•æ³¨ç±»å‹ï¼ˆå¤§å°æˆ–å•åŒï¼‰
            bet_types = self._analyze_bet_types(all_position_bets, standard_positions)
            
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'å…¨ä½ç½®æŠ•æ³¨',
                'æŠ•æ³¨ä½ç½®æ•°': len(positions_with_bets),
                'æŠ•æ³¨ç±»å‹': bet_types,
                'æŠ•æ³¨å†…å®¹': f"åä¸ªä½ç½®å…¨æŠ•: {bet_types}",
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨ä½ç½®æ•°': len(positions_with_bets)}, 'åä¸ªä½ç½®å…¨æŠ•')
            }
            self._add_unique_result(results, 'åä¸ªä½ç½®å…¨æŠ•', record)
    
    def _collect_position_bets_from_plays(self, account, lottery, period, group, all_position_bets):
        """ä»å„ç§ç©æ³•ä¸­æ”¶é›†ä½ç½®æŠ•æ³¨ä¿¡æ¯ - å¢å¼ºç‰ˆæœ¬ï¼Œè®°å½•å…·ä½“æŠ•æ³¨å†…å®¹"""
        
        # 1. ä»ä¸¤é¢ç©æ³•æ”¶é›†
        two_sides_categories = ['ä¸¤é¢', 'åŒé¢']
        two_sides_group = group[group['ç©æ³•åˆ†ç±»'].isin(two_sides_categories)]
        
        for _, row in two_sides_group.iterrows():
            content = str(row['å†…å®¹'])
            self._extract_position_bets_from_content(content, all_position_bets)
        
        # 2. ä»ç‹¬ç«‹ç©æ³•æ”¶é›†ï¼ˆå¤§å°å•åŒé¾™è™ï¼‰
        independent_categories = [
            'å¤§å°_å† å†›', 'å¤§å°_äºšå†›', 'å¤§å°_å­£å†›',
            'å•åŒ_å† å†›', 'å•åŒ_äºšå†›', 'å•åŒ_å­£å†›',
            'é¾™è™_å† å†›', 'é¾™è™_äºšå†›', 'é¾™è™_å­£å†›'
        ]
        
        independent_group = group[group['ç©æ³•åˆ†ç±»'].isin(independent_categories)]
        
        for _, row in independent_group.iterrows():
            content = str(row['å†…å®¹'])
            category = str(row['ç©æ³•åˆ†ç±»'])
            
            # ç¡®å®šä½ç½®
            if 'å† å†›' in category or 'å‰ä¸€' in category:
                position = 'å† å†›'
            elif 'äºšå†›' in category:
                position = 'äºšå†›'
            elif 'å­£å†›' in category:
                position = 'ç¬¬ä¸‰å'
            else:
                continue
            
            # æå–å…·ä½“çš„æŠ•æ³¨å†…å®¹
            if 'å¤§å°' in category:
                bets = self.data_analyzer.extract_size_parity_from_content(content)
                # åªå…³æ³¨å¤§å°
                size_bets = [bet for bet in bets if bet in ['å¤§', 'å°']]
                if size_bets:
                    # è®°å½•å…·ä½“çš„æŠ•æ³¨å†…å®¹ï¼Œè€Œä¸æ˜¯ç¬¼ç»Ÿçš„"å¤§å°ç±»"
                    all_position_bets[position].update(size_bets)
            elif 'å•åŒ' in category:
                bets = self.data_analyzer.extract_size_parity_from_content(content)
                # åªå…³æ³¨å•åŒ
                parity_bets = [bet for bet in bets if bet in ['å•', 'åŒ']]
                if parity_bets:
                    # è®°å½•å…·ä½“çš„æŠ•æ³¨å†…å®¹ï¼Œè€Œä¸æ˜¯ç¬¼ç»Ÿçš„"å•åŒç±»"
                    all_position_bets[position].update(parity_bets)
        
        # 3. ä»å·ç ç±»ç©æ³•æ”¶é›†ï¼ˆå®šä½èƒ†ç­‰ï¼‰
        number_categories = [
            '1-5å', '6-10å', 'å† å†›', 'å‰ä¸€', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å',
            'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå', 'å®šä½èƒ†',
            'å®šä½èƒ†_ç¬¬1~5å', 'å®šä½èƒ†_ç¬¬6~10å'
        ]
        
        number_group = group[group['ç©æ³•åˆ†ç±»'].isin(number_categories)]
        
        for _, row in number_group.iterrows():
            content = str(row['å†…å®¹'])
            category = str(row['ç©æ³•åˆ†ç±»'])
            
            # ä½¿ç”¨ç»Ÿä¸€è§£æå™¨è§£æä½ç½®
            bets_by_position = ContentParser.parse_pk10_content(content)
            
            for position, numbers in bets_by_position.items():
                if numbers:  # å¦‚æœæœ‰å·ç æŠ•æ³¨
                    all_position_bets[position].add('å·ç ')
    
    def _extract_position_bets_from_content(self, content, all_position_bets):
        """ä»å†…å®¹ä¸­æå–ä½ç½®æŠ•æ³¨ä¿¡æ¯ - å¢å¼ºç‰ˆæœ¬ï¼Œè®°å½•å…·ä½“æŠ•æ³¨å†…å®¹"""
        content_str = str(content)
        
        if '-' in content_str:
            parts = content_str.split(',')
            for part in parts:
                if '-' in part:
                    try:
                        position, bet_option = part.split('-', 1)
                        position = self.data_analyzer._normalize_pk10_position(position)
                        bet_option = bet_option.strip()
                        
                        # ç›´æ¥è®°å½•å…·ä½“çš„æŠ•æ³¨ç±»å‹ï¼Œè€Œä¸æ˜¯åˆ†ç±»
                        if bet_option in ['å¤§', 'å°', 'å•', 'åŒ']:
                            all_position_bets[position].add(bet_option)
                    except ValueError:
                        continue
    
    def _analyze_bet_types(self, all_position_bets, standard_positions):
        """åˆ†ææŠ•æ³¨ç±»å‹ - æœ€ç»ˆä¿®å¤ç‰ˆæœ¬"""
        # ç»Ÿè®¡æ¯ä¸ªå…·ä½“æŠ•æ³¨ç±»å‹çš„æ•°é‡
        size_bets_count = {'å¤§': 0, 'å°': 0}
        parity_bets_count = {'å•': 0, 'åŒ': 0}
        number_count = 0
        
        for position in standard_positions:
            if position in all_position_bets:
                bets = all_position_bets[position]
                
                # ç»Ÿè®¡å…·ä½“çš„å¤§å°æŠ•æ³¨
                if 'å¤§' in bets:
                    size_bets_count['å¤§'] += 1
                if 'å°' in bets:
                    size_bets_count['å°'] += 1
                
                # ç»Ÿè®¡å…·ä½“çš„å•åŒæŠ•æ³¨
                if 'å•' in bets:
                    parity_bets_count['å•'] += 1
                if 'åŒ' in bets:
                    parity_bets_count['åŒ'] += 1
                
                # å·ç ç±»æŠ•æ³¨ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                if 'å·ç ' in bets:
                    number_count += 1
        
        # æ„å»ºå‡†ç¡®çš„æŠ•æ³¨ç±»å‹æè¿°
        bet_types = []
        
        # å¤§å°æŠ•æ³¨ï¼šåªæœ‰å½“ä¸€ä¸ªç±»å‹åœ¨8ä¸ªæˆ–ä»¥ä¸Šä½ç½®å‡ºç°æ—¶æ‰æ˜¾ç¤º
        for size_type, count in size_bets_count.items():
            if count >= 8:
                bet_types.append(size_type)
                break  # åªæ˜¾ç¤ºä¸»è¦çš„å¤§å°ç±»å‹
        
        # å•åŒæŠ•æ³¨ï¼šåªæœ‰å½“ä¸€ä¸ªç±»å‹åœ¨8ä¸ªæˆ–ä»¥ä¸Šä½ç½®å‡ºç°æ—¶æ‰æ˜¾ç¤º
        for parity_type, count in parity_bets_count.items():
            if count >= 8:
                bet_types.append(parity_type)
                break  # åªæ˜¾ç¤ºä¸»è¦çš„å•åŒç±»å‹
        
        # å·ç æŠ•æ³¨
        if number_count >= 8:
            bet_types.append('å·ç ')
        
        return 'ã€'.join(bet_types) if bet_types else 'æ··åˆæŠ•æ³¨'

    # =============== æ—¶æ—¶å½©åˆ†ææ–¹æ³• ===============
    def analyze_ssc_patterns(self, df):
        """åˆ†ææ—¶æ—¶å½©æŠ•æ³¨æ¨¡å¼"""
        results = defaultdict(list)
        
        df_target = df[df['å½©ç§'].apply(self.identify_lottery_type) == 'SSC']
        
        if len(df_target) == 0:
            return results
        
        grouped = df_target.groupby(['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·'])
        
        for (account, lottery, period), group in grouped:
            self._analyze_ssc_two_sides(account, lottery, period, group, results)
            self._analyze_ssc_douniu(account, lottery, period, group, results)
            self._analyze_ssc_dingwei(account, lottery, period, group, results)
            self._analyze_ssc_zonghe(account, lottery, period, group, results)
            self._analyze_ssc_dingwei_detailed(account, lottery, period, group, results)
        
        return results
    
    def _analyze_ssc_two_sides(self, account, lottery, period, group, results):
        two_sides_group = group[group['ç©æ³•åˆ†ç±»'] == 'ä¸¤é¢']
        
        total_bets = set()
        ball_bets = defaultdict(set)
        
        for _, row in two_sides_group.iterrows():
            content = str(row['å†…å®¹'])
            
            if 'æ€»å’Œã€é¾™è™-' in content:
                clean_content = content.replace('æ€»å’Œã€é¾™è™-', '')
                bets = clean_content.split(',')
                for bet in bets:
                    if 'æ€»å’Œå¤§' in bet:
                        total_bets.add('å¤§')
                    elif 'æ€»å’Œå°' in bet:
                        total_bets.add('å°')
                    elif 'æ€»å’Œå•' in bet:
                        total_bets.add('å•')
                    elif 'æ€»å’ŒåŒ' in bet:
                        total_bets.add('åŒ')
                    elif 'é¾™' in bet:
                        total_bets.add('é¾™')
                    elif 'è™' in bet:
                        total_bets.add('è™')
            
            for i in range(1, 6):
                ball_key = f'ç¬¬{i}çƒ'
                if ball_key in content:
                    bets = self.data_analyzer.extract_size_parity_from_content(content)
                    ball_bets[ball_key].update(bets)
        
        conflicts = []
        if 'å¤§' in total_bets and 'å°' in total_bets:
            conflicts.append('æ€»å’Œå¤§/å°')
        if 'å•' in total_bets and 'åŒ' in total_bets:
            conflicts.append('æ€»å’Œå•/åŒ')
        if 'é¾™' in total_bets and 'è™' in total_bets:
            conflicts.append('é¾™/è™')
        
        if conflicts:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'ä¸¤é¢',
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                'æŠ•æ³¨å†…å®¹': f"æ€»å’Œ:{','.join(sorted(total_bets))}",
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'ä¸¤é¢çŸ›ç›¾')
            }
            self._add_unique_result(results, 'ä¸¤é¢çŸ›ç›¾', record)
        
        for ball, bets in ball_bets.items():
            ball_conflicts = []
            if 'å¤§' in bets and 'å°' in bets:
                ball_conflicts.append('å¤§å°')
            if 'å•' in bets and 'åŒ' in bets:
                ball_conflicts.append('å•åŒ')
            
            if ball_conflicts:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': 'ä¸¤é¢',
                    'çŸ›ç›¾ç±»å‹': f"{ball}{'ã€'.join(ball_conflicts)}",
                    'æŠ•æ³¨å†…å®¹': f"{ball}:{','.join(sorted(bets))}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': f"{ball}{'ã€'.join(ball_conflicts)}"}, 'ä¸¤é¢çŸ›ç›¾')
                }
                self._add_unique_result(results, 'ä¸¤é¢çŸ›ç›¾', record)
    
    def _analyze_ssc_douniu(self, account, lottery, period, group, results):
        douniu_group = group[group['ç©æ³•åˆ†ç±»'] == 'æ–—ç‰›']
        
        for _, row in douniu_group.iterrows():
            content = str(row['å†…å®¹'])
            bull_types = self.data_analyzer.extract_douniu_types(content)
            
            if len(bull_types) >= THRESHOLD_CONFIG['SSC']['douniu_multi']:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': 'æ–—ç‰›',
                    'å·ç æ•°é‡': len(bull_types),
                    'æŠ•æ³¨å†…å®¹': ', '.join(sorted(bull_types)),
                    'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(bull_types)}, 'æ–—ç‰›å¤šç ')
                }
                self._add_unique_result(results, 'æ–—ç‰›å¤šç ', record)
    
    def _analyze_ssc_dingwei(self, account, lottery, period, group, results):
        dingwei_categories = ['å®šä½èƒ†', '1-5çƒ', 'ç¬¬1çƒ', 'ç¬¬2çƒ', 'ç¬¬3çƒ', 'ç¬¬4çƒ', 'ç¬¬5çƒ']
        
        dingwei_group = group[group['ç©æ³•åˆ†ç±»'].isin(dingwei_categories)]
        
        position_numbers = defaultdict(set)
        
        for _, row in dingwei_group.iterrows():
            content = str(row['å†…å®¹'])
            category = str(row['ç©æ³•åˆ†ç±»'])
            
            # è¯†åˆ«å½©ç§ç±»å‹
            lottery_type = self.identify_lottery_type(lottery)
            
            # PK10ç«–çº¿åˆ†éš”æ ¼å¼å¤„ç†
            if lottery_type == 'PK10' and '|' in content and re.search(r'\d{2}', content):
                positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å']
                parts = content.split('|')
                
                for i, part in enumerate(parts):
                    if i < len(positions):
                        position = positions[i]
                        numbers = self.data_analyzer.extract_numbers_from_content(part, 1, 10)
                        position_numbers[position].update(numbers)
            
            # æ—¶æ—¶å½©ç«–çº¿åˆ†éš”æ ¼å¼å¤„ç†
            elif '|' in content:
                parts = content.split('|')
                positions = ['ç¬¬1çƒ', 'ç¬¬2çƒ', 'ç¬¬3çƒ', 'ç¬¬4çƒ', 'ç¬¬5çƒ']
                for i, part in enumerate(parts):
                    if i < len(positions) and part.strip() and part.strip() != '_':
                        numbers = self.data_analyzer.extract_numbers_from_content(part, 0, 9)
                        position_numbers[positions[i]].update(numbers)
            
            elif '-' in content:
                parts = content.split(',')
                for part in parts:
                    if '-' in part:
                        position, numbers_str = part.split('-', 1)
                        numbers = self.data_analyzer.extract_numbers_from_content(numbers_str, 0, 9)
                        position_numbers[position].update(numbers)
            
            else:
                numbers = self.data_analyzer.extract_numbers_from_content(content, 0, 9)
                if numbers:
                    position = 'ç¬¬1çƒ'
                    position_numbers[position].update(numbers)
        
        for position, numbers in position_numbers.items():
            if len(numbers) >= THRESHOLD_CONFIG['SSC']['dingwei_multi']:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': 'å®šä½èƒ†',
                    'ä½ç½®': position,
                    'å·ç æ•°é‡': len(numbers),
                    'æŠ•æ³¨å†…å®¹': f"{position}-{','.join([str(num) for num in sorted(numbers)])}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(numbers)}, 'å®šä½èƒ†å¤šç ')
                }
                self._add_unique_result(results, 'å®šä½èƒ†å¤šç ', record)
    
    def _analyze_ssc_zonghe(self, account, lottery, period, group, results):
        zonghe_group = group[group['ç©æ³•åˆ†ç±»'] == 'æ€»å’Œ']
        
        all_bets = set()
        
        for _, row in zonghe_group.iterrows():
            content = str(row['å†…å®¹'])
            bets = self.data_analyzer.extract_size_parity_from_content(content)
            all_bets.update(bets)
        
        conflicts = []
        if 'å¤§' in all_bets and 'å°' in all_bets:
            conflicts.append('å¤§å°')
        if 'å•' in all_bets and 'åŒ' in all_bets:
            conflicts.append('å•åŒ')
        
        if conflicts:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'æ€»å’Œ',
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(all_bets)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'æ€»å’ŒçŸ›ç›¾')
            }
            self._add_unique_result(results, 'æ€»å’ŒçŸ›ç›¾', record)
    
    def _analyze_ssc_dingwei_detailed(self, account, lottery, period, group, results):
        """æ—¶æ—¶å½©å®šä½èƒ†ç»†åˆ†ä½ç½®æ£€æµ‹ - å¢å¼ºä½ç½®åˆ¤æ–­"""
        dingwei_detailed_categories = [
            'å®šä½_ä¸‡ä½', 'å®šä½_åƒä½', 'å®šä½_ç™¾ä½', 'å®šä½_åä½', 'å®šä½_ä¸ªä½',
            'ä¸‡ä½', 'åƒä½', 'ç™¾ä½', 'åä½', 'ä¸ªä½',
            'ç¬¬1çƒ', 'ç¬¬2çƒ', 'ç¬¬3çƒ', 'ç¬¬4çƒ', 'ç¬¬5çƒ'
        ]
        
        dingwei_detailed_group = group[group['ç©æ³•åˆ†ç±»'].isin(dingwei_detailed_categories)]
        
        position_numbers = defaultdict(set)
        
        # ä¿®å¤è¿™é‡Œçš„ç¼©è¿›ï¼šæ•´ä¸ªforå¾ªç¯åº”è¯¥ç¼©è¿›
        for _, row in dingwei_detailed_group.iterrows():
            content = str(row['å†…å®¹'])
            category = str(row['ç©æ³•åˆ†ç±»'])
            
            # æ–°å¢ï¼šåŸºäºå†…å®¹é‡æ–°åˆ†ç±»
            actual_category = self.normalize_play_category_from_content(content, category, 'SSC')
            
            # å¢å¼ºä½ç½®åˆ¤æ–­ï¼šä»ç©æ³•åˆ†ç±»æ¨æ–­ä½ç½®
            inferred_position = self._infer_ssc_position_from_category(actual_category)  # ä½¿ç”¨ actual_category
        
            # ä½¿ç”¨ç»Ÿä¸€è§£æå™¨
            bets_by_position = ContentParser.parse_ssc_content(content)
            
            for position, bets in bets_by_position.items():
                # å¦‚æœè§£æå‡ºçš„ä½ç½®æ˜¯"æœªçŸ¥ä½ç½®"ï¼Œä½¿ç”¨ä»ç©æ³•åˆ†ç±»æ¨æ–­çš„ä½ç½®
                if position == 'æœªçŸ¥ä½ç½®' and inferred_position:
                    position = inferred_position
                
                # æå–æ¯ä¸ªä½ç½®çš„å·ç 
                for bet in bets:
                    numbers = self.data_analyzer.extract_numbers_from_content(bet, 0, 9)
                    position_numbers[position].update(numbers)
        
        # æ£€æŸ¥æ¯ä¸ªä½ç½®çš„è¶…ç 
        for position, numbers in position_numbers.items():
            if len(numbers) >= THRESHOLD_CONFIG['SSC']['dingwei_multi']:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': f'{position}å¤šç ',
                    'ä½ç½®': position,
                    'å·ç æ•°é‡': len(numbers),
                    'æŠ•æ³¨å†…å®¹': f"{position}-{','.join([str(num) for num in sorted(numbers)])}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(numbers)}, 'å®šä½èƒ†å¤šç ')
                }
                self._add_unique_result(results, 'å®šä½èƒ†å¤šç ', record)
    
    def _infer_ssc_position_from_category(self, category):
        """ä»æ—¶æ—¶å½©ç©æ³•åˆ†ç±»æ¨æ–­ä½ç½®"""
        category_str = str(category).strip()
        
        position_mapping = {
            'ç¬¬1çƒ': ['ç¬¬1çƒ', 'å®šä½_ä¸‡ä½', 'ä¸‡ä½'],
            'ç¬¬2çƒ': ['ç¬¬2çƒ', 'å®šä½_åƒä½', 'åƒä½'],
            'ç¬¬3çƒ': ['ç¬¬3çƒ', 'å®šä½_ç™¾ä½', 'ç™¾ä½'],
            'ç¬¬4çƒ': ['ç¬¬4çƒ', 'å®šä½_åä½', 'åä½'],
            'ç¬¬5çƒ': ['ç¬¬5çƒ', 'å®šä½_ä¸ªä½', 'ä¸ªä½']
        }
        
        for position, keywords in position_mapping.items():
            for keyword in keywords:
                if keyword in category_str:
                    return position
        
        return None

    # =============== å…­åˆå½©åˆ†ææ–¹æ³• ===============
    def analyze_lhc_patterns(self, df):
        """åˆ†æå…­åˆå½©æŠ•æ³¨æ¨¡å¼"""
        results = defaultdict(list)
        
        df_target = df[df['å½©ç§'].apply(self.identify_lottery_type) == 'LHC']
        
        if len(df_target) == 0:
            return results
        
        # ä½¿ç”¨ç‹¬ç«‹çš„å°¾æ•°æ£€æµ‹æ–¹æ³•
        self._analyze_lhc_tail_plays(df_target, results)
        
        # å…¶ä»–æ£€æµ‹æ–¹æ³•
        grouped = df_target.groupby(['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·'])
        
        for (account, lottery, period), group in grouped:
            self._analyze_lhc_zhengma_wave_comprehensive(account, lottery, period, group, results)
            
            # å…¶ä»–æ£€æµ‹æ–¹æ³•ä¿æŒä¸å˜
            self._analyze_lhc_lianxiao(account, lottery, period, group, results)
            self._analyze_lhc_lianwei(account, lottery, period, group, results)
            self._analyze_lhc_tema(account, lottery, period, group, results)
            self._analyze_lhc_two_sides(account, lottery, period, group, results)
            self._analyze_lhc_zhengma(account, lottery, period, group, results)
            self._analyze_lhc_zhengte(account, lottery, period, group, results)
            self._analyze_lhc_pingte(account, lottery, period, group, results)
            self._analyze_lhc_texiao(account, lottery, period, group, results)
            self._analyze_lhc_yixiao(account, lottery, period, group, results)
            self._analyze_lhc_wave(account, lottery, period, group, results)
            self._analyze_lhc_five_elements(account, lottery, period, group, results)
            self._analyze_lhc_banbo(account, lottery, period, group, results)
        
        return results
    
    def _analyze_lhc_tail_plays(self, df_target, results):
        """åˆ†æå…­åˆå½©å°¾æ•°ç©æ³•çš„å®Œæ•´é€»è¾‘ - ä»Colabç‰ˆæœ¬ç§»æ¤"""
        tail_categories = ['å°¾æ•°', 'å°¾æ•°_å¤´å°¾æ•°', 'ç‰¹å°¾', 'å…¨å°¾']
        
        # æŒ‰ä¸åŒå°¾æ•°åˆ†ç±»åˆ†åˆ«åˆ†æ
        for tail_category in tail_categories:
            grouped = df_target[df_target['ç©æ³•åˆ†ç±»'] == tail_category].groupby(
                ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·']
            )
            
            for (account, lottery, period), group in grouped:
                # ä½¿ç”¨å­—å…¸æŒ‰è°ƒæ•´åçš„åˆ†ç±»èšåˆå°¾æ•°
                category_tails = defaultdict(set)
                category_contents = defaultdict(list)
                
                for _, row in group.iterrows():
                    content = str(row['å†…å®¹'])
                    category = str(row['ç©æ³•åˆ†ç±»'])
                    
                    # æ–°å¢ï¼šåŸºäºå†…å®¹é‡æ–°åˆ†ç±»
                    actual_category = self.normalize_play_category_from_content(content, category, 'LHC')
                    
                    clean_content = self.data_analyzer.parse_lhc_special_content(content)
                    tails = self.data_analyzer.extract_tails_from_content(clean_content)
                    category_tails[actual_category].update(tails)
                    category_contents[actual_category].append(clean_content)
                
                # å¯¹æ¯ä¸ªè°ƒæ•´åçš„åˆ†ç±»åˆ†åˆ«æ£€æŸ¥é˜ˆå€¼
                for actual_category, tails_set in category_tails.items():
                    if len(tails_set) >= THRESHOLD_CONFIG['LHC']['tail_play']:
                        # æ ¹æ®ä¸åŒçš„å°¾æ•°åˆ†ç±»ï¼Œä½¿ç”¨ä¸åŒçš„ç»“æœé”®å
                        if actual_category == 'å°¾æ•°':
                            result_key = 'å°¾æ•°å¤šç '
                        elif actual_category == 'å°¾æ•°_å¤´å°¾æ•°':
                            result_key = 'å°¾æ•°å¤´å°¾å¤šç '
                        elif actual_category == 'ç‰¹å°¾':
                            result_key = 'ç‰¹å°¾å¤šå°¾'
                        elif actual_category == 'å…¨å°¾':
                            result_key = 'å…¨å°¾å¤šå°¾'
                        else:
                            result_key = 'å°¾æ•°å¤šç '
                        
                        # æ„å»ºæŠ•æ³¨å†…å®¹æ˜¾ç¤º - æ˜¾ç¤ºå…·ä½“çš„å°¾æ•°åˆ—è¡¨
                        bet_content = ', '.join([f"{tail}å°¾" for tail in sorted(tails_set)])
                        
                        record = {
                            'ä¼šå‘˜è´¦å·': account,
                            'å½©ç§': lottery,
                            'æœŸå·': period,
                            'ç©æ³•åˆ†ç±»': f"{actual_category}ï¼ˆ{', '.join([str(tail) for tail in sorted(tails_set)])}ï¼‰",
                            'å°¾æ•°æ•°é‡': len(tails_set),
                            'å·ç æ•°é‡': len(tails_set),  # å…¼å®¹å­—æ®µ
                            'æŠ•æ³¨å†…å®¹': bet_content,
                            'æ’åºæƒé‡': self._calculate_sort_weight({'å°¾æ•°æ•°é‡': len(tails_set)}, result_key)
                        }
                        self._add_unique_result(results, result_key, record)
    
    def _analyze_lhc_tema(self, account, lottery, period, group, results):
        tema_group = group[group['ç©æ³•åˆ†ç±»'] == 'ç‰¹ç ']
        
        all_numbers = set()
        
        for _, row in tema_group.iterrows():
            content = str(row['å†…å®¹'])
            clean_content = self.data_analyzer.parse_lhc_special_content(content)
            numbers = self.data_analyzer.extract_numbers_from_content(
                clean_content, 1, 49
            )
            all_numbers.update(numbers)
        
        if len(all_numbers) >= THRESHOLD_CONFIG['LHC']['number_play']:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'ç‰¹ç ',
                'å·ç æ•°é‡': len(all_numbers),
                'æŠ•æ³¨å†…å®¹': ', '.join([f"{num:02d}" for num in sorted(all_numbers)]),
                'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'ç‰¹ç å¤šç ')
            }
            self._add_unique_result(results, 'ç‰¹ç å¤šç ', record)
    
    def _analyze_lhc_two_sides(self, account, lottery, period, group, results):
        two_sides_group = group[group['ç©æ³•åˆ†ç±»'] == 'ä¸¤é¢']
        
        all_bets = {
            'range_bet': set(),
            'normal_size': set(),
            'tail_size': set(),
            'parity': set(),
            'sum_parity': set(),
            'animal_type': set(),
            'zodiac': set(),
            'wave': set()
        }
        
        for _, row in two_sides_group.iterrows():
            content = str(row['å†…å®¹'])
            
            two_sides_analysis = self.data_analyzer.extract_lhc_two_sides_content(content)
            
            for bet_type in two_sides_analysis:
                if bet_type in all_bets:
                    all_bets[bet_type].update(two_sides_analysis[bet_type])
        
        # åŒºé—´å¤šç»„ - ä¿®å¤ï¼šæ˜¾ç¤ºå…·ä½“çš„åŒºé—´å†…å®¹
        if len(all_bets['range_bet']) >= THRESHOLD_CONFIG['LHC']['range_bet']:
            # å°†åŒºé—´é›†åˆè½¬æ¢ä¸ºæ’åºåçš„åˆ—è¡¨
            sorted_ranges = sorted(list(all_bets['range_bet']))
            bet_content = ', '.join(sorted_ranges)
            
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'ä¸¤é¢',
                'æŠ•æ³¨åŒºé—´æ•°': len(all_bets['range_bet']),
                'æŠ•æ³¨åŒºé—´': sorted_ranges,
                'æŠ•æ³¨å†…å®¹': bet_content,  # æ·»åŠ æŠ•æ³¨å†…å®¹å­—æ®µ
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨åŒºé—´æ•°': len(all_bets['range_bet'])}, 'åŒºé—´å¤šç»„')
            }
            self._add_unique_result(results, 'åŒºé—´å¤šç»„', record)
        
        conflict_types = []
        
        if 'å¤§' in all_bets.get('normal_size', set()) and 'å°' in all_bets.get('normal_size', set()):
            conflict_types.append('å¤§å°çŸ›ç›¾')
        
        if 'å°¾å¤§' in all_bets.get('tail_size', set()) and 'å°¾å°' in all_bets.get('tail_size', set()):
            conflict_types.append('å°¾å¤§å°çŸ›ç›¾')
        
        if 'å•' in all_bets.get('parity', set()) and 'åŒ' in all_bets.get('parity', set()):
            conflict_types.append('å•åŒçŸ›ç›¾')
        
        if 'åˆå•' in all_bets.get('sum_parity', set()) and 'åˆåŒ' in all_bets.get('sum_parity', set()):
            conflict_types.append('åˆæ•°å•åŒçŸ›ç›¾')
        
        if 'å®¶ç¦½' in all_bets.get('animal_type', set()) and 'é‡å…½' in all_bets.get('animal_type', set()):
            conflict_types.append('å®¶ç¦½é‡å…½çŸ›ç›¾')
        
        if conflict_types:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'ä¸¤é¢',
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types),
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types)}, 'ä¸¤é¢ç©æ³•çŸ›ç›¾')
            }
            self._add_unique_result(results, 'ä¸¤é¢ç©æ³•çŸ›ç›¾', record)
        
        wave_set = all_bets.get('wave', set())
        if len(wave_set) >= THRESHOLD_CONFIG['LHC']['wave_bet']:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'ä¸¤é¢',
                'æŠ•æ³¨æ³¢è‰²æ•°': len(wave_set),
                'æŠ•æ³¨æ³¢è‰²': sorted(list(wave_set)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨æ³¢è‰²æ•°': len(wave_set)}, 'æ³¢è‰²ä¸‰ç»„')
            }
            self._add_unique_result(results, 'æ³¢è‰²ä¸‰ç»„', record)
    
    def _analyze_lhc_zhengma(self, account, lottery, period, group, results):
        zhengma_group = group[group['ç©æ³•åˆ†ç±»'] == 'æ­£ç ']
        
        all_numbers = set()
        
        for _, row in zhengma_group.iterrows():
            content = str(row['å†…å®¹'])
            clean_content = self.data_analyzer.parse_lhc_special_content(content)
            numbers = self.data_analyzer.extract_numbers_from_content(
                clean_content, 1, 49
            )
            all_numbers.update(numbers)
        
        if len(all_numbers) >= THRESHOLD_CONFIG['LHC']['number_play']:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'æ­£ç ',
                'å·ç æ•°é‡': len(all_numbers),
                'æŠ•æ³¨å†…å®¹': ', '.join([f"{num:02d}" for num in sorted(all_numbers)]),
                'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'æ­£ç å¤šç ')
            }
            self._add_unique_result(results, 'æ­£ç å¤šç ', record)
    
    def _analyze_lhc_zhengma_1_6(self, account, lottery, period, group, results):
        """å…­åˆå½©æ­£ç 1-6æ£€æµ‹ - å¢å¼ºä½ç½®åˆ¤æ–­"""
        zhengma_1_6_group = group[group['ç©æ³•åˆ†ç±»'] == 'æ­£ç 1-6']
        
        if zhengma_1_6_group.empty:
            return
        
        position_bets = defaultdict(lambda: defaultdict(set))
        
        for _, row in zhengma_1_6_group.iterrows():
            content = str(row['å†…å®¹'])
            
            # ä½¿ç”¨ç»Ÿä¸€è§£æå™¨
            bets_by_position = ContentParser.parse_lhc_zhengma_content(content)
            
            for position, bets in bets_by_position.items():
                # æ ‡å‡†åŒ–ä½ç½®åç§°
                normalized_position = self._normalize_zhengma_position(position)
                
                for bet in bets:
                    if bet == 'åˆå•':
                        position_bets[normalized_position]['sum_parity'].add('åˆå•')
                    elif bet == 'åˆåŒ':
                        position_bets[normalized_position]['sum_parity'].add('åˆåŒ')
                    # å¯ä»¥æ·»åŠ å…¶ä»–æŠ•æ³¨ç±»å‹çš„è§£æ
            
            # æ£€æŸ¥æ¯ä¸ªä½ç½®çš„çŸ›ç›¾
            for position, bets_by_type in position_bets.items():
                conflicts = []
                
                # åˆæ•°å•åŒçŸ›ç›¾
                sum_parity_bets = bets_by_type.get('sum_parity', set())
                if 'åˆå•' in sum_parity_bets and 'åˆåŒ' in sum_parity_bets:
                    conflicts.append('åˆæ•°å•åŒçŸ›ç›¾')
                
                if conflicts:
                    record = {
                        'ä¼šå‘˜è´¦å·': account,
                        'å½©ç§': lottery,
                        'æœŸå·': period,
                        'ç©æ³•åˆ†ç±»': 'æ­£ç 1-6',
                        'ä½ç½®': position,
                        'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                        'æŠ•æ³¨å†…å®¹': f"{position}-{','.join(sorted(sum_parity_bets))}",
                        'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'æ­£ç 1-6çŸ›ç›¾')
                    }
                    self._add_unique_result(results, 'æ­£ç 1-6çŸ›ç›¾', record)
    
    def _normalize_zhengma_position(self, position):
        """æ ‡å‡†åŒ–æ­£ç ä½ç½®åç§° - ä¿®å¤ç‰ˆæœ¬"""
        position_mapping = {
            # ä¸­æ–‡æ ‡å‡†æ ¼å¼
            'æ­£ç ä¸€': 'æ­£ç ä¸€', 'æ­£1': 'æ­£ç ä¸€', 'æ­£ç 1': 'æ­£ç ä¸€',
            'æ­£ç äºŒ': 'æ­£ç äºŒ', 'æ­£2': 'æ­£ç äºŒ', 'æ­£ç 2': 'æ­£ç äºŒ', 
            'æ­£ç ä¸‰': 'æ­£ç ä¸‰', 'æ­£3': 'æ­£ç ä¸‰', 'æ­£ç 3': 'æ­£ç ä¸‰',
            'æ­£ç å››': 'æ­£ç å››', 'æ­£4': 'æ­£ç å››', 'æ­£ç 4': 'æ­£ç å››',
            'æ­£ç äº”': 'æ­£ç äº”', 'æ­£5': 'æ­£ç äº”', 'æ­£ç 5': 'æ­£ç äº”',
            'æ­£ç å…­': 'æ­£ç å…­', 'æ­£6': 'æ­£ç å…­', 'æ­£ç 6': 'æ­£ç å…­',
            # å¤„ç†å¯èƒ½çš„æ•°å­—æ ¼å¼
            '1': 'æ­£ç ä¸€', '2': 'æ­£ç äºŒ', '3': 'æ­£ç ä¸‰',
            '4': 'æ­£ç å››', '5': 'æ­£ç äº”', '6': 'æ­£ç å…­',
            # é»˜è®¤æ˜ å°„
            'æœªçŸ¥ä½ç½®': 'æ­£ç ä¸€'
        }
        
        position = position.strip()
        
        # ç›´æ¥æ˜ å°„
        if position in position_mapping:
            return position_mapping[position]
        
        # æ¨¡ç³ŠåŒ¹é…
        for key, value in position_mapping.items():
            if key in position:
                return value
        
        # å¦‚æœåŒ…å«æ•°å­—ï¼Œå°è¯•æå–æ•°å­—å¹¶æ˜ å°„
        import re
        digit_match = re.search(r'\d', position)
        if digit_match:
            digit = digit_match.group()
            if digit in position_mapping:
                return position_mapping[digit]
        
        # è¿”å›åŸä½ç½®ï¼Œä½†ç¡®ä¿è‡³å°‘æ˜¯ä¸­æ–‡æ ¼å¼
        return position

    def _extract_specific_zhengte_position(self, content, category):
        """ç²¾ç¡®æå–æ­£ç‰¹çš„å…·ä½“ä½ç½®"""
        content_str = str(content)
        category_str = str(category)
        
        # ä½ç½®æ˜ å°„
        position_mapping = {
            'æ­£1ç‰¹': ['æ­£1ç‰¹', 'æ­£ä¸€ç‰¹', 'æ­£ç ä¸€ç‰¹', 'æ­£ç 1ç‰¹'],
            'æ­£2ç‰¹': ['æ­£2ç‰¹', 'æ­£äºŒç‰¹', 'æ­£ç äºŒç‰¹', 'æ­£ç 2ç‰¹'],
            'æ­£3ç‰¹': ['æ­£3ç‰¹', 'æ­£ä¸‰ç‰¹', 'æ­£ç ä¸‰ç‰¹', 'æ­£ç 3ç‰¹'],
            'æ­£4ç‰¹': ['æ­£4ç‰¹', 'æ­£å››ç‰¹', 'æ­£ç å››ç‰¹', 'æ­£ç 4ç‰¹'],
            'æ­£5ç‰¹': ['æ­£5ç‰¹', 'æ­£äº”ç‰¹', 'æ­£ç äº”ç‰¹', 'æ­£ç 5ç‰¹'],
            'æ­£6ç‰¹': ['æ­£6ç‰¹', 'æ­£å…­ç‰¹', 'æ­£ç å…­ç‰¹', 'æ­£ç 6ç‰¹']
        }
        
        # é¦–å…ˆæ£€æŸ¥åˆ†ç±»æœ¬èº«æ˜¯å¦å·²ç»æ˜¯å…·ä½“ä½ç½®
        for position, keywords in position_mapping.items():
            for keyword in keywords:
                if keyword in category_str:
                    return position
        
        # å¦‚æœåˆ†ç±»æ˜¯"æ­£ç‰¹"ï¼Œä»å†…å®¹ä¸­æå–å…·ä½“ä½ç½®
        if category_str == 'æ­£ç‰¹':
            for position, keywords in position_mapping.items():
                for keyword in keywords:
                    if keyword in content_str:
                        return position
            
            # å¦‚æœå†…å®¹ä¸­åŒ…å«æ•°å­—ï¼Œå°è¯•æ¨æ–­ä½ç½®
            if 'æ­£ç ä¸€' in content_str or 'æ­£1' in content_str:
                return 'æ­£1ç‰¹'
            elif 'æ­£ç äºŒ' in content_str or 'æ­£2' in content_str:
                return 'æ­£2ç‰¹'
            elif 'æ­£ç ä¸‰' in content_str or 'æ­£3' in content_str:
                return 'æ­£3ç‰¹'
            elif 'æ­£ç å››' in content_str or 'æ­£4' in content_str:
                return 'æ­£4ç‰¹'
            elif 'æ­£ç äº”' in content_str or 'æ­£5' in content_str:
                return 'æ­£5ç‰¹'
            elif 'æ­£ç å…­' in content_str or 'æ­£6' in content_str:
                return 'æ­£6ç‰¹'
        
        # é»˜è®¤è¿”å›åˆ†ç±»åç§°
        return category_str
    
    def _analyze_lhc_zhengte(self, account, lottery, period, group, results):
        """åˆ†æå…­åˆå½©æ­£ç‰¹ç©æ³• - æ¢å¤åŸæœ‰é€»è¾‘"""
        zhengte_categories = ['æ­£ç‰¹', 'æ­£1ç‰¹', 'æ­£2ç‰¹', 'æ­£3ç‰¹', 'æ­£4ç‰¹', 'æ­£5ç‰¹', 'æ­£6ç‰¹']
        
        # æŒ‰å…·ä½“ä½ç½®åˆ†åˆ«ç»Ÿè®¡ - ä½¿ç”¨åŸæœ‰é€»è¾‘
        position_numbers = defaultdict(set)
        position_bets = defaultdict(lambda: defaultdict(set))
        
        for category in zhengte_categories:
            category_group = group[group['ç©æ³•åˆ†ç±»'] == category]
            
            for _, row in category_group.iterrows():
                content = str(row['å†…å®¹'])
                category = str(row['ç©æ³•åˆ†ç±»'])
                
                # ç²¾ç¡®è¯†åˆ«å…·ä½“ä½ç½® - ä½¿ç”¨åŸæœ‰æ–¹æ³•
                specific_position = self._extract_specific_zhengte_position(content, category)
                
                clean_content = self.data_analyzer.parse_lhc_special_content(content)
                
                # æå–å·ç 
                numbers = self.data_analyzer.extract_numbers_from_content(clean_content, 1, 49)
                position_numbers[specific_position].update(numbers)
        
        # å¯¹æ¯ä¸ªå…·ä½“ä½ç½®åˆ†åˆ«è¿›è¡Œæ£€æµ‹ - åŸæœ‰é€»è¾‘
        for position, numbers in position_numbers.items():
            # å¤šå·ç æ£€æµ‹
            if len(numbers) >= THRESHOLD_CONFIG['LHC']['number_play']:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': f'{position}å¤šç ',
                    'ä½ç½®': position,
                    'å·ç æ•°é‡': len(numbers),
                    'æŠ•æ³¨å†…å®¹': f"{position}: {', '.join([f'{num:02d}' for num in sorted(numbers)])}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(numbers)}, f'{position}å¤šç ')
                }
                self._add_unique_result(results, f'{position}å¤šç ', record)
            
            # çŸ›ç›¾æŠ•æ³¨æ£€æµ‹
            bets_for_position = position_bets[position]
            conflicts = []
            
            if 'å¤§' in bets_for_position.get('normal_size', set()) and 'å°' in bets_for_position.get('normal_size', set()):
                conflicts.append('å¤§å°çŸ›ç›¾')
            if 'å•' in bets_for_position.get('parity', set()) and 'åŒ' in bets_for_position.get('parity', set()):
                conflicts.append('å•åŒçŸ›ç›¾')
            if 'å°¾å¤§' in bets_for_position.get('tail_size', set()) and 'å°¾å°' in bets_for_position.get('tail_size', set()):
                conflicts.append('å°¾å¤§å°çŸ›ç›¾')
            if 'åˆå•' in bets_for_position.get('sum_parity', set()) and 'åˆåŒ' in bets_for_position.get('sum_parity', set()):
                conflicts.append('åˆæ•°å•åŒçŸ›ç›¾')
            
            if conflicts:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': position,
                    'ä½ç½®': position,
                    'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                    'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, f'{position}çŸ›ç›¾')
                }
                self._add_unique_result(results, f'{position}çŸ›ç›¾', record)
    
    def _analyze_lhc_pingte(self, account, lottery, period, group, results):
        pingte_group = group[group['ç©æ³•åˆ†ç±»'] == 'å¹³ç‰¹']
        
        all_zodiacs = set()
        
        for _, row in pingte_group.iterrows():
            content = str(row['å†…å®¹'])
            clean_content = self.data_analyzer.parse_lhc_special_content(content)
            zodiacs = self.data_analyzer.extract_zodiacs_from_content(clean_content)
            all_zodiacs.update(zodiacs)
        
        if len(all_zodiacs) >= THRESHOLD_CONFIG['LHC']['zodiac_play']:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'å¹³ç‰¹',
                'ç”Ÿè‚–æ•°é‡': len(all_zodiacs),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(all_zodiacs)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'ç”Ÿè‚–æ•°é‡': len(all_zodiacs)}, 'å¹³ç‰¹å¤šè‚–')
            }
            self._add_unique_result(results, 'å¹³ç‰¹å¤šè‚–', record)
    
    def _analyze_lhc_texiao(self, account, lottery, period, group, results):
        texiao_group = group[group['ç©æ³•åˆ†ç±»'] == 'ç‰¹è‚–']
        
        all_zodiacs = set()
        
        for _, row in texiao_group.iterrows():
            content = str(row['å†…å®¹'])
            clean_content = self.data_analyzer.parse_lhc_special_content(content)
            zodiacs = self.data_analyzer.extract_zodiacs_from_content(clean_content)
            all_zodiacs.update(zodiacs)
        
        if len(all_zodiacs) >= THRESHOLD_CONFIG['LHC']['zodiac_play']:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'ç‰¹è‚–',
                'ç”Ÿè‚–æ•°é‡': len(all_zodiacs),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(all_zodiacs)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'ç”Ÿè‚–æ•°é‡': len(all_zodiacs)}, 'ç‰¹è‚–å¤šè‚–')
            }
            self._add_unique_result(results, 'ç‰¹è‚–å¤šè‚–', record)
    
    def _analyze_lhc_yixiao(self, account, lottery, period, group, results):
        yixiao_group = group[group['ç©æ³•åˆ†ç±»'] == 'ä¸€è‚–']
        
        all_zodiacs = set()
        
        for _, row in yixiao_group.iterrows():
            content = str(row['å†…å®¹'])
            clean_content = self.data_analyzer.parse_lhc_special_content(content)
            zodiacs = self.data_analyzer.extract_zodiacs_from_content(clean_content)
            all_zodiacs.update(zodiacs)
        
        if len(all_zodiacs) >= THRESHOLD_CONFIG['LHC']['zodiac_play']:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'ä¸€è‚–',
                'ç”Ÿè‚–æ•°é‡': len(all_zodiacs),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(all_zodiacs)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'ç”Ÿè‚–æ•°é‡': len(all_zodiacs)}, 'ä¸€è‚–å¤šè‚–')
            }
            self._add_unique_result(results, 'ä¸€è‚–å¤šè‚–', record)
    
    def _analyze_lhc_wave(self, account, lottery, period, group, results):
        """å…­åˆå½©è‰²æ³¢æ£€æµ‹ - åŒ…å«åŠæ³¢å†…å®¹æ£€æµ‹ï¼Œä¸ƒè‰²æ³¢å°±æ˜¯è‰²æ³¢"""
        wave_group = group[group['ç©æ³•åˆ†ç±»'] == 'è‰²æ³¢']
        
        if wave_group.empty:
            return
        
        # æ”¶é›†æ‰€æœ‰æ³¢è‰²æŠ•æ³¨å’ŒåŠæ³¢æŠ•æ³¨
        all_wave_bets = set()
        all_banbo_bets = set()  # åŠæ³¢æŠ•æ³¨
        
        # å®šä¹‰åŠæ³¢æŠ•æ³¨é¡¹
        banbo_items = {
            'çº¢å¤§', 'çº¢å°', 'çº¢å•', 'çº¢åŒ',
            'è“å¤§', 'è“å°', 'è“å•', 'è“åŒ', 
            'ç»¿å¤§', 'ç»¿å°', 'ç»¿å•', 'ç»¿åŒ'
        }
        
        for _, row in wave_group.iterrows():
            content = str(row['å†…å®¹'])
            clean_content = self.data_analyzer.parse_lhc_special_content(content)
            
            # æå–ä¼ ç»Ÿæ³¢è‰²
            waves = self.data_analyzer.extract_wave_color_from_content(clean_content)
            all_wave_bets.update(waves)
            
            # æå–åŠæ³¢æŠ•æ³¨é¡¹
            for item in banbo_items:
                if item in clean_content:
                    all_banbo_bets.add(item)
        
        # æ£€æµ‹1: ä¼ ç»Ÿè‰²æ³¢å…¨åŒ…ï¼ˆçº¢æ³¢ã€è“æ³¢ã€ç»¿æ³¢ï¼‰- ä¸ƒè‰²æ³¢å°±æ˜¯è‰²æ³¢
        traditional_waves = {'çº¢æ³¢', 'è“æ³¢', 'ç»¿æ³¢'}
        if traditional_waves.issubset(all_wave_bets):
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'è‰²æ³¢',
                'è¿è§„ç±»å‹': 'è‰²æ³¢å…¨åŒ…',
                'æŠ•æ³¨æ³¢è‰²æ•°': len(traditional_waves),
                'æŠ•æ³¨æ³¢è‰²': sorted(list(traditional_waves)),
                'æŠ•æ³¨å†…å®¹': f"è‰²æ³¢å…¨åŒ…: {', '.join(sorted(traditional_waves))}",
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨æ³¢è‰²æ•°': len(traditional_waves)}, 'è‰²æ³¢å…¨åŒ…')
            }
            self._add_unique_result(results, 'è‰²æ³¢å…¨åŒ…', record)
        
        # æ£€æµ‹2: è‰²æ³¢ç©æ³•ä¸­çš„åŠæ³¢å…¨åŒ…æ£€æµ‹
        # å¤§å°å…¨åŒ…æ£€æµ‹
        size_full_set = {'çº¢å¤§', 'çº¢å°', 'è“å¤§', 'è“å°', 'ç»¿å¤§', 'ç»¿å°'}
        if size_full_set.issubset(all_banbo_bets):
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'è‰²æ³¢',
                'è¿è§„ç±»å‹': 'è‰²æ³¢ä¸­åŠæ³¢å¤§å°å…¨åŒ…',
                'æŠ•æ³¨åŠæ³¢æ•°': len(size_full_set),
                'æŠ•æ³¨åŠæ³¢': sorted(list(size_full_set)),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(size_full_set)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨åŠæ³¢æ•°': len(size_full_set)}, 'è‰²æ³¢ä¸­åŠæ³¢å¤§å°å…¨åŒ…')
            }
            self._add_unique_result(results, 'è‰²æ³¢ä¸­åŠæ³¢å…¨åŒ…', record)
        
        # å•åŒå…¨åŒ…æ£€æµ‹
        parity_full_set = {'çº¢å•', 'çº¢åŒ', 'è“å•', 'è“åŒ', 'ç»¿å•', 'ç»¿åŒ'}
        if parity_full_set.issubset(all_banbo_bets):
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'è‰²æ³¢',
                'è¿è§„ç±»å‹': 'è‰²æ³¢ä¸­åŠæ³¢å•åŒå…¨åŒ…',
                'æŠ•æ³¨åŠæ³¢æ•°': len(parity_full_set),
                'æŠ•æ³¨åŠæ³¢': sorted(list(parity_full_set)),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(parity_full_set)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨åŠæ³¢æ•°': len(parity_full_set)}, 'è‰²æ³¢ä¸­åŠæ³¢å•åŒå…¨åŒ…')
            }
            self._add_unique_result(results, 'è‰²æ³¢ä¸­åŠæ³¢å…¨åŒ…', record)
    
    def _analyze_lhc_five_elements(self, account, lottery, period, group, results):
        five_elements_group = group[group['ç©æ³•åˆ†ç±»'] == 'äº”è¡Œ']
        
        all_elements = set()
        
        for _, row in five_elements_group.iterrows():
            content = str(row['å†…å®¹'])
            clean_content = self.data_analyzer.parse_lhc_special_content(content)
            elements = self.data_analyzer.extract_five_elements_from_content(clean_content)
            all_elements.update(elements)
        
        if len(all_elements) >= THRESHOLD_CONFIG['LHC']['five_elements']:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'äº”è¡Œ',
                'æŠ•æ³¨äº”è¡Œæ•°': len(all_elements),
                'æŠ•æ³¨äº”è¡Œ': sorted(list(all_elements)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨äº”è¡Œæ•°': len(all_elements)}, 'äº”è¡Œå¤šç»„')
            }
            self._add_unique_result(results, 'äº”è¡Œå¤šç»„', record)
    
    def _analyze_lhc_lianxiao(self, account, lottery, period, group, results):
        """åˆ†æå…­åˆå½©è¿è‚–ç©æ³• - ä¿®å¤ç‰ˆæœ¬ï¼Œç¡®ä¿åŒºåˆ†å…·ä½“ç±»å‹"""
        # å®šä¹‰è¿è‚–ç±»å‹åŠå…¶å¯¹åº”çš„é˜ˆå€¼
        lianxiao_config = {
            'äºŒè¿è‚–': {'threshold': 7},
            'ä¸‰è¿è‚–': {'threshold': 7},  
            'å››è¿è‚–': {'threshold': 7},
            'äº”è¿è‚–': {'threshold': 8},
        }
        
        # é¦–å…ˆæ£€æŸ¥å…·ä½“çš„è¿è‚–ç±»å‹
        for lianxiao_type, config in lianxiao_config.items():
            lianxiao_group = group[group['ç©æ³•åˆ†ç±»'] == lianxiao_type]
            
            for _, row in lianxiao_group.iterrows():
                content = str(row['å†…å®¹'])
                category = str(row['ç©æ³•åˆ†ç±»'])
                
                # è§£æç©æ³•-æŠ•æ³¨å†…å®¹æ ¼å¼
                if '-' in content:
                    parts = content.split('-', 1)
                    bet_content = parts[1].strip()
                else:
                    bet_content = content
                    
                zodiacs = self.data_analyzer.extract_zodiacs_from_content(bet_content)
                
                # ä½¿ç”¨é’ˆå¯¹å…·ä½“è¿è‚–ç±»å‹çš„é˜ˆå€¼
                if len(zodiacs) >= config['threshold']:
                    record = {
                        'ä¼šå‘˜è´¦å·': account,
                        'å½©ç§': lottery,
                        'æœŸå·': period,
                        'ç©æ³•åˆ†ç±»': f"{lianxiao_type}ï¼ˆ{len(zodiacs)}ç”Ÿè‚–ï¼‰",
                        'è¿è§„ç±»å‹': f'{lianxiao_type}å¤šè‚–',
                        'ç”Ÿè‚–æ•°é‡': len(zodiacs),
                        'æŠ•æ³¨å†…å®¹': ', '.join(sorted(zodiacs)),
                        'æ’åºæƒé‡': self._calculate_sort_weight({'ç”Ÿè‚–æ•°é‡': len(zodiacs)}, f'{lianxiao_type}å¤šè‚–')
                    }
                    self._add_unique_result(results, f'{lianxiao_type}å¤šè‚–', record)
        
        # ç„¶åæ£€æŸ¥é€šç”¨çš„è¿è‚–ç±»å‹ï¼ˆä½œä¸ºåå¤‡ï¼‰
        generic_lianxiao_group = group[group['ç©æ³•åˆ†ç±»'] == 'è¿è‚–']
        if not generic_lianxiao_group.empty:
            # å°è¯•ä»å†…å®¹ä¸­æ¨æ–­å…·ä½“ç±»å‹
            for _, row in generic_lianxiao_group.iterrows():
                content = str(row['å†…å®¹'])
                
                # ä»å†…å®¹ä¸­æ¨æ–­å…·ä½“è¿è‚–ç±»å‹
                inferred_type = self._infer_lianxiao_type_from_content(content)
                
                # è§£æç©æ³•-æŠ•æ³¨å†…å®¹æ ¼å¼
                if '-' in content:
                    parts = content.split('-', 1)
                    bet_content = parts[1].strip()
                else:
                    bet_content = content
                    
                zodiacs = self.data_analyzer.extract_zodiacs_from_content(bet_content)
                
                # æ ¹æ®æ¨æ–­çš„ç±»å‹ä½¿ç”¨ç›¸åº”çš„é˜ˆå€¼ï¼Œå¦‚æœæ²¡æœ‰æ¨æ–­å‡ºç±»å‹åˆ™ä½¿ç”¨é€šç”¨é˜ˆå€¼
                if inferred_type and inferred_type in lianxiao_config:
                    threshold = lianxiao_config[inferred_type]['threshold']
                    display_type = inferred_type
                else:
                    threshold = 6  # é€šç”¨é˜ˆå€¼
                    display_type = 'è¿è‚–'
                
                if len(zodiacs) >= threshold:
                    record = {
                        'ä¼šå‘˜è´¦å·': account,
                        'å½©ç§': lottery,
                        'æœŸå·': period,
                        'ç©æ³•åˆ†ç±»': f"{display_type}ï¼ˆ{len(zodiacs)}ç”Ÿè‚–ï¼‰",
                        'è¿è§„ç±»å‹': f'{display_type}å¤šè‚–',
                        'ç”Ÿè‚–æ•°é‡': len(zodiacs),
                        'æŠ•æ³¨å†…å®¹': ', '.join(sorted(zodiacs)),
                        'æ’åºæƒé‡': self._calculate_sort_weight({'ç”Ÿè‚–æ•°é‡': len(zodiacs)}, f'{display_type}å¤šè‚–')
                    }
                    self._add_unique_result(results, f'{display_type}å¤šè‚–', record)
    
    def _infer_lianxiao_type_from_content(self, content):
        """ä»å†…å®¹ä¸­æ¨æ–­è¿è‚–ç±»å‹"""
        content_str = str(content)
        
        # ä»å†…å®¹ä¸­æŸ¥æ‰¾å…·ä½“ç±»å‹
        if 'äºŒè¿è‚–' in content_str:
            return 'äºŒè¿è‚–'
        elif 'ä¸‰è¿è‚–' in content_str:
            return 'ä¸‰è¿è‚–'
        elif 'å››è¿è‚–' in content_str:
            return 'å››è¿è‚–'
        elif 'äº”è¿è‚–' in content_str:
            return 'äº”è¿è‚–'
        
        return None
    
    def _analyze_lhc_lianwei(self, account, lottery, period, group, results):
        """åˆ†æå…­åˆå½©è¿å°¾ç©æ³• - ä¿®å¤ç‰ˆæœ¬ï¼Œç¡®ä¿åŒºåˆ†å…·ä½“ç±»å‹"""
        # å®šä¹‰è¿å°¾ç±»å‹åŠå…¶å¯¹åº”çš„é˜ˆå€¼
        lianwei_config = {
            'äºŒè¿å°¾': {'threshold': 7},
            'ä¸‰è¿å°¾': {'threshold': 7},
            'å››è¿å°¾': {'threshold': 7},  
            'äº”è¿å°¾': {'threshold': 8},
        }
        
        # é¦–å…ˆæ£€æŸ¥å…·ä½“çš„è¿å°¾ç±»å‹
        for lianwei_type, config in lianwei_config.items():
            lianwei_group = group[group['ç©æ³•åˆ†ç±»'] == lianwei_type]
            
            for _, row in lianwei_group.iterrows():
                content = str(row['å†…å®¹'])
                tails = self.data_analyzer.extract_tails_from_content(content)
                
                # ä½¿ç”¨é’ˆå¯¹å…·ä½“è¿å°¾ç±»å‹çš„é˜ˆå€¼
                if len(tails) >= config['threshold']:
                    record = {
                        'ä¼šå‘˜è´¦å·': account,
                        'å½©ç§': lottery,
                        'æœŸå·': period,
                        'ç©æ³•åˆ†ç±»': f"{lianwei_type}ï¼ˆ{len(tails)}å°¾ï¼‰",
                        'è¿è§„ç±»å‹': f'{lianwei_type}å¤šå°¾',
                        'å°¾æ•°æ•°é‡': len(tails),
                        'æŠ•æ³¨å†…å®¹': ', '.join([f"{tail}å°¾" for tail in sorted(tails)]),
                        'æ’åºæƒé‡': self._calculate_sort_weight({'å°¾æ•°æ•°é‡': len(tails)}, f'{lianwei_type}å¤šå°¾')
                    }
                    self._add_unique_result(results, f'{lianwei_type}å¤šå°¾', record)
        
        # ç„¶åæ£€æŸ¥é€šç”¨çš„è¿å°¾ç±»å‹ï¼ˆä½œä¸ºåå¤‡ï¼‰
        generic_lianwei_group = group[group['ç©æ³•åˆ†ç±»'] == 'è¿å°¾']
        if not generic_lianwei_group.empty:
            # å°è¯•ä»å†…å®¹ä¸­æ¨æ–­å…·ä½“ç±»å‹
            for _, row in generic_lianwei_group.iterrows():
                content = str(row['å†…å®¹'])
                
                # ä»å†…å®¹ä¸­æ¨æ–­å…·ä½“è¿å°¾ç±»å‹
                inferred_type = self._infer_lianwei_type_from_content(content)
                
                tails = self.data_analyzer.extract_tails_from_content(content)
                
                # æ ¹æ®æ¨æ–­çš„ç±»å‹ä½¿ç”¨ç›¸åº”çš„é˜ˆå€¼ï¼Œå¦‚æœæ²¡æœ‰æ¨æ–­å‡ºç±»å‹åˆ™ä½¿ç”¨é€šç”¨é˜ˆå€¼
                if inferred_type and inferred_type in lianwei_config:
                    threshold = lianwei_config[inferred_type]['threshold']
                    display_type = inferred_type
                else:
                    threshold = 6  # é€šç”¨é˜ˆå€¼
                    display_type = 'è¿å°¾'
                
                if len(tails) >= threshold:
                    record = {
                        'ä¼šå‘˜è´¦å·': account,
                        'å½©ç§': lottery,
                        'æœŸå·': period,
                        'ç©æ³•åˆ†ç±»': f"{display_type}ï¼ˆ{len(tails)}å°¾ï¼‰",
                        'è¿è§„ç±»å‹': f'{display_type}å¤šå°¾',
                        'å°¾æ•°æ•°é‡': len(tails),
                        'æŠ•æ³¨å†…å®¹': ', '.join([f"{tail}å°¾" for tail in sorted(tails)]),
                        'æ’åºæƒé‡': self._calculate_sort_weight({'å°¾æ•°æ•°é‡': len(tails)}, f'{display_type}å¤šå°¾')
                    }
                    self._add_unique_result(results, f'{display_type}å¤šå°¾', record)
    
    def _infer_lianwei_type_from_content(self, content):
        """ä»å†…å®¹ä¸­æ¨æ–­è¿å°¾ç±»å‹"""
        content_str = str(content)
        
        # ä»å†…å®¹ä¸­æŸ¥æ‰¾å…·ä½“ç±»å‹
        if 'äºŒè¿å°¾' in content_str:
            return 'äºŒè¿å°¾'
        elif 'ä¸‰è¿å°¾' in content_str:
            return 'ä¸‰è¿å°¾'
        elif 'å››è¿å°¾' in content_str:
            return 'å››è¿å°¾'
        elif 'äº”è¿å°¾' in content_str:
            return 'äº”è¿å°¾'
        
        return None
    
    def _analyze_lhc_zhengte_detailed(self, account, lottery, period, group, results):
        """å…­åˆå½©æ­£ç ç‰¹è¯¦ç»†æ£€æµ‹"""
        zhengte_categories = ['æ­£1ç‰¹', 'æ­£2ç‰¹', 'æ­£3ç‰¹', 'æ­£4ç‰¹', 'æ­£5ç‰¹', 'æ­£6ç‰¹']
        
        for category in zhengte_categories:
            category_group = group[group['ç©æ³•åˆ†ç±»'] == category]
            
            all_numbers = set()
            all_bets = defaultdict(set)
            
            for _, row in category_group.iterrows():
                content = str(row['å†…å®¹'])
                category = str(row['ç©æ³•åˆ†ç±»'])
                
                # æ–°å¢ï¼šåŸºäºå†…å®¹é‡æ–°åˆ†ç±»
                actual_category = self.normalize_play_category_from_content(content, category, 'LHC')
                
                clean_content = self.data_analyzer.parse_lhc_special_content(content)
                
                # æå–æ•°å­—
                numbers = self.data_analyzer.extract_numbers_from_content(clean_content, 1, 49)
                all_numbers.update(numbers)
                
                # æå–ä¸¤é¢ç©æ³•å†…å®¹
                two_sides_analysis = self.data_analyzer.extract_lhc_two_sides_content(content)
                for bet_type, bets in two_sides_analysis.items():
                    all_bets[bet_type].update(bets)
            
            # å¤šå·ç æ£€æµ‹
            if len(all_numbers) >= THRESHOLD_CONFIG['LHC']['number_play']:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': category,
                    'å·ç æ•°é‡': len(all_numbers),
                    'æŠ•æ³¨å†…å®¹': ', '.join([f"{num:02d}" for num in sorted(all_numbers)]),
                    'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'æ­£ç‰¹å¤šç ')
                }
                self._add_unique_result(results, 'æ­£ç‰¹å¤šç ', record)
            
            # çŸ›ç›¾æŠ•æ³¨æ£€æµ‹
            conflicts = []
            if 'å¤§' in all_bets.get('normal_size', set()) and 'å°' in all_bets.get('normal_size', set()):
                conflicts.append('å¤§å°çŸ›ç›¾')
            if 'å•' in all_bets.get('parity', set()) and 'åŒ' in all_bets.get('parity', set()):
                conflicts.append('å•åŒçŸ›ç›¾')
            if 'å°¾å¤§' in all_bets.get('tail_size', set()) and 'å°¾å°' in all_bets.get('tail_size', set()):
                conflicts.append('å°¾å¤§å°çŸ›ç›¾')
            if 'åˆå•' in all_bets.get('sum_parity', set()) and 'åˆåŒ' in all_bets.get('sum_parity', set()):
                conflicts.append('åˆæ•°å•åŒçŸ›ç›¾')
            
            if conflicts:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': category,
                    'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                    'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'æ­£ç‰¹çŸ›ç›¾')
                }
                self._add_unique_result(results, 'æ­£ç‰¹çŸ›ç›¾', record)
    
    def _analyze_lhc_lianxiao_lianwei_detailed(self, account, lottery, period, group, results):
        """è¿è‚–è¿å°¾ç»†åˆ†æ£€æµ‹"""
        # è¿è‚–ç»†åˆ†
        lianxiao_categories = {
            'è¿è‚–è¿å°¾_äºŒè¿è‚–': 2,
            'è¿è‚–è¿å°¾_ä¸‰è¿è‚–': 3, 
            'è¿è‚–è¿å°¾_å››è¿è‚–': 4,
            'è¿è‚–è¿å°¾_äº”è¿è‚–': 5
        }
        
        for category, threshold in lianxiao_categories.items():
            category_group = group[group['ç©æ³•åˆ†ç±»'] == category]
            
            for _, row in category_group.iterrows():
                content = str(row['å†…å®¹'])
                category = str(row['ç©æ³•åˆ†ç±»'])
                
                # æ–°å¢ï¼šåŸºäºå†…å®¹é‡æ–°åˆ†ç±»
                actual_category = self.normalize_play_category_from_content(content, category, 'LHC')
                
                zodiacs = self.data_analyzer.extract_zodiacs_from_content(content)
                
                # è¶…è¿‡é˜ˆå€¼æ£€æµ‹
                if len(zodiacs) > threshold + 2:  # å…è®¸ä¸€å®šçš„å†—ä½™
                    record = {
                        'ä¼šå‘˜è´¦å·': account,
                        'å½©ç§': lottery,
                        'æœŸå·': period,
                        'ç©æ³•åˆ†ç±»': category,
                        'ç”Ÿè‚–æ•°é‡': len(zodiacs),
                        'æŠ•æ³¨å†…å®¹': ', '.join(sorted(zodiacs)),
                        'æ’åºæƒé‡': self._calculate_sort_weight({'ç”Ÿè‚–æ•°é‡': len(zodiacs)}, 'è¿è‚–å¤šè‚–')
                    }
                    self._add_unique_result(results, 'è¿è‚–å¤šè‚–', record)
        
        # è¿å°¾ç»†åˆ†
        lianwei_categories = {
            'è¿è‚–è¿å°¾_äºŒè¿å°¾': 2,
            'è¿è‚–è¿å°¾_ä¸‰è¿å°¾': 3,
            'è¿è‚–è¿å°¾_å››è¿å°¾': 4,
            'è¿è‚–è¿å°¾_äº”è¿å°¾': 5
        }
        
        for category, threshold in lianwei_categories.items():
            category_group = group[group['ç©æ³•åˆ†ç±»'] == category]
            
            for _, row in category_group.iterrows():
                content = str(row['å†…å®¹'])
                tails = self.data_analyzer.extract_tails_from_content(content)
                
                if len(tails) > threshold + 2:
                    record = {
                        'ä¼šå‘˜è´¦å·': account,
                        'å½©ç§': lottery,
                        'æœŸå·': period,
                        'ç©æ³•åˆ†ç±»': category,
                        'å°¾æ•°æ•°é‡': len(tails),
                        'æŠ•æ³¨å†…å®¹': ', '.join([f"{tail}å°¾" for tail in sorted(tails)]),
                        'æ’åºæƒé‡': self._calculate_sort_weight({'å°¾æ•°æ•°é‡': len(tails)}, 'è¿å°¾å¤šå°¾')
                    }
                    self._add_unique_result(results, 'è¿å°¾å¤šå°¾', record)
    
    def _analyze_lhc_banbo(self, account, lottery, period, group, results):
        """å…­åˆå½©åŠæ³¢æ£€æµ‹ - æ£€æµ‹å¤§å°å…¨åŒ…å’Œå•åŒå…¨åŒ…ï¼ŒåŒ…æ‹¬è“æ³¢ã€ç»¿æ³¢ã€çº¢æ³¢ç©æ³•"""
        # æ‰©å±•åŠæ³¢ç›¸å…³çš„ç©æ³•åˆ†ç±»
        banbo_categories = ['åŠæ³¢', 'è“æ³¢', 'ç»¿æ³¢', 'çº¢æ³¢']
        
        banbo_group = group[group['ç©æ³•åˆ†ç±»'].isin(banbo_categories)]
        
        if banbo_group.empty:
            return
        
        # å®šä¹‰ä¸¤ç»„åŠæ³¢å…¨åŒ…
        size_full_set = {'çº¢å¤§', 'çº¢å°', 'è“å¤§', 'è“å°', 'ç»¿å¤§', 'ç»¿å°'}  # å¤§å°å…¨åŒ…
        parity_full_set = {'çº¢å•', 'çº¢åŒ', 'è“å•', 'è“åŒ', 'ç»¿å•', 'ç»¿åŒ'}  # å•åŒå…¨åŒ…
        
        all_banbo_bets = set()
        
        for _, row in banbo_group.iterrows():
            content = str(row['å†…å®¹'])
            
            # è§£æç©æ³•-æŠ•æ³¨å†…å®¹æ ¼å¼
            if '-' in content:
                parts = content.split('-', 1)
                bet_content = parts[1].strip()  # åªä½¿ç”¨æŠ•æ³¨å†…å®¹éƒ¨åˆ†
            else:
                bet_content = content
            
            # æå–æ‰€æœ‰åŠæ³¢æŠ•æ³¨é¡¹
            for bet in size_full_set.union(parity_full_set):
                if bet in bet_content:
                    all_banbo_bets.add(bet)
        
        # æ£€æµ‹å¤§å°å…¨åŒ…
        if size_full_set.issubset(all_banbo_bets):
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'åŠæ³¢',
                'æŠ•æ³¨åŠæ³¢æ•°': len(size_full_set),
                'æŠ•æ³¨åŠæ³¢': sorted(list(size_full_set)),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(size_full_set)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨åŠæ³¢æ•°': len(size_full_set)}, 'åŠæ³¢å¤§å°å…¨åŒ…')
            }
            self._add_unique_result(results, 'åŠæ³¢å¤§å°å…¨åŒ…', record)
        
        # æ£€æµ‹å•åŒå…¨åŒ…
        if parity_full_set.issubset(all_banbo_bets):
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'åŠæ³¢',
                'æŠ•æ³¨åŠæ³¢æ•°': len(parity_full_set),
                'æŠ•æ³¨åŠæ³¢': sorted(list(parity_full_set)),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(parity_full_set)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨åŠæ³¢æ•°': len(parity_full_set)}, 'åŠæ³¢å•åŒå…¨åŒ…')
            }
            self._add_unique_result(results, 'åŠæ³¢å•åŒå…¨åŒ…', record)

    def _analyze_lhc_zhengma_wave_detailed(self, account, lottery, period, group, results):
        """åˆ†æå…­åˆå½©æ­£ç ä¸­çš„æ³¢è‰²æŠ•æ³¨ - ç²¾ç¡®ä¿®å¤ç‰ˆæœ¬"""
        # æ­£ç ç›¸å…³çš„ç©æ³•åˆ†ç±» - ä¿æŒä¸å˜
        zhengma_categories = ['æ­£ç ', 'æ­£ç 1-6', 'æ­£ç ä¸€', 'æ­£ç äºŒ', 'æ­£ç ä¸‰', 'æ­£ç å››', 'æ­£ç äº”', 'æ­£ç å…­']
        
        zhengma_group = group[group['ç©æ³•åˆ†ç±»'].isin(zhengma_categories)]
        
        if zhengma_group.empty:
            return
        
        # ä¿®å¤ï¼šä½¿ç”¨æ›´ç²¾ç¡®çš„ä½ç½®æå–æ–¹æ³•
        position_waves = defaultdict(set)
        
        for _, row in zhengma_group.iterrows():
            content = str(row['å†…å®¹'])
            category = str(row['ç©æ³•åˆ†ç±»'])
            
            # ä¿®å¤ï¼šä½¿ç”¨åŸæœ‰çš„ä½ç½®æ¨æ–­æ–¹æ³•ï¼Œç¡®ä¿æ­£5ç‰¹ç­‰ä¸è¢«å½±å“
            inferred_position = ContentParser.infer_position_from_content(content, 'LHC')
            
            # å¦‚æœåŸæœ‰æ–¹æ³•è¿”å›æœªçŸ¥ä½ç½®ï¼Œå†å°è¯•ä»åˆ†ç±»ä¸­æå–
            if inferred_position == 'æœªçŸ¥ä½ç½®':
                inferred_position = self._extract_position_from_zhengma_category_safe(category)
            
            # æå–æ³¢è‰²
            waves = self.data_analyzer.extract_wave_color_from_content(content)
            
            # åªæ·»åŠ æœ‰æ•ˆçš„ä½ç½®å’Œæ³¢è‰²
            if inferred_position != 'æœªçŸ¥ä½ç½®' and waves:
                position_waves[inferred_position].update(waves)
        
        # æ£€æŸ¥æ¯ä¸ªä½ç½®çš„æ³¢è‰²å…¨åŒ…æƒ…å†µ
        traditional_waves = {'çº¢æ³¢', 'è“æ³¢', 'ç»¿æ³¢'}
        for position, waves in position_waves.items():
            # åªæ£€æŸ¥è¯¥ä½ç½®æœ¬èº«çš„æ³¢è‰²
            if traditional_waves.issubset(waves):
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': f'{position}æ³¢è‰²å…¨åŒ…',
                    'ä½ç½®': position,
                    'è¿è§„ç±»å‹': f'{position}æ³¢è‰²å…¨åŒ…',
                    'æŠ•æ³¨æ³¢è‰²æ•°': len(traditional_waves),
                    'æŠ•æ³¨æ³¢è‰²': sorted(list(traditional_waves)),
                    'æŠ•æ³¨å†…å®¹': f"{position}æ³¢è‰²å…¨åŒ…: {', '.join(sorted(traditional_waves))}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨æ³¢è‰²æ•°': len(traditional_waves)}, f'{position}æ³¢è‰²å…¨åŒ…')
                }
                self._add_unique_result(results, f'{position}æ³¢è‰²å…¨åŒ…', record)
    
    def _extract_position_from_zhengma_category_safe(self, category):
        """å®‰å…¨åœ°ä»å…­åˆå½©ç©æ³•åˆ†ç±»ä¸­æå–ä½ç½® - ä¸å½±å“æ­£ç‰¹æ£€æµ‹"""
        category_str = str(category).strip()
        
        # åªå¤„ç†æ˜ç¡®çš„æ­£ç 1-6æ ¼å¼ï¼Œä¸å½±å“æ­£ç‰¹
        if 'æ­£ç 1-6' in category_str and '_' in category_str:
            parts = category_str.split('_')
            if len(parts) > 1:
                position_part = parts[1].strip()
                
                # åªæ˜ å°„æ˜ç¡®çš„æ­£ç ä½ç½®
                position_mapping = {
                    'æ­£ç ä¸€': 'æ­£ç ä¸€',
                    'æ­£ç äºŒ': 'æ­£ç äºŒ',
                    'æ­£ç ä¸‰': 'æ­£ç ä¸‰', 
                    'æ­£ç å››': 'æ­£ç å››',
                    'æ­£ç äº”': 'æ­£ç äº”',
                    'æ­£ç å…­': 'æ­£ç å…­'
                }
                
                for position, keywords in position_mapping.items():
                    if position in position_part:
                        return position
        
        return 'æœªçŸ¥ä½ç½®'

    def _analyze_lhc_zhengma_wave_comprehensive(self, account, lottery, period, group, results):
        """ç»¼åˆè€ƒè™‘ç©æ³•å’Œå†…å®¹çš„å…­åˆå½©æ­£ç æ³¢è‰²æ£€æµ‹ - å½»åº•ä¿®å¤ç‰ˆæœ¬"""
        zhengma_categories = ['æ­£ç ', 'æ­£ç 1-6', 'æ­£ç ä¸€', 'æ­£ç äºŒ', 'æ­£ç ä¸‰', 'æ­£ç å››', 'æ­£ç äº”', 'æ­£ç å…­']
        
        zhengma_group = group[group['ç©æ³•åˆ†ç±»'].isin(zhengma_categories)]
        
        if zhengma_group.empty:
            st.warning(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ­£ç æŠ•æ³¨è®°å½• - {account} {period}")
            return
        
        position_waves = defaultdict(set)
        
        # è°ƒè¯•ä¿¡æ¯
        debug_records = []
        
        for _, row in zhengma_group.iterrows():
            content = normalize_spaces(str(row['å†…å®¹']))
            category = normalize_spaces(str(row['ç©æ³•åˆ†ç±»']))
            
            # è°ƒè¯•è®°å½•
            debug_record = {
                'account': account,
                'period': period,
                'category': category,
                'content': content,
                'position_found': None,
                'waves_found': None
            }
            
            # ç›´æ¥ä»ç©æ³•åˆ†ç±»ä¸­æå–ä½ç½®
            position = self._extract_position_from_zhengma_category_direct(category)
            debug_record['position_found'] = position
            
            # æå–æ³¢è‰²
            waves = self.data_analyzer.extract_wave_color_from_content(content)
            debug_record['waves_found'] = waves
            
            if position and position != 'æœªçŸ¥ä½ç½®' and waves:
                position_waves[position].update(waves)
            
            debug_records.append(debug_record)
        
        # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
        if debug_records:
            st.write(f"ğŸ¯ æ­£ç æ³¢è‰²æ£€æµ‹è°ƒè¯•ä¿¡æ¯ - {account} {period}:")
            for record in debug_records:
                st.write(f"  - ç©æ³•: {record['category']}, å†…å®¹: {record['content']}, ä½ç½®: {record['position_found']}, æ³¢è‰²: {record['waves_found']}")
        
        # æ£€æŸ¥æ¯ä¸ªä½ç½®çš„æ³¢è‰²
        for position, waves in position_waves.items():
            st.write(f"  ğŸ“Š ä½ç½® {position} çš„æ³¢è‰²é›†åˆ: {waves}")
        
        # æ£€æŸ¥æ³¢è‰²å…¨åŒ…
        traditional_waves = {'çº¢æ³¢', 'è“æ³¢', 'ç»¿æ³¢'}
        for position, waves in position_waves.items():
            if traditional_waves.issubset(waves):
                st.success(f"ğŸ‰ æ£€æµ‹åˆ° {position} æ³¢è‰²å…¨åŒ…!")
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': f'{position}æ³¢è‰²å…¨åŒ…',
                    'ä½ç½®': position,
                    'è¿è§„ç±»å‹': f'{position}æ³¢è‰²å…¨åŒ…',
                    'æŠ•æ³¨æ³¢è‰²æ•°': len(traditional_waves),
                    'æŠ•æ³¨æ³¢è‰²': sorted(list(traditional_waves)),
                    'æŠ•æ³¨å†…å®¹': f"{position}æ³¢è‰²å…¨åŒ…: {', '.join(sorted(traditional_waves))}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨æ³¢è‰²æ•°': len(traditional_waves)}, f'{position}æ³¢è‰²å…¨åŒ…')
                }
                self._add_unique_result(results, f'{position}æ³¢è‰²å…¨åŒ…', record)
    
    def _extract_position_from_zhengma_category_direct(self, category):
        """ç›´æ¥ä»å…­åˆå½©ç©æ³•åˆ†ç±»ä¸­æå–ä½ç½® - å½»åº•ä¿®å¤ç‰ˆæœ¬"""
        category_str = str(category).strip()
        
        # å¤„ç†æ‰€æœ‰å¯èƒ½çš„ç©ºæ ¼å’Œæ ¼å¼é—®é¢˜
        category_clean = category_str.replace(' ', '').replace('Â ', '').replace('_', '').replace('-', '')
        
        # å®Œæ•´çš„ä½ç½®æ˜ å°„
        position_mapping = {
            'æ­£ç ä¸€': ['æ­£ç ä¸€', 'æ­£1', 'æ­£ç 1', 'æ­£ä¸€'],
            'æ­£ç äºŒ': ['æ­£ç äºŒ', 'æ­£2', 'æ­£ç 2', 'æ­£äºŒ'],
            'æ­£ç ä¸‰': ['æ­£ç ä¸‰', 'æ­£3', 'æ­£ç 3', 'æ­£ä¸‰'],
            'æ­£ç å››': ['æ­£ç å››', 'æ­£4', 'æ­£ç 4', 'æ­£å››'],
            'æ­£ç äº”': ['æ­£ç äº”', 'æ­£5', 'æ­£ç 5', 'æ­£äº”'],
            'æ­£ç å…­': ['æ­£ç å…­', 'æ­£6', 'æ­£ç 6', 'æ­£å…­']
        }
        
        # é¦–å…ˆæ£€æŸ¥å®Œæ•´åŒ¹é…
        for position, keywords in position_mapping.items():
            for keyword in keywords:
                keyword_clean = keyword.replace(' ', '')
                if keyword_clean == category_clean:
                    return position
        
        # ç„¶åæ£€æŸ¥åŒ…å«å…³ç³»
        for position, keywords in position_mapping.items():
            for keyword in keywords:
                keyword_clean = keyword.replace(' ', '')
                if keyword_clean in category_clean:
                    return position
        
        # å¤„ç†"æ­£ç 1-6_æ­£ç ä¸€"è¿™ç§æ ¼å¼
        if 'æ­£ç 1-6' in category_clean or 'æ­£ç 16' in category_clean:
            for position, keywords in position_mapping.items():
                for keyword in keywords:
                    keyword_clean = keyword.replace(' ', '')
                    if keyword_clean in category_clean:
                        return position
        
        st.warning(f"âš ï¸ æ— æ³•ä»ç©æ³•åˆ†ç±»ä¸­æå–æ­£ç ä½ç½®: {category_str} -> {category_clean}")
        return 'æœªçŸ¥ä½ç½®'

    # =============== 3Dç³»åˆ—åˆ†ææ–¹æ³• ===============
    def analyze_3d_patterns(self, df):
        """åˆ†æ3Dç³»åˆ—æŠ•æ³¨æ¨¡å¼"""
        results = defaultdict(list)
        
        df_target = df[df['å½©ç§'].apply(self.identify_lottery_type) == '3D']
        
        if len(df_target) == 0:
            return results
        
        grouped = df_target.groupby(['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·'])
        
        for (account, lottery, period), group in grouped:
            self._analyze_3d_two_sides(account, lottery, period, group, results)
            self._analyze_3d_dingwei(account, lottery, period, group, results)
        
        return results
    
    def _analyze_3d_two_sides(self, account, lottery, period, group, results):
        """åˆ†æ3Dä¸¤é¢ç©æ³•çŸ›ç›¾ - å¢å¼ºç«–çº¿æ ¼å¼æ”¯æŒ"""
        two_sides_group = group[group['ç©æ³•åˆ†ç±»'] == 'ä¸¤é¢']
        
        if two_sides_group.empty:
            return
        
        # æŒ‰ä½ç½®åˆ†ç±»æ”¶é›†æŠ•æ³¨
        position_bets = defaultdict(set)
        
        for _, row in two_sides_group.iterrows():
            content = str(row['å†…å®¹'])
            
            # é¦–å…ˆå°è¯•è§£æç«–çº¿æ ¼å¼
            bets_by_position = self.data_analyzer.parse_3d_content(content)
            if bets_by_position:
                # ç«–çº¿æ ¼å¼è§£ææˆåŠŸ
                for position, bets in bets_by_position.items():
                    for bet in bets:
                        # æå–å¤§å°å•åŒä¿¡æ¯
                        if isinstance(bet, str):
                            if 'å¤§' in bet:
                                position_bets[position].add('å¤§')
                            if 'å°' in bet:
                                position_bets[position].add('å°')
                            if 'å•' in bet:
                                position_bets[position].add('å•')
                            if 'åŒ' in bet:
                                position_bets[position].add('åŒ')
            else:
                # åŸæœ‰çš„è§£æé€»è¾‘
                positions = ['ç™¾ä½', 'åä½', 'ä¸ªä½', 'ç™¾å', 'ç™¾ä¸ª', 'åä¸ª', 'ç™¾åä¸ª']
                bets = ['å¤§', 'å°', 'å•', 'åŒ', 'è´¨', 'åˆ', 'å’Œå¤§', 'å’Œå°', 'å’Œå•', 'å’ŒåŒ', 
                       'å’Œå°¾å¤§', 'å’Œå°¾å°', 'å’Œå°¾è´¨', 'å’Œå°¾åˆ']
                
                # å¤„ç†å¤šç§æ ¼å¼
                parts = [part.strip() for part in content.split(',')]
                
                current_position = None
                
                for part in parts:
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«ä½ç½®ä¿¡æ¯
                    position_found = False
                    for position in positions:
                        if position in part:
                            current_position = position
                            position_found = True
                            break
                    
                    if position_found:
                        # æå–è¯¥ä½ç½®çš„æ‰€æœ‰æŠ•æ³¨é€‰é¡¹
                        for bet in bets:
                            if bet in part:
                                position_bets[current_position].add(bet)
                    elif current_position:
                        # å¦‚æœæ²¡æœ‰ä½ç½®ä¿¡æ¯ä½†æœ‰å½“å‰ä¸Šä¸‹æ–‡ä½ç½®ï¼Œæ£€æŸ¥æŠ•æ³¨é€‰é¡¹
                        for bet in bets:
                            if bet in part:
                                position_bets[current_position].add(bet)
        
        # æ£€æŸ¥æ¯ä¸ªä½ç½®çš„çŸ›ç›¾ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ä¸å˜ï¼‰
        for position, bet_options in position_bets.items():
            conflicts = []
            
            # åŸºæœ¬å¤§å°å•åŒè´¨åˆçŸ›ç›¾
            if 'å¤§' in bet_options and 'å°' in bet_options:
                conflicts.append('å¤§å°çŸ›ç›¾')
            if 'å•' in bet_options and 'åŒ' in bet_options:
                conflicts.append('å•åŒçŸ›ç›¾')
            if 'è´¨' in bet_options and 'åˆ' in bet_options:
                conflicts.append('è´¨åˆçŸ›ç›¾')
            
            # å’Œæ•°å±æ€§çŸ›ç›¾
            if 'å’Œå¤§' in bet_options and 'å’Œå°' in bet_options:
                conflicts.append('å’Œå¤§å°çŸ›ç›¾')
            if 'å’Œå•' in bet_options and 'å’ŒåŒ' in bet_options:
                conflicts.append('å’Œå•åŒçŸ›ç›¾')
            if 'å’Œå°¾å¤§' in bet_options and 'å’Œå°¾å°' in bet_options:
                conflicts.append('å’Œå°¾å¤§å°çŸ›ç›¾')
            if 'å’Œå°¾è´¨' in bet_options and 'å’Œå°¾åˆ' in bet_options:
                conflicts.append('å’Œå°¾è´¨åˆçŸ›ç›¾')
            
            if conflicts:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': 'ä¸¤é¢',
                    'ä½ç½®': position,
                    'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                    'æŠ•æ³¨å†…å®¹': f"{position}:{','.join(sorted(bet_options))}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'ä¸¤é¢çŸ›ç›¾')
                }
                self._add_unique_result(results, 'ä¸¤é¢çŸ›ç›¾', record)
    
    def _analyze_3d_dingwei(self, account, lottery, period, group, results):
        """åˆ†æ3Då®šä½èƒ†å¤šç  - å¢å¼ºç«–çº¿æ ¼å¼æ”¯æŒ"""
        dingwei_categories = ['å®šä½èƒ†', 'å®šä½èƒ†_ç™¾ä½', 'å®šä½èƒ†_åä½', 'å®šä½èƒ†_ä¸ªä½']
        
        dingwei_group = group[group['ç©æ³•åˆ†ç±»'].isin(dingwei_categories)]
        
        position_numbers = defaultdict(set)
        
        # ä¿®å¤è¿™é‡Œçš„ç¼©è¿›ï¼šæ•´ä¸ªforå¾ªç¯åº”è¯¥ç¼©è¿›
        for _, row in dingwei_group.iterrows():
            content = str(row['å†…å®¹'])
            category = str(row['ç©æ³•åˆ†ç±»'])
            
            # é¦–å…ˆä½¿ç”¨ç»Ÿä¸€è§£æå™¨è§£æç«–çº¿æ ¼å¼
            bets_by_position = self.data_analyzer.parse_3d_content(content)
            if bets_by_position:
                # å¦‚æœæœ‰è§£æç»“æœï¼Œä½¿ç”¨è§£æå‡ºçš„ä½ç½®å’Œå·ç 
                for position, numbers in bets_by_position.items():
                    position_numbers[position].update(numbers)
                continue
            
            # æ–°å¢ï¼šåŸºäºå†…å®¹é‡æ–°åˆ†ç±»ï¼ˆåœ¨åŸæœ‰é€»è¾‘ä¹‹å‰ï¼‰
            actual_category = self.normalize_play_category_from_content(content, category, '3D')
            
            # å¦‚æœæ²¡æœ‰ç«–çº¿æ ¼å¼ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
            # ç¡®å®šä½ç½®
            if 'ç™¾ä½' in actual_category:  # è¿™é‡Œè¦ç”¨ actual_categoryï¼Œä¸æ˜¯ category
                position = 'ç™¾ä½'
            elif 'åä½' in actual_category:  # è¿™é‡Œä¹Ÿè¦ç”¨ actual_category
                position = 'åä½'
            elif 'ä¸ªä½' in actual_category:  # è¿™é‡Œä¹Ÿè¦ç”¨ actual_category
                position = 'ä¸ªä½'
            else:
                # ä»å†…å®¹æ¨æ–­ä½ç½®
                if 'ç™¾ä½' in content:
                    position = 'ç™¾ä½'
                elif 'åä½' in content:
                    position = 'åä½'
                elif 'ä¸ªä½' in content:
                    position = 'ä¸ªä½'
                else:
                    position = 'æœªçŸ¥ä½ç½®'
            
            # æå–å·ç 
            numbers = self.data_analyzer.extract_numbers_from_content(content, 0, 9)
            position_numbers[position].update(numbers)
        
        # æ£€æŸ¥æ¯ä¸ªä½ç½®çš„è¶…ç 
        for position, numbers in position_numbers.items():
            if len(numbers) >= THRESHOLD_CONFIG['3D']['dingwei_multi']:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': f'{position}å¤šç ',
                    'ä½ç½®': position,
                    'å·ç æ•°é‡': len(numbers),
                    'æŠ•æ³¨å†…å®¹': f"{position}-{','.join([str(num) for num in sorted(numbers)])}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(numbers)}, 'å®šä½èƒ†å¤šç ')
                }
                self._add_unique_result(results, 'å®šä½èƒ†å¤šç ', record)

    # =============== å¿«ä¸‰åˆ†ææ–¹æ³• ===============
    def analyze_k3_patterns(self, df):
        """åˆ†æå¿«ä¸‰æŠ•æ³¨æ¨¡å¼"""
        results = defaultdict(list)
        
        df_target = df[df['å½©ç§'].apply(self.identify_lottery_type) == 'K3']
        
        if len(df_target) == 0:
            return results
        
        grouped = df_target.groupby(['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·'])
        
        for (account, lottery, period), group in grouped:
            self._analyze_k3_hezhi_enhanced(account, lottery, period, group, results)
            # å…ˆè¿›è¡Œèšåˆæ£€æµ‹ï¼ˆæ›´ä¸¥æ ¼çš„æ£€æµ‹ï¼‰
            self._analyze_k3_dudan_aggregated(account, lottery, period, group, results)
            # å¦‚æœèšåˆæ£€æµ‹æ²¡æœ‰å‘ç°é—®é¢˜ï¼Œå†è¿›è¡Œå•ä¸ªè®°å½•æ£€æµ‹
            if not any('ç‹¬èƒ†å¤šç ' in key for key in results.keys()):
                self._analyze_k3_dudan(account, lottery, period, group, results)
            self._analyze_k3_different(account, lottery, period, group, results)
            self._analyze_k3_two_sides_plays(account, lottery, period, group, results)
        
        return results
    
    def _analyze_k3_hezhi_enhanced(self, account, lottery, period, group, results):
        """åˆ†æå¿«ä¸‰å’Œå€¼ç©æ³• - ä¼˜åŒ–ç‰ˆï¼Œé¿å…é‡å¤æ£€æµ‹"""
        hezhi_categories = ['å’Œå€¼', 'å’Œå€¼_å¤§å°å•åŒ']
        
        hezhi_group = group[group['ç©æ³•åˆ†ç±»'].isin(hezhi_categories)]
        
        if hezhi_group.empty:
            return
        
        all_numbers = set()
        all_contents = []
        has_big = False
        has_small = False
        has_single = False
        has_double = False
        
        for _, row in hezhi_group.iterrows():
            content = str(row['å†…å®¹'])
            category = str(row['ç©æ³•åˆ†ç±»'])
            
            # æå–æ•°å­—
            numbers = self.data_analyzer.extract_numbers_from_content(
                content,
                LOTTERY_CONFIGS['K3']['hezhi_min'],
                LOTTERY_CONFIGS['K3']['hezhi_max']
            )
            all_numbers.update(numbers)
            all_contents.append(content)
            
            # æ£€æŸ¥å¤§å°å•åŒ
            content_lower = content.lower()
            if 'å¤§' in content_lower:
                has_big = True
            if 'å°' in content_lower:
                has_small = True
            if 'å•' in content_lower:
                has_single = True
            if 'åŒ' in content_lower:
                has_double = True
        
        # å’Œå€¼å¤šç æ£€æµ‹ï¼ˆ11ç æˆ–ä»¥ä¸Šï¼‰- å¦‚æœæ£€æµ‹åˆ°å°±å®Œå…¨é€€å‡º
        if len(all_numbers) >= THRESHOLD_CONFIG['K3']['hezhi_multi_number']:
            bet_content = ', '.join([str(num) for num in sorted(all_numbers)])
            
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'å’Œå€¼',
                'å·ç æ•°é‡': len(all_numbers),
                'æŠ•æ³¨å†…å®¹': bet_content,
                'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'å’Œå€¼å¤šç ')
            }
            self._add_unique_result(results, 'å’Œå€¼å¤šç ', record)
            return  # å®Œå…¨é€€å‡ºï¼Œä¸è¿›è¡Œåç»­æ£€æµ‹
        
        # å’Œå€¼çŸ›ç›¾æ£€æµ‹ï¼ˆå¤§å°å•åŒåŒæ—¶ä¸‹æ³¨ï¼‰
        conflict_types = []
        if has_big and has_small:
            conflict_types.append('å¤§å°')
        if has_single and has_double:
            conflict_types.append('å•åŒ')
        
        if conflict_types:
            bet_content_parts = []
            if has_big:
                bet_content_parts.append('å¤§')
            if has_small:
                bet_content_parts.append('å°')
            if has_single:
                bet_content_parts.append('å•')
            if has_double:
                bet_content_parts.append('åŒ')
            bet_content = ', '.join(bet_content_parts)
            
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'å’Œå€¼',
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types),
                'æŠ•æ³¨å†…å®¹': bet_content,
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types)}, 'å’Œå€¼çŸ›ç›¾')
            }
            self._add_unique_result(results, 'å’Œå€¼çŸ›ç›¾', record)
            return  # å¦‚æœæ£€æµ‹åˆ°å’Œå€¼çŸ›ç›¾ï¼Œä¹Ÿä¸è¿›è¡Œå’Œå€¼å¤§å°çŸ›ç›¾æ£€æµ‹
        
        # å’Œå€¼å¤§å°çŸ›ç›¾æ£€æµ‹ - åªæœ‰åœ¨æ²¡æœ‰æ£€æµ‹åˆ°å’Œå€¼å¤šç å’Œå’Œå€¼çŸ›ç›¾æ—¶æ‰è¿›è¡Œ
        if all_numbers and len(all_numbers) < THRESHOLD_CONFIG['K3']['hezhi_multi_number']:
            small_values = [num for num in all_numbers if 3 <= num <= 10]
            big_values = [num for num in all_numbers if 11 <= num <= 18]
            single_values = [num for num in all_numbers if num % 2 == 1]
            double_values = [num for num in all_numbers if num % 2 == 0]
            
            # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„çŸ›ç›¾
            possible_contradictions = []
            
            # æŠ•æ³¨å°ä½†åŒ…å«å¤šä¸ªå¤§å·ç ï¼ˆ4ä¸ªæˆ–ä»¥ä¸Šï¼‰
            if has_small and len(big_values) >= THRESHOLD_CONFIG['K3']['value_size_contradiction']:
                contradiction_value = len(big_values)
                description = f"æŠ•æ³¨å°ä½†åŒ…å«å¤šä¸ªå¤§å·ç (å°{len(small_values)}ä¸ª,å¤§{len(big_values)}ä¸ª)"
                possible_contradictions.append(('å¤§å°çŸ›ç›¾', description, contradiction_value))
            
            # æŠ•æ³¨å¤§ä½†åŒ…å«å¤šä¸ªå°å·ç ï¼ˆ4ä¸ªæˆ–ä»¥ä¸Šï¼‰
            if has_big and len(small_values) >= THRESHOLD_CONFIG['K3']['value_size_contradiction']:
                contradiction_value = len(small_values)
                description = f"æŠ•æ³¨å¤§ä½†åŒ…å«å¤šä¸ªå°å·ç (å°{len(small_values)}ä¸ª,å¤§{len(big_values)}ä¸ª)"
                possible_contradictions.append(('å¤§å°çŸ›ç›¾', description, contradiction_value))
            
            # æŠ•æ³¨å•ä½†åŒ…å«å¤šä¸ªåŒå·ç ï¼ˆ4ä¸ªæˆ–ä»¥ä¸Šï¼‰
            if has_single and len(double_values) >= THRESHOLD_CONFIG['K3']['value_size_contradiction']:
                contradiction_value = len(double_values)
                description = f"æŠ•æ³¨å•ä½†åŒ…å«å¤šä¸ªåŒå·ç (å•{len(single_values)}ä¸ª,åŒ{len(double_values)}ä¸ª)"
                possible_contradictions.append(('å•åŒçŸ›ç›¾', description, contradiction_value))
            
            # æŠ•æ³¨åŒä½†åŒ…å«å¤šä¸ªå•å·ç ï¼ˆ4ä¸ªæˆ–ä»¥ä¸Šï¼‰
            if has_double and len(single_values) >= THRESHOLD_CONFIG['K3']['value_size_contradiction']:
                contradiction_value = len(single_values)
                description = f"æŠ•æ³¨åŒä½†åŒ…å«å¤šä¸ªå•å·ç (å•{len(single_values)}ä¸ª,åŒ{len(double_values)}ä¸ª)"
                possible_contradictions.append(('å•åŒçŸ›ç›¾', description, contradiction_value))
            
            # ä¼˜å…ˆå±•ç¤ºæ•°é‡æœ€å¤šçš„çŸ›ç›¾ç»„åˆ
            if possible_contradictions:
                # æŒ‰çŸ›ç›¾å€¼é™åºæ’åº
                possible_contradictions.sort(key=lambda x: x[2], reverse=True)
                
                # é€‰æ‹©çŸ›ç›¾å€¼æœ€å¤§çš„é‚£ä¸ª
                best_contradiction = possible_contradictions[0]
                contradiction_type, contradiction_desc, contradiction_value = best_contradiction
                
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': 'å’Œå€¼',
                    'çŸ›ç›¾ç±»å‹': contradiction_desc,
                    'çŸ›ç›¾å€¼': contradiction_value,
                    'å¤§å·ç æ•°é‡': len(big_values),
                    'å°å·ç æ•°é‡': len(small_values),
                    'å•å·ç æ•°é‡': len(single_values),
                    'åŒå·ç æ•°é‡': len(double_values),
                    'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾å€¼': contradiction_value}, 'å’Œå€¼å¤§å°çŸ›ç›¾')
                }
                self._add_unique_result(results, 'å’Œå€¼å¤§å°çŸ›ç›¾', record)

    def _analyze_k3_dudan(self, account, lottery, period, group, results):
        """åˆ†æå¿«ä¸‰ç‹¬èƒ†ç©æ³• - å•ä¸ªè®°å½•æ£€æµ‹"""
        dudan_group = group[group['ç©æ³•åˆ†ç±»'] == 'ç‹¬èƒ†']
        
        for _, row in dudan_group.iterrows():
            content = str(row['å†…å®¹'])
            category = str(row['ç©æ³•åˆ†ç±»'])
            
            numbers = self.data_analyzer.extract_numbers_from_content(content, 1, 6)
            
            # æ£€æµ‹å•ä¸ªè®°å½•çš„å¤šå·ç ï¼ˆé€šå¸¸ä¸ä¼šè§¦å‘ï¼Œå› ä¸ºä¸‰å†›æ˜¯åˆ†å¼€æŠ•æ³¨çš„ï¼‰
            if len(numbers) >= 5:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': 'ç‹¬èƒ†',
                    'å·ç æ•°é‡': len(numbers),
                    'æŠ•æ³¨å†…å®¹': ', '.join([str(num) for num in sorted(numbers)]),
                    'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(numbers)}, 'ç‹¬èƒ†å¤šç ')
                }
                self._add_unique_result(results, 'ç‹¬èƒ†å¤šç ', record)
    
    def _analyze_k3_dudan_aggregated(self, account, lottery, period, group, results):
        """åˆ†æå¿«ä¸‰ç‹¬èƒ†ç©æ³• - æŒ‰è´¦æˆ·æœŸå·èšåˆæ£€æµ‹"""
        dudan_group = group[group['ç©æ³•åˆ†ç±»'] == 'ç‹¬èƒ†']
        
        if dudan_group.empty:
            return
        
        # èšåˆåŒä¸€è´¦æˆ·åŒä¸€æœŸå·çš„æ‰€æœ‰ç‹¬èƒ†æŠ•æ³¨
        all_numbers = set()
        
        for _, row in dudan_group.iterrows():
            content = str(row['å†…å®¹'])
            numbers = self.data_analyzer.extract_numbers_from_content(content, 1, 6)
            all_numbers.update(numbers)
        
        # ä½¿ç”¨é…ç½®çš„é˜ˆå€¼
        threshold = THRESHOLD_CONFIG['K3'].get('dudan_multi_number', 3)
        if len(all_numbers) >= threshold:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'ç‹¬èƒ†',
                'å·ç æ•°é‡': len(all_numbers),
                'æŠ•æ³¨å†…å®¹': f"èšåˆæŠ•æ³¨: {', '.join([str(num) for num in sorted(all_numbers)])}",
                'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'ç‹¬èƒ†å¤šç ')
            }
            self._add_unique_result(results, 'ç‹¬èƒ†å¤šç ', record)
    
    def _analyze_k3_different(self, account, lottery, period, group, results):
        different_categories = ['äºŒä¸åŒå·', 'ä¸‰ä¸åŒå·']
        
        for category in different_categories:
            category_group = group[group['ç©æ³•åˆ†ç±»'] == category]
            
            for _, row in category_group.iterrows():
                content = str(row['å†…å®¹'])
                numbers = self.data_analyzer.extract_numbers_from_content(content, 1, 6)
                
                if len(numbers) == 6:
                    record = {
                        'ä¼šå‘˜è´¦å·': account,
                        'å½©ç§': lottery,
                        'æœŸå·': period,
                        'ç©æ³•åˆ†ç±»': category,
                        'å·ç æ•°é‡': len(numbers),
                        'æŠ•æ³¨å†…å®¹': ', '.join([str(num) for num in sorted(numbers)]),
                        'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(numbers)}, 'ä¸åŒå·å…¨åŒ…')
                    }
                    self._add_unique_result(results, 'ä¸åŒå·å…¨åŒ…', record)
    
    def _analyze_k3_two_sides_plays(self, account, lottery, period, group, results):
        """å¿«ä¸‰ä¸¤é¢ç©æ³•åˆ†æ"""
        two_sides_categories = ['ä¸¤é¢']
        
        two_sides_group = group[group['ç©æ³•åˆ†ç±»'].isin(two_sides_categories)]
        
        has_big = False
        has_small = False
        has_single = False
        has_double = False
        
        for _, row in two_sides_group.iterrows():
            content = str(row['å†…å®¹'])
            content_lower = content.lower()
            
            if 'å¤§' in content_lower:
                has_big = True
            if 'å°' in content_lower:
                has_small = True
            if 'å•' in content_lower:
                has_single = True
            if 'åŒ' in content_lower:
                has_double = True
        
        conflict_types = []
        if has_big and has_small:
            conflict_types.append('å¤§å°')
        if has_single and has_double:
            conflict_types.append('å•åŒ')
        
        if conflict_types:
            bet_content_parts = []
            if has_big:
                bet_content_parts.append('å¤§')
            if has_small:
                bet_content_parts.append('å°')
            if has_single:
                bet_content_parts.append('å•')
            if has_double:
                bet_content_parts.append('åŒ')
            bet_content = ', '.join(bet_content_parts)
            
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'ä¸¤é¢',
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types),
                'æŠ•æ³¨å†…å®¹': bet_content,
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types)}, 'ä¸¤é¢çŸ›ç›¾')
            }
            self._add_unique_result(results, 'ä¸¤é¢çŸ›ç›¾', record)

    # =============== ä¸‰è‰²å½©åˆ†ææ–¹æ³• ===============
    def analyze_three_color_patterns(self, df):
        """åˆ†æä¸‰è‰²å½©æŠ•æ³¨æ¨¡å¼"""
        results = defaultdict(list)
        
        df_target = df[df['å½©ç§'].apply(self.identify_lottery_type) == 'THREE_COLOR']
        
        if len(df_target) == 0:
            return results
        
        grouped = df_target.groupby(['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·'])
        
        for (account, lottery, period), group in grouped:
            self._analyze_three_color_zhengma(account, lottery, period, group, results)
            self._analyze_three_color_two_sides(account, lottery, period, group, results)
            self._analyze_three_color_wave(account, lottery, period, group, results)
        
        return results
    
    def _analyze_three_color_zhengma(self, account, lottery, period, group, results):
        zhengma_group = group[group['ç©æ³•åˆ†ç±»'] == 'æ­£ç ']
        
        all_numbers = set()
        
        for _, row in zhengma_group.iterrows():
            content = str(row['å†…å®¹'])
            numbers = self.data_analyzer.extract_numbers_from_content(content, 0, 9)
            all_numbers.update(numbers)
        
        if len(all_numbers) >= THRESHOLD_CONFIG['THREE_COLOR']['zhengma_multi']:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'æ­£ç ',
                'å·ç æ•°é‡': len(all_numbers),
                'æŠ•æ³¨å†…å®¹': ', '.join([str(num) for num in sorted(all_numbers)]),
                'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'æ­£ç å¤šç ')
            }
            self._add_unique_result(results, 'æ­£ç å¤šç ', record)
    
    def _analyze_three_color_two_sides(self, account, lottery, period, group, results):
        two_sides_group = group[group['ç©æ³•åˆ†ç±»'] == 'ä¸¤é¢']
        
        has_big = False
        has_small = False
        has_single = False
        has_double = False
        
        for _, row in two_sides_group.iterrows():
            content = str(row['å†…å®¹'])
            bets = self.data_analyzer.extract_size_parity_from_content(content)
            
            if 'å¤§' in bets:
                has_big = True
            if 'å°' in bets:
                has_small = True
            if 'å•' in bets:
                has_single = True
            if 'åŒ' in bets:
                has_double = True
        
        conflict_types = []
        if has_big and has_small:
            conflict_types.append('å¤§å°')
        if has_single and has_double:
            conflict_types.append('å•åŒ')
        
        if conflict_types:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'ä¸¤é¢',
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types),
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types)}, 'ä¸¤é¢çŸ›ç›¾')
            }
            self._add_unique_result(results, 'ä¸¤é¢çŸ›ç›¾', record)
    
    def _analyze_three_color_wave(self, account, lottery, period, group, results):
        """ä¸‰è‰²å½©è‰²æ³¢æ£€æµ‹ - è®°å½•åŒä¸€æœŸå·å†…åŒæ—¶æŠ•æ³¨çº¢æ³¢å’Œç»¿æ³¢"""
        wave_group = group[group['ç©æ³•åˆ†ç±»'] == 'è‰²æ³¢']
        
        # æ”¶é›†è¯¥æœŸå·å†…æ‰€æœ‰æ³¢è‰²æŠ•æ³¨
        all_waves = set()
        
        for _, row in wave_group.iterrows():
            content = str(row['å†…å®¹'])
            # ä½¿ç”¨ä¸‰è‰²å½©ä¸“ç”¨çš„æ³¢è‰²æå–æ–¹æ³•
            waves = self.data_analyzer.extract_three_color_wave_from_content(content)
            all_waves.update(waves)
        
        # æ£€æŸ¥æ˜¯å¦åœ¨åŒä¸€æœŸå·å†…åŒæ—¶æŠ•æ³¨äº†çº¢æ³¢å’Œç»¿æ³¢
        if 'çº¢æ³¢' in all_waves and 'ç»¿æ³¢' in all_waves:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': 'è‰²æ³¢',
                'æŠ•æ³¨æ³¢è‰²æ•°': len(all_waves),
                'æŠ•æ³¨æ³¢è‰²': sorted(list(all_waves)),
                'æŠ•æ³¨å†…å®¹': f"åŒä¸€æœŸå·å†…æŠ•æ³¨: {', '.join(sorted(all_waves))}",
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨æ³¢è‰²æ•°': len(all_waves)}, 'è‰²æ³¢çº¢ç»¿æŠ•æ³¨')
            }
            self._add_unique_result(results, 'è‰²æ³¢çº¢ç»¿æŠ•æ³¨', record)
    
    def _calculate_sort_weight(self, record, result_type):
        """è®¡ç®—æ’åºæƒé‡ - ä¼˜åŒ–ç‰ˆæœ¬"""
        weight = 0
        
        # åŸºäºå·ç æ•°é‡
        if record.get('å·ç æ•°é‡', 0) > 0:
            weight += record['å·ç æ•°é‡'] * 10
        
        # åŸºäºçŸ›ç›¾ç±»å‹å¤æ‚åº¦
        if record.get('çŸ›ç›¾ç±»å‹'):
            conflict_count = len(record['çŸ›ç›¾ç±»å‹'].split('ã€'))
            weight += conflict_count * 15
        
        # åŸºäºå…¶ä»–æ•°é‡å­—æ®µ - ä¼˜åŒ–ï¼šç”Ÿè‚–æ•°é‡ã€å°¾æ•°æ•°é‡ç­‰æŒ‰ç…§æ•°é‡å¤§å°æ’åº
        for field in ['ç”Ÿè‚–æ•°é‡', 'å°¾æ•°æ•°é‡', 'æŠ•æ³¨åŒºé—´æ•°', 'æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨äº”è¡Œæ•°']:
            if record.get(field, 0) > 0:
                weight += record[field] * 8
        
        # åŸºäºçŸ›ç›¾å€¼ - ä¼˜åŒ–ï¼šå’Œå€¼å¤§å°çŸ›ç›¾æŒ‰ç…§ç›¸åæ–¹å‘çš„æ•°é‡æ’åº
        if record.get('çŸ›ç›¾å€¼', 0) > 0:
            weight += record['çŸ›ç›¾å€¼'] * 5
        
        # åŸºäºæ£€æµ‹ç±»å‹é‡è¦æ€§
        if 'å¤šå·ç ' in result_type:
            weight += 25
        elif 'çŸ›ç›¾' in result_type:
            weight += 20
        elif 'å…¨åŒ…' in result_type:
            weight += 30
        elif 'ä¸‰ç»„' in result_type:
            weight += 35
        
        return weight

    def _analyze_detailed_category_patterns(self, account, lottery, period, group, results, 
                                          category_config, extract_method, count_field, 
                                          result_suffix, content_formatter=None):
        """
        é€šç”¨è¯¦ç»†åˆ†ç±»æ£€æµ‹æ–¹æ³•
        category_config: åˆ†ç±»é…ç½®å­—å…¸ {åˆ†ç±»å: {é˜ˆå€¼é…ç½®}}
        extract_method: å†…å®¹æå–æ–¹æ³•
        count_field: æ•°é‡å­—æ®µå
        result_suffix: ç»“æœåç¼€
        content_formatter: å†…å®¹æ ¼å¼åŒ–å‡½æ•°
        """
        for category_name, config in category_config.items():
            category_group = group[group['ç©æ³•åˆ†ç±»'] == category_name]
            
            for _, row in category_group.iterrows():
                content = str(row['å†…å®¹'])
                
                # è§£æç©æ³•-æŠ•æ³¨å†…å®¹æ ¼å¼
                if '-' in content:
                    parts = content.split('-', 1)
                    bet_content = parts[1].strip()
                else:
                    bet_content = content
                    
                # æå–å†…å®¹
                items = extract_method(bet_content)
                
                # æ£€æµ‹é˜ˆå€¼
                if len(items) >= config['threshold']:
                    # æ ¼å¼åŒ–æ˜¾ç¤ºå†…å®¹
                    if content_formatter:
                        display_content = content_formatter(items)
                    else:
                        display_content = ', '.join(sorted([str(item) for item in items]))
                    
                    record = {
                        'ä¼šå‘˜è´¦å·': account,
                        'å½©ç§': lottery,
                        'æœŸå·': period,
                        'ç©æ³•åˆ†ç±»': f"{category_name}ï¼ˆ{len(items)}{count_field}ï¼‰",
                        'è¿è§„ç±»å‹': f'{category_name}{result_suffix}',
                        count_field: len(items),
                        'æŠ•æ³¨å†…å®¹': display_content,
                        'æ’åºæƒé‡': self._calculate_sort_weight({count_field: len(items)}, f'{category_name}{result_suffix}')
                    }
                    self._add_unique_result(results, f'{category_name}{result_suffix}', record)
    
    def analyze_all_patterns(self, df):
        """ç»¼åˆåˆ†ææ‰€æœ‰æ¨¡å¼"""
        logger.info("å¼€å§‹ç»¼åˆåˆ†ææ‰€æœ‰å½©ç¥¨æ¨¡å¼...")
        
        # é‡ç½®ç¼“å­˜
        self.seen_records = set()
        
        # ä½¿ç”¨è¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        all_results = {}
        # ä¿®æ”¹è¿™é‡Œï¼šæ·»åŠ 3Dç³»åˆ—
        lottery_types = ['PKæ‹¾èµ›è½¦', 'æ—¶æ—¶å½©', 'å…­åˆå½©', 'å¿«ä¸‰', 'ä¸‰è‰²å½©', '3Dç³»åˆ—']
        
        for i, lottery_type in enumerate(lottery_types):
            status_text.text(f"æ­£åœ¨åˆ†æ {lottery_type}...")
            
            if lottery_type == 'PKæ‹¾èµ›è½¦':
                all_results[lottery_type] = self.analyze_pk10_patterns(df)
            elif lottery_type == 'æ—¶æ—¶å½©':
                all_results[lottery_type] = self.analyze_ssc_patterns(df)
            elif lottery_type == 'å…­åˆå½©':
                all_results[lottery_type] = self.analyze_lhc_patterns(df)
            elif lottery_type == 'å¿«ä¸‰':
                all_results[lottery_type] = self.analyze_k3_patterns(df)
            elif lottery_type == 'ä¸‰è‰²å½©':
                all_results[lottery_type] = self.analyze_three_color_patterns(df)
            # æ·»åŠ 3Dç³»åˆ—åˆ†æ
            elif lottery_type == '3Dç³»åˆ—':
                all_results[lottery_type] = self.analyze_3d_patterns(df)
            
            progress_bar.progress((i + 1) / len(lottery_types))
        
        status_text.text("åˆ†æå®Œæˆï¼")
        
        # ç»Ÿè®¡ç»“æœ
        total_findings = 0
        for lottery_type, results in all_results.items():
            type_count = sum(len(records) for records in results.values())
            total_findings += type_count
            if type_count > 0:
                logger.info(f"{lottery_type}: å‘ç° {type_count} æ¡å¯ç–‘è®°å½•")
                for result_type, records in results.items():
                    if records:
                        logger.info(f"  - {result_type}: {len(records)} æ¡")
        
        logger.info(f"æ€»è®¡å‘ç° {total_findings} æ¡å¯ç–‘è®°å½•")
        return all_results

# ==================== ç»“æœå¤„ç†å™¨ ====================
class ResultProcessor:
    def __init__(self):
        self.behavior_names = {
            'PKæ‹¾èµ›è½¦': {
                'å† å†›å¤šç ': 'å† å†›å¤šç ',
                'äºšå†›å¤šç ': 'äºšå†›å¤šç ',
                'ç¬¬ä¸‰åå¤šç ': 'ç¬¬ä¸‰åå¤šç ',
                'ç¬¬å››åå¤šç ': 'ç¬¬å››åå¤šç ',
                'ç¬¬äº”åå¤šç ': 'ç¬¬äº”åå¤šç ',
                'ç¬¬å…­åå¤šç ': 'ç¬¬å…­åå¤šç ',
                'ç¬¬ä¸ƒåå¤šç ': 'ç¬¬ä¸ƒåå¤šç ',
                'ç¬¬å…«åå¤šç ': 'ç¬¬å…«åå¤šç ',
                'ç¬¬ä¹åå¤šç ': 'ç¬¬ä¹åå¤šç ',
                'ç¬¬ååå¤šç ': 'ç¬¬ååå¤šç ',
                'è¶…ç ': 'è¶…ç ',
                'å† äºšå’Œå¤šç ': 'å† äºšå’Œå¤šç ',
                'å† äºšå’ŒçŸ›ç›¾': 'å† äºšå’ŒçŸ›ç›¾',
                'ä¸¤é¢çŸ›ç›¾': 'ä¸¤é¢çŸ›ç›¾',
                'ç‹¬ç«‹ç©æ³•çŸ›ç›¾': 'ç‹¬ç«‹ç©æ³•çŸ›ç›¾',
                'å‰ä¸€å¤šç ': 'å‰ä¸€å¤šç ',
                'é¾™è™çŸ›ç›¾': 'é¾™è™çŸ›ç›¾',
                'åä¸ªä½ç½®å…¨æŠ•': 'åä¸ªä½ç½®å…¨æŠ•'
            },
            'å¿«ä¸‰': {
                'å’Œå€¼å¤šç ': 'å’Œå€¼å¤šç ',
                'å’Œå€¼çŸ›ç›¾': 'å’Œå€¼çŸ›ç›¾',  # å¤§å°å•åŒåŒæ—¶ä¸‹æ³¨
                'å’Œå€¼å¤§å°çŸ›ç›¾': 'å’Œå€¼å¤§å°çŸ›ç›¾',  # æŠ•æ³¨æ–¹å‘ä¸å·ç åˆ†å¸ƒçŸ›ç›¾
                'ç‹¬èƒ†å¤šç ': 'ç‹¬èƒ†å¤šç ',
                'ä¸åŒå·å…¨åŒ…': 'ä¸åŒå·å…¨åŒ…',
                'ä¸¤é¢çŸ›ç›¾': 'ä¸¤é¢çŸ›ç›¾'
            },
            'å…­åˆå½©': {
                'æ•°å­—ç±»å¤šç ': 'æ•°å­—ç±»å¤šç ',
                'ç‰¹ç å¤šç ': 'ç‰¹ç å¤šç ',
                'æ­£ç å¤šç ': 'æ­£ç å¤šç ',
                'æ­£ç 1-6å¤šç ': 'æ­£ç 1-6å¤šç ',
                'æ­£ç‰¹å¤šç ': 'æ­£ç‰¹å¤šç ',
                'ç”Ÿè‚–ç±»å¤šç ': 'ç”Ÿè‚–ç±»å¤šç ',
                'å¹³ç‰¹å¤šè‚–': 'å¹³ç‰¹å¤šè‚–',
                'ç‰¹è‚–å¤šè‚–': 'ç‰¹è‚–å¤šè‚–',
                'ä¸€è‚–å¤šè‚–': 'ä¸€è‚–å¤šè‚–',
                # å°¾æ•°ç›¸å…³è¡Œä¸ºç±»å‹ç‹¬ç«‹æ˜¾ç¤º
                'å°¾æ•°å¤šç ': 'å°¾æ•°å¤šç ',
                'å°¾æ•°å¤´å°¾å¤šç ': 'å°¾æ•°å¤´å°¾å¤šç ',
                'ç‰¹å°¾å¤šå°¾': 'ç‰¹å°¾å¤šå°¾',
                'å…¨å°¾å¤šå°¾': 'å…¨å°¾å¤šå°¾',
                'ä¸¤é¢ç©æ³•çŸ›ç›¾': 'ä¸¤é¢ç©æ³•çŸ›ç›¾',
                'æ­£ç 1-6çŸ›ç›¾': 'æ­£ç 1-6çŸ›ç›¾',
                'æ­£ç‰¹çŸ›ç›¾': 'æ­£ç‰¹çŸ›ç›¾',
                'æ­£1ç‰¹å¤šç ': 'æ­£1ç‰¹å¤šç ',
                'æ­£2ç‰¹å¤šç ': 'æ­£2ç‰¹å¤šç ', 
                'æ­£3ç‰¹å¤šç ': 'æ­£3ç‰¹å¤šç ',
                'æ­£4ç‰¹å¤šç ': 'æ­£4ç‰¹å¤šç ',
                'æ­£5ç‰¹å¤šç ': 'æ­£5ç‰¹å¤šç ',
                'æ­£6ç‰¹å¤šç ': 'æ­£6ç‰¹å¤šç ',
                'æ­£1ç‰¹çŸ›ç›¾': 'æ­£1ç‰¹çŸ›ç›¾',
                'æ­£2ç‰¹çŸ›ç›¾': 'æ­£2ç‰¹çŸ›ç›¾',
                'æ­£3ç‰¹çŸ›ç›¾': 'æ­£3ç‰¹çŸ›ç›¾',
                'æ­£4ç‰¹çŸ›ç›¾': 'æ­£4ç‰¹çŸ›ç›¾',
                'æ­£5ç‰¹çŸ›ç›¾': 'æ­£5ç‰¹çŸ›ç›¾',
                'æ­£6ç‰¹çŸ›ç›¾': 'æ­£6ç‰¹çŸ›ç›¾',
                'åŒºé—´å¤šç»„': 'åŒºé—´å¤šç»„',
                'æ³¢è‰²ä¸‰ç»„': 'æ³¢è‰²ä¸‰ç»„',
                'è‰²æ³¢ä¸‰ç»„': 'è‰²æ³¢ä¸‰ç»„',
                # è¿è‚–ç›¸å…³ - å…·ä½“ç±»å‹
                'äºŒè¿è‚–å¤šè‚–': 'äºŒè¿è‚–å¤šè‚–',
                'ä¸‰è¿è‚–å¤šè‚–': 'ä¸‰è¿è‚–å¤šè‚–', 
                'å››è¿è‚–å¤šè‚–': 'å››è¿è‚–å¤šè‚–',
                'äº”è¿è‚–å¤šè‚–': 'äº”è¿è‚–å¤šè‚–',
                'è¿è‚–å¤šè‚–': 'è¿è‚–å¤šè‚–',  # ä¿ç•™é€šç”¨ç±»å‹ä½œä¸ºåå¤‡
                # æ­£ç æ³¢è‰²ç›¸å…³
                'æ­£ç æ³¢è‰²å…¨åŒ…': 'æ­£ç æ³¢è‰²å…¨åŒ…',   
                'æ­£ç ä¸€æ³¢è‰²å…¨åŒ…': 'æ­£ç ä¸€æ³¢è‰²å…¨åŒ…',
                'æ­£ç äºŒæ³¢è‰²å…¨åŒ…': 'æ­£ç äºŒæ³¢è‰²å…¨åŒ…',
                'æ­£ç ä¸‰æ³¢è‰²å…¨åŒ…': 'æ­£ç ä¸‰æ³¢è‰²å…¨åŒ…',
                'æ­£ç å››æ³¢è‰²å…¨åŒ…': 'æ­£ç å››æ³¢è‰²å…¨åŒ…',
                'æ­£ç äº”æ³¢è‰²å…¨åŒ…': 'æ­£ç äº”æ³¢è‰²å…¨åŒ…',
                'æ­£ç å…­æ³¢è‰²å…¨åŒ…': 'æ­£ç å…­æ³¢è‰²å…¨åŒ…',        
                # è¿å°¾ç›¸å…³ - å…·ä½“ç±»å‹
                'äºŒè¿å°¾å¤šå°¾': 'äºŒè¿å°¾å¤šå°¾',
                'ä¸‰è¿å°¾å¤šå°¾': 'ä¸‰è¿å°¾å¤šå°¾',
                'å››è¿å°¾å¤šå°¾': 'å››è¿å°¾å¤šå°¾',
                'äº”è¿å°¾å¤šå°¾': 'äº”è¿å°¾å¤šå°¾',
                'è¿å°¾å¤šå°¾': 'è¿å°¾å¤šå°¾',  # ä¿ç•™é€šç”¨ç±»å‹ä½œä¸ºåå¤‡
                # æ³¢è‰²ç›¸å…³è¡Œä¸º
                'è‰²æ³¢å…¨åŒ…': 'è‰²æ³¢å…¨åŒ…',                   # ä¼ ç»Ÿè‰²æ³¢å…¨åŒ…
                'ä¸ƒè‰²æ³¢å¤šè‰²': 'ä¸ƒè‰²æ³¢å¤šè‰²',
                'è‰²æ³¢ä¸­åŠæ³¢å…¨åŒ…': 'è‰²æ³¢ä¸­åŠæ³¢å…¨åŒ…',       # è‰²æ³¢ç©æ³•ä¸­çš„åŠæ³¢å…¨åŒ…
                'åŠæ³¢å¤§å°å…¨åŒ…': 'åŠæ³¢å¤§å°å…¨åŒ…',           # åŠæ³¢ç©æ³•ä¸­çš„å¤§å°å…¨åŒ…
                'åŠæ³¢å•åŒå…¨åŒ…': 'åŠæ³¢å•åŒå…¨åŒ…',           # åŠæ³¢ç©æ³•ä¸­çš„å•åŒå…¨åŒ…
                'äº”è¡Œå¤šç»„': 'äº”è¡Œå¤šç»„',
                'è¿è‚–å¤šè‚–': 'è¿è‚–å¤šè‚–',
                'è¿å°¾å¤šå°¾': 'è¿å°¾å¤šå°¾'
            },
            '3Dç³»åˆ—': {
                'ç™¾ä½å¤šç ': 'ç™¾ä½å¤šç ',
                'åä½å¤šç ': 'åä½å¤šç ',
                'ä¸ªä½å¤šç ': 'ä¸ªä½å¤šç ',
                'ä¸¤é¢çŸ›ç›¾': 'ä¸¤é¢çŸ›ç›¾',
                'å®šä½èƒ†å¤šç ': 'å®šä½èƒ†å¤šç '
            },
            'æ—¶æ—¶å½©': {
                'ç¬¬1çƒå¤šç ': 'ç¬¬1çƒå¤šç ',
                'ç¬¬2çƒå¤šç ': 'ç¬¬2çƒå¤šç ',
                'ç¬¬3çƒå¤šç ': 'ç¬¬3çƒå¤šç ',
                'ç¬¬4çƒå¤šç ': 'ç¬¬4çƒå¤šç ',
                'ç¬¬5çƒå¤šç ': 'ç¬¬5çƒå¤šç ',
                'ä¸¤é¢çŸ›ç›¾': 'ä¸¤é¢çŸ›ç›¾',
                'æ–—ç‰›å¤šç ': 'æ–—ç‰›å¤šç ',
                'å®šä½èƒ†å¤šç ': 'å®šä½èƒ†å¤šç ',
                'æ€»å’ŒçŸ›ç›¾': 'æ€»å’ŒçŸ›ç›¾'
            },
            'ä¸‰è‰²å½©': {
                'æ­£ç å¤šç ': 'æ­£ç å¤šç ',
                'ä¸¤é¢çŸ›ç›¾': 'ä¸¤é¢çŸ›ç›¾',
                'è‰²æ³¢å…¨åŒ…': 'è‰²æ³¢å…¨åŒ…',
                'è‰²æ³¢çº¢ç»¿æŠ•æ³¨': 'è‰²æ³¢çº¢ç»¿æŠ•æ³¨'
            }
        }
        self.displayed_records_cache = set()  # ç¼“å­˜å·²æ˜¾ç¤ºçš„è®°å½•
    
    def organize_results_by_account(self, all_results):
        """ç»„ç»‡ç»“æœæŒ‰è´¦æˆ·åˆ†ç±»æœ¬"""
        account_results = defaultdict(lambda: {
            'violations': [],
            'periods': set(),
            'violation_types': set(),
            'violation_count': 0,
            'lottery_types': set(),
            'violations_by_type': defaultdict(list),
            'violations_by_lottery': defaultdict(lambda: defaultdict(list))
        })
        
        for lottery_type, results in all_results.items():
            for result_type, records in results.items():
                for record in records:
                    account = record['ä¼šå‘˜è´¦å·']
                    period = record['æœŸå·']
                    lottery = record['å½©ç§']
                    
                    violation_record = {
                        'å½©ç§': lottery,
                        'æœŸå·': period,
                        'ç©æ³•åˆ†ç±»': record['ç©æ³•åˆ†ç±»'],
                        'è¿è§„ç±»å‹': result_type,
                        'è¯¦ç»†ä¿¡æ¯': self._get_violation_details(record, result_type),
                        'æŠ•æ³¨å†…å®¹': record.get('æŠ•æ³¨å†…å®¹', ''),
                        'å·ç æ•°é‡': record.get('å·ç æ•°é‡', 0),
                        'çŸ›ç›¾ç±»å‹': record.get('çŸ›ç›¾ç±»å‹', ''),
                        'ä½ç½®': record.get('ä½ç½®', ''),
                        'æ’åºæƒé‡': record.get('æ’åºæƒé‡', 0)
                    }
                    
                    account_results[account]['violations'].append(violation_record)
                    account_results[account]['violations_by_type'][result_type].append(violation_record)
                    account_results[account]['violations_by_lottery'][lottery][result_type].append(violation_record)
                    account_results[account]['periods'].add(period)
                    account_results[account]['violation_types'].add(result_type)
                    account_results[account]['violation_count'] += 1
                    account_results[account]['lottery_types'].add(lottery)
        
        return account_results
    
    def _get_violation_details(self, record, result_type):
        """è·å–è¿è§„è¯¦æƒ…"""
        details = []
        
        # ä¸“é—¨å¤„ç†å’Œå€¼å¤§å°çŸ›ç›¾çš„æ˜¾ç¤º
        if 'å’Œå€¼å¤§å°çŸ›ç›¾' in result_type:
            # å’Œå€¼å¤§å°çŸ›ç›¾æ˜¾ç¤ºçŸ›ç›¾ç±»å‹å’ŒçŸ›ç›¾å€¼
            if record.get('çŸ›ç›¾ç±»å‹'):
                details.append(f"çŸ›ç›¾ç±»å‹: {record['çŸ›ç›¾ç±»å‹']}")
            if record.get('çŸ›ç›¾å€¼', 0) > 0:
                details.append(f"çŸ›ç›¾å€¼: {record['çŸ›ç›¾å€¼']}")
            return ' | '.join(details) if details else 'æ— è¯¦æƒ…'
        
        # ä¸“é—¨å¤„ç†å’Œå€¼çŸ›ç›¾çš„æ˜¾ç¤º
        elif 'å’Œå€¼çŸ›ç›¾' in result_type:
            # å’Œå€¼çŸ›ç›¾åªæ˜¾ç¤ºçŸ›ç›¾ç±»å‹
            if record.get('çŸ›ç›¾ç±»å‹'):
                details.append(f"çŸ›ç›¾ç±»å‹: {record['çŸ›ç›¾ç±»å‹']}")
            return ' | '.join(details) if details else 'æ— è¯¦æƒ…'
        
        # å°¾æ•°å¤šç çš„ç‰¹æ®Šå¤„ç†
        elif 'å°¾æ•°' in result_type:
            # ä¼˜å…ˆä½¿ç”¨å°¾æ•°æ•°é‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å·ç æ•°é‡
            tail_count = record.get('å°¾æ•°æ•°é‡', record.get('å·ç æ•°é‡', 0))
            details.append(f"å°¾æ•°æ•°é‡: {tail_count}ä¸ª")
        
        # æ­£å¸¸å¤„ç†å…¶ä»–ç±»å‹
        else:
            if 'å·ç æ•°é‡' in record and record['å·ç æ•°é‡'] > 0:
                details.append(f"å·ç æ•°é‡: {record['å·ç æ•°é‡']}")
            if 'çŸ›ç›¾ç±»å‹' in record:
                details.append(f"çŸ›ç›¾ç±»å‹: {record['çŸ›ç›¾ç±»å‹']}")
            if 'ä½ç½®' in record:
                details.append(f"ä½ç½®: {record['ä½ç½®']}")
            if 'ç”Ÿè‚–æ•°é‡' in record and record['ç”Ÿè‚–æ•°é‡'] > 0:
                details.append(f"ç”Ÿè‚–æ•°é‡: {record['ç”Ÿè‚–æ•°é‡']}")
            if 'æŠ•æ³¨åŒºé—´æ•°' in record and record['æŠ•æ³¨åŒºé—´æ•°'] > 0:
                details.append(f"æŠ•æ³¨åŒºé—´æ•°: {record['æŠ•æ³¨åŒºé—´æ•°']}")
            if 'æŠ•æ³¨æ³¢è‰²æ•°' in record and record['æŠ•æ³¨æ³¢è‰²æ•°'] > 0:
                details.append(f"æŠ•æ³¨æ³¢è‰²æ•°: {record['æŠ•æ³¨æ³¢è‰²æ•°']}")
            if 'æŠ•æ³¨äº”è¡Œæ•°' in record and record['æŠ•æ³¨äº”è¡Œæ•°'] > 0:
                details.append(f"æŠ•æ³¨äº”è¡Œæ•°: {record['æŠ•æ³¨äº”è¡Œæ•°']}")
        
        return ' | '.join(details) if details else 'æ— è¯¦æƒ…'
    
    def optimize_display_records(self, records, max_records=5):
        """ä¼˜åŒ–æ˜¾ç¤ºè®°å½•"""
        if not records:
            return []
        
        # é‡ç½®ç¼“å­˜ï¼ˆæ¯æ¬¡è°ƒç”¨æ—¶é‡æ–°è®¡ç®—ï¼‰
        self.displayed_records_cache = set()
        
        def get_record_key(record):
            """ç”Ÿæˆè®°å½•çš„å”¯ä¸€é”®"""
            return (
                record.get('ä¼šå‘˜è´¦å·', ''),
                record.get('æœŸå·', ''),
                record.get('ç©æ³•åˆ†ç±»', ''),
                record.get('è¿è§„ç±»å‹', ''),
                record.get('ä½ç½®', ''),
                record.get('çŸ›ç›¾ç±»å‹', '')
            )
        
        # å»é‡å¹¶æ’åº
        unique_records = []
        seen_keys = set()
        
        for record in records:
            record_key = get_record_key(record)
            if record_key not in seen_keys:
                seen_keys.add(record_key)
                unique_records.append(record)
        
        # æŒ‰æ’åºæƒé‡æ’åº
        unique_records.sort(key=lambda x: x.get('æ’åºæƒé‡', 0), reverse=True)
        
        # å¯¹äºå’Œå€¼çŸ›ç›¾ï¼Œç¡®ä¿å±•ç¤ºå¤šæ ·æ€§
        if unique_records and 'å’Œå€¼çŸ›ç›¾' in unique_records[0].get('è¿è§„ç±»å‹', ''):
            return self._ensure_variety_in_display(unique_records, max_records)
        else:
            return unique_records[:max_records]
    
    def _ensure_variety_in_display(self, records, max_records=5):
        """ç¡®ä¿å±•ç¤ºçš„è®°å½•åŒ…å«ä¸åŒç±»å‹çš„çŸ›ç›¾"""
        if len(records) <= max_records:
            return records
        
        # æŒ‰çŸ›ç›¾ç±»å‹åˆ†ç»„
        conflict_groups = {
            'å¤§å°': [],
            'å•åŒ': [], 
            'å¤§å°å•åŒ': [],
            'å…¶ä»–': []
        }
        
        for record in records:
            conflict_type = record.get('çŸ›ç›¾ç±»å‹', '')
            if 'å¤§å°' in conflict_type and 'å•åŒ' in conflict_type:
                conflict_groups['å¤§å°å•åŒ'].append(record)
            elif 'å¤§å°' in conflict_type:
                conflict_groups['å¤§å°'].append(record)
            elif 'å•åŒ' in conflict_type:
                conflict_groups['å•åŒ'].append(record)
            else:
                conflict_groups['å…¶ä»–'].append(record)
        
        # ä¼˜å…ˆä»æ¯ä¸ªç±»å‹ä¸­é€‰å–ä»£è¡¨æ€§è®°å½•
        selected_records = []
        
        # ç¬¬ä¸€è½®ï¼šä»æ¯ä¸ªéç©ºç±»å‹ä¸­å„å–1æ¡
        for group_name in ['å¤§å°å•åŒ', 'å¤§å°', 'å•åŒ', 'å…¶ä»–']:
            if conflict_groups[group_name] and len(selected_records) < max_records:
                selected_records.append(conflict_groups[group_name][0])
        
        # å¦‚æœè¿˜æ²¡å–æ»¡ï¼Œç»§ç»­æŒ‰åŸæœ‰é¡ºåºè¡¥å……
        if len(selected_records) < max_records:
            # è·å–å·²é€‰è®°å½•çš„ç´¢å¼•ï¼Œé¿å…é‡å¤
            selected_indices = set(records.index(r) for r in selected_records)
            
            for record in records:
                if records.index(record) not in selected_indices and len(selected_records) < max_records:
                    selected_records.append(record)
        
        return selected_records
    
    def create_summary_stats(self, account_results, df_clean):
        """åˆ›å»ºæ±‡æ€»ç»Ÿè®¡"""
        total_violations = sum(data['violation_count'] for data in account_results.values())
        
        summary = {
            'æ€»è®°å½•æ•°': len(df_clean),
            'æ€»ä¼šå‘˜æ•°': df_clean['ä¼šå‘˜è´¦å·'].nunique(),
            'è¿è§„è´¦æˆ·æ•°': len(account_results),
            'æ€»è¿è§„è®°å½•æ•°': total_violations,
            'æ€»è¿è§„æœŸæ•°': sum(len(data['periods']) for data in account_results.values()),
            'å½©ç§åˆ†å¸ƒ': df_clean['å½©ç§'].value_counts().to_dict(),
            'è¿è§„ç±»å‹ç»Ÿè®¡': defaultdict(int),
            'è´¦æˆ·è¿è§„ç»Ÿè®¡': []
        }
        
        for account, data in account_results.items():
            for violation_type in data['violation_types']:
                summary['è¿è§„ç±»å‹ç»Ÿè®¡'][violation_type] += len(data['violations_by_type'][violation_type])
            
            summary['è´¦æˆ·è¿è§„ç»Ÿè®¡'].append({
                'è´¦æˆ·': account,
                'è¿è§„æœŸæ•°': len(data['periods']),
                'è¿è§„æ¬¡æ•°': data['violation_count'],
                'è¿è§„ç±»å‹æ•°': len(data['violation_types']),
                'å½©ç§æ•°': len(data['lottery_types'])
            })
        
        summary['è´¦æˆ·è¿è§„ç»Ÿè®¡'] = sorted(summary['è´¦æˆ·è¿è§„ç»Ÿè®¡'], key=lambda x: x['è¿è§„æ¬¡æ•°'], reverse=True)
        
        return summary
    
    def display_summary(self, summary):
        """æ˜¾ç¤ºæ±‡æ€»ç»Ÿè®¡"""
        st.subheader("ğŸ“Š æ±‡æ€»ç»Ÿè®¡")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»è®°å½•æ•°", summary['æ€»è®°å½•æ•°'])
        with col2:
            st.metric("æ€»ä¼šå‘˜æ•°", summary['æ€»ä¼šå‘˜æ•°'])
        with col3:
            st.metric("è¿è§„è´¦æˆ·æ•°", summary['è¿è§„è´¦æˆ·æ•°'])
        with col4:
            st.metric("æ€»è¿è§„è®°å½•æ•°", summary['æ€»è¿è§„è®°å½•æ•°'])
        
        if summary['è¿è§„ç±»å‹ç»Ÿè®¡']:
            with st.expander("ğŸ“ˆ è¿è§„ç±»å‹åˆ†å¸ƒ", expanded=False):
                violation_df = pd.DataFrame({
                    'è¿è§„ç±»å‹': list(summary['è¿è§„ç±»å‹ç»Ÿè®¡'].keys()),
                    'æ•°é‡': list(summary['è¿è§„ç±»å‹ç»Ÿè®¡'].values())
                }).sort_values('æ•°é‡', ascending=False)
                
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.bar_chart(violation_df.set_index('è¿è§„ç±»å‹'))
                with col2:
                    st.dataframe(violation_df, hide_index=True)
        
        if summary['è´¦æˆ·è¿è§„ç»Ÿè®¡']:
            with st.expander("ğŸ† è´¦æˆ·è¿è§„æ’å", expanded=False):
                top_accounts = summary['è´¦æˆ·è¿è§„ç»Ÿè®¡'][:10]
                account_df = pd.DataFrame(top_accounts)
                st.dataframe(account_df, hide_index=True)
    
    def display_account_results(self, account_results):
        """æ˜¾ç¤ºè´¦æˆ·ç»“æœæœ¬"""
        if not account_results:
            st.info("ğŸ‰ æœªå‘ç°å¯ç–‘æŠ•æ³¨è¡Œä¸º")
            return
        
        st.subheader("ğŸ” è¿è§„è´¦æˆ·è¯¦æƒ…")
        
        sorted_accounts = sorted(account_results.items(), 
                               key=lambda x: x[1]['violation_count'], 
                               reverse=True)
        
        for account_index, (account, data) in enumerate(sorted_accounts, 1):
            # è½¬ä¹‰è´¦å·ä¸­çš„ä¸‹åˆ’çº¿
            account_display = account.replace('_', '\\_')
            
            with st.container():
                col1, col2, col3 = st.columns([3, 2, 1])
                
                with col1:
                    st.subheader(f"{account_index}. {account_display}")  # ä½¿ç”¨è½¬ä¹‰åçš„è´¦å·
                    # ä½¿ç”¨ data ä¸­çš„ lottery_types
                    lottery_types_list = list(data['lottery_types'])
                    st.write(f"**æ¶‰åŠå½©ç§:** {', '.join(lottery_types_list[:5])}{'...' if len(lottery_types_list) > 5 else ''}")

                with col2:
                    # ä½¿ç”¨ data ä¸­çš„ violation_types
                    violation_types_list = list(data['violation_types'])
                    violation_text = "ã€".join(violation_types_list[:5])
                    if len(violation_types_list) > 5:
                        violation_text += f" ç­‰{len(violation_types_list)}ç§"
                    st.write(f"**è¿è§„å†…å®¹:** {violation_text}")

                with col3:
                    # ä½¿ç”¨ data ä¸­çš„ periods å’Œ violation_count
                    st.write(f"**è¿è§„æœŸæ•°:** {len(data['periods'])}")
                    st.write(f"**è¿è§„æ¬¡æ•°:** {data['violation_count']}")
                
                # æŒ‰å½©ç§å’Œè¿è§„ç±»å‹åˆ†ç»„æ˜¾ç¤ºï¼Œé¿å…é‡å¤
                displayed_violations = set()
                
                for lottery in sorted(data['violations_by_lottery'].keys()):
                    lottery_violations = data['violations_by_lottery'][lottery]
                    
                    with st.expander(f"ğŸ¯ {lottery} (å…±{sum(len(v) for v in lottery_violations.values())}æ¬¡è¿è§„)", expanded=True):
                        
                        for violation_type in sorted(lottery_violations.keys()):
                            type_violations = lottery_violations[violation_type]
                            
                            # ä½¿ç”¨ä¼˜åŒ–æ˜¾ç¤ºæ–¹æ³•
                            representative_records = self.optimize_display_records(type_violations, max_records=5)
                            other_records_count = len(type_violations) - len(representative_records)
                            
                            if representative_records:
                                st.write(f"**{violation_type}** ({len(type_violations)}æ¬¡)")
                                
                                # å‡†å¤‡æ˜¾ç¤ºæ•°æ®
                                display_data = []
                                for record in representative_records:
                                    display_record = {
                                        'æœŸå·': record['æœŸå·'],
                                        'ç©æ³•åˆ†ç±»': record['ç©æ³•åˆ†ç±»'],
                                        'è¿è§„ç±»å‹': violation_type,
                                        'è¯¦ç»†ä¿¡æ¯': record.get('è¯¦ç»†ä¿¡æ¯', ''),
                                        'æŠ•æ³¨å†…å®¹': record.get('æŠ•æ³¨å†…å®¹', '')
                                    }
                                    # æ·»åŠ ä½ç½®ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                                    if record.get('ä½ç½®'):
                                        display_record['ä½ç½®'] = record['ä½ç½®']
                                    display_data.append(display_record)
                                
                                df_display = pd.DataFrame(display_data)
                                container = st.container()
                                with container:
                                    st.dataframe(
                                        df_display,
                                        use_container_width=True,
                                        hide_index=True,
                                        height=min(300, len(representative_records) * 35 + 38)
                                    )
                                
                                if other_records_count > 0:
                                    st.info(f"è¿˜æœ‰ {other_records_count} æ¡ç›¸å…³è®°å½•...")
                
                st.markdown("---")

# ==================== å¯¼å‡ºåŠŸèƒ½ ====================
class Exporter:
    """ç»“æœå¯¼å‡ºå™¨"""
    
    def prepare_export_data(self, account_summary):
        """å‡†å¤‡å¯¼å‡ºæ•°æ®"""
        export_data = []
        
        for account, summary in account_summary.items():
            for lottery, lottery_data in summary['violations_by_lottery'].items():
                for behavior_type, records in lottery_data.items():
                    for record in records:
                        export_record = {
                            'ä¼šå‘˜è´¦å·': account,
                            'å½©ç§': lottery,
                            'æœŸå·': record['æœŸå·'],
                            'ç©æ³•åˆ†ç±»': record['ç©æ³•åˆ†ç±»'],
                            'è¡Œä¸ºç±»å‹': behavior_type
                        }
                        
                        # æ·»åŠ çŸ›ç›¾ç±»å‹
                        if 'çŸ›ç›¾ç±»å‹' in record:
                            export_record['çŸ›ç›¾ç±»å‹'] = record['çŸ›ç›¾ç±»å‹']
                        
                        # æ·»åŠ æ•°é‡ä¿¡æ¯
                        self._add_quantity_info(export_record, record, behavior_type)
                        
                        export_data.append(export_record)
        
        return export_data
    
    def _add_quantity_info(self, export_record, record, behavior_type):
        """æ·»åŠ æ•°é‡ä¿¡æ¯åˆ°å¯¼å‡ºè®°å½•"""
        quantity_fields = {
            # å¿«ä¸‰ç›¸å…³
            'å’Œå€¼å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å’Œå€¼çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),  # å’Œå€¼çŸ›ç›¾åªæœ‰æŠ•æ³¨å†…å®¹
            'å’Œå€¼å¤§å°çŸ›ç›¾': ('çŸ›ç›¾å€¼', 'æŠ•æ³¨å†…å®¹'),  # å’Œå€¼å¤§å°çŸ›ç›¾æœ‰çŸ›ç›¾å€¼
            'ç‹¬èƒ†å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ä¸åŒå·å…¨åŒ…': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ä¸¤é¢çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),

            # PK10æ–°å¢
            'åä¸ªä½ç½®å…¨æŠ•': ('æŠ•æ³¨ä½ç½®æ•°', 'æŠ•æ³¨å†…å®¹'),
            
            # å…­åˆå½©ç›¸å…³
            'æ•°å­—ç±»å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç‰¹ç å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç 1-6å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç‰¹å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç”Ÿè‚–ç±»å¤šç ': ('ç”Ÿè‚–æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å¹³ç‰¹å¤šè‚–': ('ç”Ÿè‚–æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç‰¹è‚–å¤šè‚–': ('ç”Ÿè‚–æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ä¸€è‚–å¤šè‚–': ('ç”Ÿè‚–æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å°¾æ•°å¤šç ': ('å°¾æ•°æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å°¾æ•°å¤´å°¾å¤šç ': ('å°¾æ•°æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç‰¹å°¾å¤šå°¾': ('å°¾æ•°æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å…¨å°¾å¤šå°¾': ('å°¾æ•°æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'è¿è‚–å¤šè‚–': ('ç”Ÿè‚–æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'è¿å°¾å¤šå°¾': ('å°¾æ•°æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'åŒºé—´å¤šç»„': ('æŠ•æ³¨åŒºé—´æ•°', 'æŠ•æ³¨å†…å®¹'),
            'æ³¢è‰²ä¸‰ç»„': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),
            'è‰²æ³¢ä¸‰ç»„': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),
            # ä¿®æ”¹ä¸ºåªè®°å½•å…¨åŒ…æƒ…å†µ
            'è‰²æ³¢å…¨åŒ…': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),
            'åŠæ³¢å•åŒå…¨åŒ…': ('æŠ•æ³¨åŠæ³¢æ•°', 'æŠ•æ³¨å†…å®¹'),
            'åŠæ³¢å¤§å°å…¨åŒ…': ('æŠ•æ³¨åŠæ³¢æ•°', 'æŠ•æ³¨å†…å®¹'),
            'äº”è¡Œå¤šç»„': ('æŠ•æ³¨äº”è¡Œæ•°', 'æŠ•æ³¨å†…å®¹'),
            'ä¸¤é¢ç©æ³•çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç 1-6çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç ä¸€æ³¢è‰²å…¨åŒ…': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç äºŒæ³¢è‰²å…¨åŒ…': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç ä¸‰æ³¢è‰²å…¨åŒ…': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç å››æ³¢è‰²å…¨åŒ…': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç äº”æ³¢è‰²å…¨åŒ…': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç å…­æ³¢è‰²å…¨åŒ…': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç‰¹çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            # æ­£ç‰¹å…·ä½“ä½ç½®
            'æ­£1ç‰¹å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'æ­£2ç‰¹å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'æ­£3ç‰¹å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'æ­£4ç‰¹å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'æ­£5ç‰¹å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'æ­£6ç‰¹å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'æ­£1ç‰¹çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'æ­£2ç‰¹çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'æ­£3ç‰¹çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'æ­£4ç‰¹çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'æ­£5ç‰¹çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'æ­£6ç‰¹çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),

            # åŠæ³¢ç›¸å…³
            'åŠæ³¢å…¨åŒ…': (None, 'æŠ•æ³¨å†…å®¹'),
            'åŠæ³¢å¤šç»„æŠ•æ³¨': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),       
            
             # ä¸‰è‰²å½©ç›¸å…³
            'è‰²æ³¢å…¨åŒ…': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),
            'è‰²æ³¢çº¢ç»¿æŠ•æ³¨': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),

             # 3Dç³»åˆ—ç›¸å…³
            'ç™¾ä½å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'åä½å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ä¸ªä½å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ä¸¤é¢çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'å®šä½èƒ†å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),

             # æ—¶æ—¶å½©ç›¸å…³
            'æ–—ç‰›å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å®šä½èƒ†å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬1çƒå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬2çƒå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬3çƒå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬4çƒå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬5çƒå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬6çƒå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬7çƒå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬8çƒå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬9çƒå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬10çƒå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            
            # PK10ç›¸å…³
            'è¶…ç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å† å†›å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'äºšå†›å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬ä¸‰åå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬å››åå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬äº”åå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬å…­åå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬ä¸ƒåå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬å…«åå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬ä¹åå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç¬¬ååå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å† äºšå’Œå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å‰ä¸€å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å† äºšå’ŒçŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'ä¸¤é¢çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'ç‹¬ç«‹ç©æ³•çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'é¾™è™çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'æ€»å’ŒçŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'è‰²æ³¢çŸ›ç›¾æŠ•æ³¨': (None, 'æŠ•æ³¨å†…å®¹'),
            'ä¸¤é¢ç©æ³•çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç 1-6çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç‰¹çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
        }
        
        if behavior_type in quantity_fields:
            count_field, content_field = quantity_fields[behavior_type]
            if count_field and count_field in record:
                export_record[count_field] = record[count_field]
            
            if content_field and record.get(content_field):
                export_record[content_field] = str(record[content_field])
            
            # æ·»åŠ ä½ç½®ä¿¡æ¯ï¼ˆ3Dç³»åˆ—ä¸“ç”¨ï¼‰
            if record.get('ä½ç½®'):
                export_record['ä½ç½®'] = record['ä½ç½®']
    
    def export_to_excel(self, account_summary, filename_prefix="å½©ç¥¨åˆ†æç»“æœ"):
        """å¯¼å‡ºåˆ†æç»“æœåˆ°Excelæ–‡ä»¶"""
        try:
            export_data = self.prepare_export_data(account_summary)
            
            if not export_data:
                st.warning("æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®")
                return
            
            # åˆ›å»ºDataFrame
            df_export = pd.DataFrame(export_data)
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
            output_filename = f"{filename_prefix}_{timestamp}.xlsx"
            
            with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:
                # å†™å…¥è¯¦ç»†æ•°æ®
                df_export.to_excel(writer, sheet_name='è¯¦ç»†åˆ†æç»“æœ', index=False)
                
                # åˆ›å»ºç»Ÿè®¡å·¥ä½œè¡¨
                self._create_summary_sheets(writer, account_summary, export_data)
            
            st.success(f"âœ… åˆ†æç»“æœå·²æˆåŠŸå¯¼å‡ºåˆ°: {output_filename}")
            st.info(f"ğŸ“Š å¯¼å‡ºå†…å®¹åŒ…å« {len(export_data)} æ¡è®°å½•")
            
            # æä¾›ä¸‹è½½
            with open(output_filename, "rb") as file:
                btn = st.download_button(
                    label="ğŸ“¥ ä¸‹è½½åˆ†æç»“æœ",
                    data=file,
                    file_name=output_filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            
        except Exception as e:
            st.error(f"âŒ å¯¼å‡ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
    
    def _create_summary_sheets(self, writer, account_summary, export_data):
        """åˆ›å»ºç»Ÿè®¡å·¥ä½œè¡¨"""
        # è´¦æˆ·ç»Ÿè®¡
        account_stats = []
        for account, summary in account_summary.items():
            account_stats.append({
                'ä¼šå‘˜è´¦å·': account,
                'æ€»å¯ç–‘æœŸå·æ•°': len(summary['periods']),
                'æ¶‰åŠå½©ç§æ•°': len(summary['lottery_types']),
                'è¡Œä¸ºç±»å‹æ•°': len(summary['violation_types'])
            })
        
        if account_stats:
            df_account_stats = pd.DataFrame(account_stats)
            df_account_stats.to_excel(writer, sheet_name='è´¦æˆ·ç»Ÿè®¡', index=False)
        
        # è¡Œä¸ºç±»å‹ç»Ÿè®¡
        if export_data:
            behavior_stats = pd.DataFrame(export_data)['è¡Œä¸ºç±»å‹'].value_counts().reset_index()
            behavior_stats.columns = ['è¡Œä¸ºç±»å‹', 'è®°å½•æ•°']
            behavior_stats.to_excel(writer, sheet_name='è¡Œä¸ºç±»å‹ç»Ÿè®¡', index=False)
        
        # å½©ç§ç»Ÿè®¡
        if export_data:
            lottery_stats = pd.DataFrame(export_data)['å½©ç§'].value_counts().reset_index()
            lottery_stats.columns = ['å½©ç§', 'è®°å½•æ•°']
            lottery_stats.to_excel(writer, sheet_name='å½©ç§ç»Ÿè®¡', index=False)

# ==================== Streamlitç•Œé¢ ====================
def main():
    st.title("ğŸ¯ æ™ºèƒ½å½©ç¥¨åˆ†ææ£€æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    
    st.sidebar.title("ç³»ç»Ÿé…ç½®")
    
    uploaded_file = st.sidebar.file_uploader(
        "ä¸Šä¼ Excelæ–‡ä»¶", 
        type=['xlsx', 'xls'],
        help="è¯·ä¸Šä¼ åŒ…å«å½©ç¥¨æŠ•æ³¨æ•°æ®çš„Excelæ–‡ä»¶"
    )

    st.sidebar.subheader("æ•°æ®å¤„ç†é€‰é¡¹")
    enable_space_normalization = st.sidebar.checkbox(
        "å¯ç”¨ç©ºæ ¼æ ‡å‡†åŒ–å¤„ç†", 
        value=True,
        help="è‡ªåŠ¨å¤„ç†å„ç§ç©ºæ ¼å­—ç¬¦ï¼ˆæ™®é€šç©ºæ ¼ã€å…¨è§’ç©ºæ ¼ã€è¿ç»­ç©ºæ ¼ï¼‰"
    )

    st.sidebar.subheader("è°ƒè¯•é€‰é¡¹")
    enable_detailed_debug = st.sidebar.checkbox(
        "å¯ç”¨è¯¦ç»†è°ƒè¯•æ¨¡å¼", 
        value=True,
        help="æ˜¾ç¤ºè¯¦ç»†çš„å¤„ç†è¿‡ç¨‹å’Œè°ƒè¯•ä¿¡æ¯"
    )
    
    st.sidebar.subheader("æ£€æµ‹é˜ˆå€¼é…ç½®")
    
    with st.sidebar.expander("PKæ‹¾ç³»åˆ—é˜ˆå€¼"):
        pk10_multi = st.slider("è¶…ç é˜ˆå€¼", 5, 15, THRESHOLD_CONFIG['PK10']['multi_number'])
        pk10_gyh = st.slider("å† äºšå’Œå¤šç é˜ˆå€¼", 8, 20, THRESHOLD_CONFIG['PK10']['gyh_multi_number'])
        THRESHOLD_CONFIG['PK10']['multi_number'] = pk10_multi
        THRESHOLD_CONFIG['PK10']['gyh_multi_number'] = pk10_gyh
    
    with st.sidebar.expander("æ—¶æ—¶å½©ç³»åˆ—é˜ˆå€¼"):
        ssc_dingwei = st.slider("å®šä½èƒ†å¤šç é˜ˆå€¼", 5, 15, THRESHOLD_CONFIG['SSC']['dingwei_multi'])
        ssc_douniu = st.slider("æ–—ç‰›å¤šç é˜ˆå€¼", 5, 15, THRESHOLD_CONFIG['SSC']['douniu_multi'])
        THRESHOLD_CONFIG['SSC']['dingwei_multi'] = ssc_dingwei
        THRESHOLD_CONFIG['SSC']['douniu_multi'] = ssc_douniu
    
    with st.sidebar.expander("å…­åˆå½©ç³»åˆ—é˜ˆå€¼"):
        lhc_numbers = st.slider("æ•°å­—ç±»å¤šç é˜ˆå€¼", 20, 50, THRESHOLD_CONFIG['LHC']['number_play'])
        lhc_zodiacs = st.slider("ç”Ÿè‚–ç±»å¤šç é˜ˆå€¼", 5, 15, THRESHOLD_CONFIG['LHC']['zodiac_play'])
        lhc_tails = st.slider("å°¾æ•°å¤šç é˜ˆå€¼", 5, 15, THRESHOLD_CONFIG['LHC']['tail_play'])
        THRESHOLD_CONFIG['LHC']['number_play'] = lhc_numbers
        THRESHOLD_CONFIG['LHC']['zodiac_play'] = lhc_zodiacs
        THRESHOLD_CONFIG['LHC']['tail_play'] = lhc_tails
    
    with st.sidebar.expander("å¿«ä¸‰ç³»åˆ—é˜ˆå€¼"):
        k3_hezhi = st.slider("å’Œå€¼å¤šç é˜ˆå€¼", 5, 20, THRESHOLD_CONFIG['K3']['hezhi_multi_number'])
        k3_dudan_threshold = st.slider("ç‹¬èƒ†å¤šç é˜ˆå€¼", 2, 6, 5)
        THRESHOLD_CONFIG['K3']['hezhi_multi_number'] = k3_hezhi
        THRESHOLD_CONFIG['K3']['dudan_multi_number'] = k3_dudan_threshold
    
    with st.sidebar.expander("ä¸‰è‰²å½©ç³»åˆ—é˜ˆå€¼"):
        three_color_zhengma = st.slider("æ­£ç å¤šç é˜ˆå€¼", 5, 15, THRESHOLD_CONFIG['THREE_COLOR']['zhengma_multi'])
        THRESHOLD_CONFIG['THREE_COLOR']['zhengma_multi'] = three_color_zhengma

    with st.sidebar.expander("3Dç³»åˆ—é˜ˆå€¼"):
        three_d_dingwei = st.slider("3Då®šä½èƒ†å¤šç é˜ˆå€¼", 5, 10, THRESHOLD_CONFIG['3D']['dingwei_multi'])
        THRESHOLD_CONFIG['3D']['dingwei_multi'] = three_d_dingwei
    
    if uploaded_file is not None:
        try:
            with st.spinner('æ­£åœ¨å¤„ç†æ•°æ®...'):
                # åˆå§‹åŒ–ç»„ä»¶
                processor = DataProcessor()
                analyzer = AnalysisEngine()
                result_processor = ResultProcessor()
                exporter = Exporter()
                
                # æ•°æ®æ¸…æ´—
                df_clean = processor.clean_data(uploaded_file)
                
                if df_clean is not None and len(df_clean) > 0:
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("æ€»è®°å½•æ•°", len(df_clean))
                    with col2:
                        st.metric("å”¯ä¸€ä¼šå‘˜æ•°", df_clean['ä¼šå‘˜è´¦å·'].nunique())
                    with col3:
                        st.metric("å½©ç§æ•°é‡", df_clean['å½©ç§'].nunique())
                    
                    # ç»Ÿä¸€ç©æ³•åˆ†ç±»
                    df_normalized = analyzer.normalize_play_categories(df_clean)

                    # å¯ç”¨è°ƒè¯•æ¨¡å¼
                    if enable_detailed_debug:
                        st.info("ğŸ”§ è¯¦ç»†è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")
                    
                    # ==================== æ·»åŠ  try-except ä»£ç å—å¼€å§‹ ====================
                    try:
                        # åˆ†ææŠ•æ³¨æ¨¡å¼
                        all_results = analyzer.analyze_all_patterns(df_normalized)
                        
                        # ç»Ÿè®¡ç»“æœ
                        total_findings = 0
                        for lottery_type, results in all_results.items():
                            type_count = sum(len(records) for records in results.values())
                            total_findings += type_count
                        
                        with col4:
                            st.metric("å¯ç–‘è®°å½•æ•°", total_findings)
                        
                        with st.expander("ğŸ“Š æ•°æ®é¢„è§ˆ", expanded=False):
                            st.dataframe(df_clean.head(10))
                        
                        if total_findings == 0:
                            st.success("ğŸ‰ æœªå‘ç°å¯ç–‘æŠ•æ³¨è¡Œä¸º")
                        else:
                            # å¤„ç†å¹¶æ˜¾ç¤ºç»“æœ
                            account_results = result_processor.organize_results_by_account(all_results)
                            
                            summary_stats = result_processor.create_summary_stats(account_results, df_clean)
                            result_processor.display_summary(summary_stats)
                            
                            result_processor.display_account_results(account_results)
                            
                            # å¯¼å‡ºç»“æœ
                            st.subheader("ğŸ“¥ ç»“æœå¯¼å‡º")
                            exporter.export_to_excel(account_results, "æ™ºèƒ½å½©ç¥¨åˆ†æ")
                    
                    except NameError as e:
                        if "position_bets" in str(e):
                            st.error("âŒ æ‰¾åˆ° position_bets æœªå®šä¹‰é”™è¯¯ï¼")
                            st.error("è¯·æ£€æŸ¥ä»¥ä¸‹æ–¹æ³•ä¸­æ˜¯å¦æ­£ç¡®å®šä¹‰äº† position_betsï¼š")
                            st.error("1. _analyze_pk10_two_sides")
                            st.error("2. _analyze_pk10_independent_plays") 
                            st.error("3. _analyze_pk10_dragon_tiger_comprehensive")
                            st.error("4. _analyze_lhc_zhengma_1_6")
                        import traceback
                        st.error(f"è¯¦ç»†é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                        return
                    except Exception as e:
                        st.error(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                        import traceback
                        st.error(f"è¯¦ç»†é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                        return
                    # ==================== æ·»åŠ  try-except ä»£ç å—ç»“æŸ ====================
                
                else:
                    st.error("âŒ æ•°æ®æ¸…æ´—åæ— æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
        
        except Exception as e:
            st.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
    
    else:
        st.markdown("""
        ## ğŸ“‹ ä½¿ç”¨è¯´æ˜
        
        1. **ä¸Šä¼ æ–‡ä»¶**: åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ Excelæ ¼å¼çš„å½©ç¥¨æŠ•æ³¨æ•°æ®æ–‡ä»¶
        2. **é…ç½®é˜ˆå€¼**: æ ¹æ®éœ€è¦è°ƒæ•´å„ç±»å½©ç¥¨çš„æ£€æµ‹é˜ˆå€¼
        3. **æŸ¥çœ‹ç»“æœ**: ç³»ç»Ÿå°†è‡ªåŠ¨åˆ†æå¹¶æ˜¾ç¤ºå¯ç–‘æŠ•æ³¨è¡Œä¸º
        4. **å¯¼å‡ºç»“æœ**: ä¸‹è½½è¯¦ç»†çš„æ£€æµ‹æŠ¥å‘Š
        
        ### ğŸ¯ ç³»ç»Ÿç‰¹è‰²
        
        **ğŸ” å…¨é¢æ£€æµ‹èƒ½åŠ›**
        - âœ… PKæ‹¾/èµ›è½¦ç³»åˆ—ï¼šè¶…ç ã€å† äºšå’ŒçŸ›ç›¾ã€ä¸¤é¢çŸ›ç›¾ã€é¾™è™çŸ›ç›¾
        - âœ… æ—¶æ—¶å½©ç³»åˆ—ï¼šå®šä½èƒ†å¤šç ã€æ–—ç‰›å¤šç ã€ä¸¤é¢çŸ›ç›¾ã€æ€»å’ŒçŸ›ç›¾  
        - âœ… å…­åˆå½©ç³»åˆ—ï¼šç‰¹ç /æ­£ç å¤šç ã€ç”Ÿè‚–å¤šå·ç ã€å°¾æ•°å¤šç ã€æ³¢è‰²äº”è¡ŒçŸ›ç›¾
        - âœ… å¿«ä¸‰ç³»åˆ—ï¼šå’Œå€¼å¤šç ã€å’Œå€¼çŸ›ç›¾ã€å’Œå€¼å¤§å°çŸ›ç›¾ã€ç‹¬èƒ†å¤šç ã€ä¸åŒå·å…¨åŒ…ã€ä¸¤é¢çŸ›ç›¾
        - âœ… ä¸‰è‰²å½©ç³»åˆ—ï¼šæ­£ç å¤šç ã€ä¸¤é¢çŸ›ç›¾ã€è‰²æ³¢çŸ›ç›¾
        
        **ğŸš€ æŠ€æœ¯ä¼˜åŠ¿**
        - ğŸ“Š å®Œæ•´çš„å°¾æ•°æ£€æµ‹
        - âš¡ ç¼“å­˜ä¼˜åŒ–çš„å·ç æå–ç®—æ³•
        - ğŸ¯ æ™ºèƒ½çš„ç©æ³•åˆ†ç±»æ˜ å°„
        - ğŸ“ˆ è¯¦ç»†çš„æ•°æ®è´¨é‡éªŒè¯
        - ğŸ”„ å®æ—¶è¿›åº¦æ˜¾ç¤ºå’Œæ€§èƒ½ç›‘æ§
        
        **ğŸ’¡ ç”¨æˆ·ä½“éªŒ**
        - ğŸ¨ ç°ä»£åŒ–çš„Streamlitç•Œé¢
        - âš™ï¸ å®æ—¶å¯è°ƒçš„æ£€æµ‹é˜ˆå€¼
        - ğŸ“± å“åº”å¼å¸ƒå±€è®¾è®¡
        - ğŸ“¥ ä¸€é”®å¯¼å‡ºå®Œæ•´æŠ¥å‘Š
        
        ### ğŸ“ æ”¯æŒçš„æ•°æ®æ ¼å¼
        
        ç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«ä»¥ä¸‹åˆ—åå˜ä½“ï¼š
        
        - **ä¼šå‘˜è´¦å·**: ä¼šå‘˜è´¦å·ã€ä¼šå‘˜è´¦æˆ·ã€è´¦å·ã€è´¦æˆ·ã€ç”¨æˆ·è´¦å·ã€ç©å®¶è´¦å·ã€ç”¨æˆ·IDã€ç©å®¶ID
        - **å½©ç§**: å½©ç§ã€å½©ç¥ã€å½©ç¥¨ç§ç±»ã€æ¸¸æˆç±»å‹ã€å½©ç¥¨ç±»å‹ã€æ¸¸æˆå½©ç§ã€å½©ç¥¨åç§°
        - **æœŸå·**: æœŸå·ã€æœŸæ•°ã€æœŸæ¬¡ã€æœŸã€å¥–æœŸã€æœŸå·ä¿¡æ¯ã€æœŸå·ç¼–å·
        - **ç©æ³•**: ç©æ³•ã€ç©æ³•åˆ†ç±»ã€æŠ•æ³¨ç±»å‹ã€ç±»å‹ã€æŠ•æ³¨ç©æ³•ã€ç©æ³•ç±»å‹ã€åˆ†ç±»
        - **å†…å®¹**: å†…å®¹ã€æŠ•æ³¨å†…å®¹ã€ä¸‹æ³¨å†…å®¹ã€æ³¨å•å†…å®¹ã€æŠ•æ³¨å·ç ã€å·ç å†…å®¹ã€æŠ•æ³¨ä¿¡æ¯
        - **é‡‘é¢**: é‡‘é¢ã€ä¸‹æ³¨æ€»é¢ã€æŠ•æ³¨é‡‘é¢ã€æ€»é¢ã€ä¸‹æ³¨é‡‘é¢ã€æŠ•æ³¨é¢ã€é‡‘é¢æ•°å€¼
        
        ### ğŸ² æ”¯æŒçš„å½©ç§
        
        **PKæ‹¾/èµ›è½¦ç³»åˆ—**
        - åˆ†åˆ†PKæ‹¾ã€ä¸‰åˆ†PKæ‹¾ã€äº”åˆ†PKæ‹¾ã€æ–°å¹¸è¿é£è‰‡ã€æ¾³æ´²å¹¸è¿10
        - ä¸€åˆ†PK10ã€å®¾æœPK10ã€æé€Ÿé£è‰‡ã€æ¾³æ´²é£è‰‡ã€å¹¸è¿èµ›è½¦
        - åˆ†åˆ†èµ›è½¦ã€åŒ—äº¬PK10ã€æ—§åŒ—äº¬PK10ã€æé€Ÿèµ›è½¦ã€å¹¸è¿èµ›è»Šã€åŒ—äº¬èµ›è½¦ã€æé€ŸPK10ã€å¹¸è¿PK10ã€èµ›è½¦ã€èµ›è»Š
        
        **æ—¶æ—¶å½©ç³»åˆ—**
        - åˆ†åˆ†æ—¶æ—¶å½©ã€ä¸‰åˆ†æ—¶æ—¶å½©ã€äº”åˆ†æ—¶æ—¶å½©ã€å®¾æœæ—¶æ—¶å½©
        - 1åˆ†æ—¶æ—¶å½©ã€3åˆ†æ—¶æ—¶å½©ã€5åˆ†æ—¶æ—¶å½©ã€æ—§é‡åº†æ—¶æ—¶å½©
        - å¹¸è¿æ—¶æ—¶å½©ã€è…¾è®¯åˆ†åˆ†å½©ã€æ–°ç–†æ—¶æ—¶å½©ã€å¤©æ´¥æ—¶æ—¶å½©ã€é‡åº†æ—¶æ—¶å½©ã€ä¸Šæµ·æ—¶æ—¶å½©ã€å¹¿ä¸œæ—¶æ—¶å½©ã€åˆ†åˆ†å½©ã€æ—¶æ—¶å½©ã€æ™‚æ™‚å½©
        
        **å…­åˆå½©ç³»åˆ—**
        - æ–°æ¾³é—¨å…­åˆå½©ã€æ¾³é—¨å…­åˆå½©ã€é¦™æ¸¯å…­åˆå½©ã€ä¸€åˆ†å…­åˆå½©
        - äº”åˆ†å…­åˆå½©ã€ä¸‰åˆ†å…­åˆå½©ã€é¦™æ¸¯â‘¥åˆå½©ã€åˆ†åˆ†å…­åˆå½©
        - å¿«ä¹6åˆå½©ã€æ¸¯â‘¥åˆå½©ã€å°æ¹¾å¤§ä¹é€ã€å…­åˆã€lhcã€å…­åˆå½©ã€â‘¥åˆã€6åˆ
        
        **å¿«ä¸‰ç³»åˆ—**
        - åˆ†åˆ†å¿«ä¸‰ã€ä¸‰åˆ†å¿«3ã€äº”åˆ†å¿«3ã€æ¾³æ´²å¿«ä¸‰ã€å®¾æœå¿«ä¸‰
        - 1åˆ†å¿«ä¸‰ã€3åˆ†å¿«ä¸‰ã€5åˆ†å¿«ä¸‰ã€10åˆ†å¿«ä¸‰ã€åŠ å·å¿«ä¸‰
        - å¹¸è¿å¿«ä¸‰ã€å¤§å‘å¿«ä¸‰ã€å¿«ä¸‰ã€å¿«3ã€k3ã€kä¸‰

        **3Dç³»åˆ—**
        - æ’åˆ—ä¸‰ã€æ’åˆ—3ã€å¹¸è¿æ’åˆ—3ã€ä¸€åˆ†æ’åˆ—3ã€äºŒåˆ†æ’åˆ—3ã€ä¸‰åˆ†æ’åˆ—3
        - äº”åˆ†æ’åˆ—3ã€ååˆ†æ’åˆ—3ã€å¤§å‘æ’åˆ—3ã€å¥½è¿æ’åˆ—3ã€ç¦å½©3Dã€æé€Ÿ3D
        - æé€Ÿæ’åˆ—3ã€å¹¸è¿3Dã€ä¸€åˆ†3Dã€äºŒåˆ†3Dã€ä¸‰åˆ†3Dã€äº”åˆ†3Dã€ååˆ†3Dã€å¤§å‘3Dã€å¥½è¿3D
        
        **ä¸‰è‰²å½©ç³»åˆ—**
        - ä¸€åˆ†ä¸‰è‰²å½©ã€30ç§’ä¸‰è‰²å½©ã€äº”åˆ†ä¸‰è‰²å½©ã€ä¸‰åˆ†ä¸‰è‰²å½©ã€ä¸‰è‰²ã€ä¸‰è‰²å½©ã€ä¸‰è‰²çƒ
        
        ---
        
        **æ³¨æ„**: è¯·ç¡®ä¿ä¸Šä¼ çš„Excelæ–‡ä»¶åŒ…å«å¿…è¦çš„åˆ—ä¿¡æ¯ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«å¸¸è§çš„åˆ—åå˜ä½“ã€‚
        
        """)

# ç¡®ä¿ä¸»å‡½æ•°è¢«è°ƒç”¨
if __name__ == "__main__":
    main()
