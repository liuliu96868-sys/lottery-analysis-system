import streamlit as st
import pandas as pd
import numpy as np
import re
import logging
from collections import Counter, defaultdict
from functools import lru_cache
import hashlib
import io
import warnings
import time
warnings.filterwarnings('ignore')

# è®¾ç½®é¡µé¢
st.set_page_config(
    page_title="æ™ºèƒ½å½©ç¥¨åˆ†ææ£€æµ‹ç³»ç»Ÿ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== åŸºç¡€åˆ†æå™¨æ¶æ„ ====================
from abc import ABC, abstractmethod
from collections import defaultdict
import pandas as pd
import streamlit as st

class BaseAnalyzer(ABC):
    """åŸºç¡€åˆ†æå™¨æŠ½è±¡ç±»"""
    
    def __init__(self):
        self.content_parser = ContentParser()
        self.normalizer = PlayCategoryNormalizer()
        self.seen_records = set()
    
    @abstractmethod
    def analyze(self, df):
        """åˆ†æå…¥å£æ–¹æ³• - å­ç±»å¿…é¡»å®ç°"""
        pass
    
    @abstractmethod
    def get_supported_lottery_types(self):
        """è¿”å›æ”¯æŒçš„å½©ç§ç±»å‹"""
        pass
    
    def _get_record_hash(self, record):
        """ç”Ÿæˆè®°å½•çš„å”¯ä¸€å“ˆå¸Œå€¼"""
        key_parts = [
            record['ä¼šå‘˜è´¦å·'],
            record['å½©ç§'], 
            record['æœŸå·'],
            record.get('ç©æ³•åˆ†ç±»', ''),
            record.get('è¿è§„ç±»å‹', ''),
            record.get('ä½ç½®', ''),
            str(record.get('å·ç æ•°é‡', 0)),
            record.get('çŸ›ç›¾ç±»å‹', '')
        ]
        return hashlib.md5('|'.join(key_parts).encode()).hexdigest()
    
    def _add_unique_result(self, results, result_type, record):
        """æ·»åŠ å”¯ä¸€çš„ç»“æœè®°å½•"""
        record_hash = self._get_record_hash(record)
        
        if record_hash not in self.seen_records:
            self.seen_records.add(record_hash)
            results[result_type].append(record)
            return True
        return False
    
    def _calculate_sort_weight(self, record, result_type):
        """è®¡ç®—æ’åºæƒé‡"""
        weight = 0
        
        # åŸºäºå·ç æ•°é‡
        if record.get('å·ç æ•°é‡', 0) > 0:
            weight += record['å·ç æ•°é‡'] * 10
        
        # åŸºäºçŸ›ç›¾ç±»å‹å¤æ‚åº¦
        if record.get('çŸ›ç›¾ç±»å‹'):
            conflict_count = len(record['çŸ›ç›¾ç±»å‹'].split('ã€'))
            weight += conflict_count * 15
        
        # åŸºäºå…¶ä»–æ•°é‡å­—æ®µ
        for field in ['ç”Ÿè‚–æ•°é‡', 'å°¾æ•°æ•°é‡', 'æŠ•æ³¨åŒºé—´æ•°', 'æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨äº”è¡Œæ•°']:
            if record.get(field, 0) > 0:
                weight += record[field] * 8
        
        # åŸºäºçŸ›ç›¾å€¼
        if record.get('çŸ›ç›¾å€¼', 0) > 0:
            weight += record['çŸ›ç›¾å€¼'] * 5
        
        # åŸºäºæ£€æµ‹ç±»å‹é‡è¦æ€§
        if 'å¤šå·ç ' in result_type:
            weight += 25
        elif 'çŸ›ç›¾' in result_type:
            weight += 20
        elif 'å…¨åŒ…' in result_type:
            weight += 30
        elif 'ä¸‰ç»„' in result_type:
            weight += 35
        
        return weight

class PrecisionThresholdManager:
    """ç²¾ç¡®é˜ˆå€¼ç®¡ç†å™¨"""
    
    def get_threshold(self, lottery_type, play_category, detection_type):
        """è·å–ç²¾ç¡®é˜ˆå€¼"""
        base_config = THRESHOLD_CONFIG.get(lottery_type, {})
        
        # ç©æ³•ç‰¹å®šçš„é˜ˆå€¼é…ç½®
        play_specific_config = {
            'LHC': {
                'ç‰¹ç ': {'multi_number': 31},
                'æ­£ç ': {'multi_number': 25},
                'æ­£1ç‰¹': {'multi_number': 20},
                'æ­£2ç‰¹': {'multi_number': 20},
                'æ­£3ç‰¹': {'multi_number': 20},
                'æ­£4ç‰¹': {'multi_number': 20},
                'æ­£5ç‰¹': {'multi_number': 20},
                'æ­£6ç‰¹': {'multi_number': 20},
                'å°¾æ•°': {'multi_tail': 7},
                'ç‰¹å°¾': {'multi_tail': 5},
                'å…¨å°¾': {'multi_tail': 5},
                'å¹³ç‰¹': {'zodiac_play': 7},
                'ç‰¹è‚–': {'zodiac_play': 7},
                'ä¸€è‚–': {'zodiac_play': 7}
            },
            'K3': {
                'å’Œå€¼': {'hezhi_multi_number': 11},
                'ç‹¬èƒ†': {'dudan_multi_number': 5}
            },
            'PK10': {
                'å† å†›': {'multi_number': 8},
                'äºšå†›': {'multi_number': 8},
                'ç¬¬ä¸‰å': {'multi_number': 8},
                'å† äºšå’Œ': {'gyh_multi_number': 12}
            }
        }
        
        # ä¼˜å…ˆä½¿ç”¨ç©æ³•ç‰¹å®šé…ç½®
        play_config = play_specific_config.get(lottery_type, {}).get(play_category, {})
        if detection_type in play_config:
            return play_config[detection_type]
        
        # å›é€€åˆ°åŸºç¡€é…ç½®
        return base_config.get(detection_type, 5)  # é»˜è®¤é˜ˆå€¼

# ==================== é…ç½®å¸¸é‡ ====================
LOTTERY_CONFIGS = {
    'PK10': {
        'lotteries': [
            'åˆ†åˆ†PKæ‹¾', 'ä¸‰åˆ†PKæ‹¾', 'äº”åˆ†PKæ‹¾', 'æ–°å¹¸è¿é£è‰‡', 'æ¾³æ´²å¹¸è¿10',
            'ä¸€åˆ†PK10', 'å®¾æœPK10', 'æé€Ÿé£è‰‡', 'æ¾³æ´²é£è‰‡', 'å¹¸è¿èµ›è½¦',
            'åˆ†åˆ†èµ›è½¦', 'åŒ—äº¬PK10', 'æ—§åŒ—äº¬PK10', 'æé€Ÿèµ›è½¦', 'å¹¸è¿èµ›è»Š', 
            'åŒ—äº¬èµ›è½¦', 'æé€ŸPK10', 'å¹¸è¿PK10', 'èµ›è½¦', 'èµ›è»Š'
        ],
        'min_number': 1,
        'max_number': 10,
        'gyh_min': 3,
        'gyh_max': 19,
        'position_names': ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                          'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
    },
    'K3': {
        'lotteries': [
            'åˆ†åˆ†å¿«ä¸‰', 'ä¸‰åˆ†å¿«3', 'äº”åˆ†å¿«3', 'æ¾³æ´²å¿«ä¸‰', 'å®¾æœå¿«ä¸‰',
            '1åˆ†å¿«ä¸‰', '3åˆ†å¿«ä¸‰', '5åˆ†å¿«ä¸‰', '10åˆ†å¿«ä¸‰', 'åŠ å·å¿«ä¸‰',
            'å¹¸è¿å¿«ä¸‰', 'å¤§å‘å¿«ä¸‰', 'å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰', 
            'æ¾³é—¨å¿«ä¸‰', 'é¦™æ¸¯å¿«ä¸‰', 'æ±Ÿè‹å¿«ä¸‰'
        ],
        'min_number': 1,
        'max_number': 6,
        'hezhi_min': 3,
        'hezhi_max': 18
    },
    'LHC': {
        'lotteries': [
            'æ–°æ¾³é—¨å…­åˆå½©', 'æ¾³é—¨å…­åˆå½©', 'é¦™æ¸¯å…­åˆå½©', 'ä¸€åˆ†å…­åˆå½©',
            'äº”åˆ†å…­åˆå½©', 'ä¸‰åˆ†å…­åˆå½©', 'é¦™æ¸¯â‘¥åˆå½©', 'åˆ†åˆ†å…­åˆå½©',
            'å¿«ä¹6åˆå½©', 'æ¸¯â‘¥åˆå½©', 'å°æ¹¾å¤§ä¹é€', 'å…­åˆ', 'lhc', 'å…­åˆå½©',
            'â‘¥åˆ', '6åˆ', 'å¤§å‘å…­åˆå½©'
        ],
        'min_number': 1,
        'max_number': 49
    },
    '3D': {
        'lotteries': [
            'æ’åˆ—ä¸‰', 'æ’åˆ—3', 'å¹¸è¿æ’åˆ—3', 'ä¸€åˆ†æ’åˆ—3', 'äºŒåˆ†æ’åˆ—3', 'ä¸‰åˆ†æ’åˆ—3', 
            'äº”åˆ†æ’åˆ—3', 'ååˆ†æ’åˆ—3', 'å¤§å‘æ’åˆ—3', 'å¥½è¿æ’åˆ—3', 'ç¦å½©3D', 'æé€Ÿ3D',
            'æé€Ÿæ’åˆ—3', 'å¹¸è¿3D', 'ä¸€åˆ†3D', 'äºŒåˆ†3D', 'ä¸‰åˆ†3D', 'äº”åˆ†3D', 
            'ååˆ†3D', 'å¤§å‘3D', 'å¥½è¿3D'
        ],
        'min_number': 0,
        'max_number': 9,
        'dingwei_threshold': 7  # å®šä½èƒ†å¤šç é˜ˆå€¼
    },
    'SSC': {
        'lotteries': [
            'åˆ†åˆ†æ—¶æ—¶å½©', 'ä¸‰åˆ†æ—¶æ—¶å½©', 'äº”åˆ†æ—¶æ—¶å½©', 'å®¾æœæ—¶æ—¶å½©',
            '1åˆ†æ—¶æ—¶å½©', '3åˆ†æ—¶æ—¶å½©', '5åˆ†æ—¶æ—¶å½©', 'æ—§é‡åº†æ—¶æ—¶å½©',
            'å¹¸è¿æ—¶æ—¶å½©', 'è…¾è®¯åˆ†åˆ†å½©', 'æ–°ç–†æ—¶æ—¶å½©', 'å¤©æ´¥æ—¶æ—¶å½©',
            'é‡åº†æ—¶æ—¶å½©', 'ä¸Šæµ·æ—¶æ—¶å½©', 'å¹¿ä¸œæ—¶æ—¶å½©', 'åˆ†åˆ†å½©', 'æ—¶æ—¶å½©', 'æ™‚æ™‚å½©'
        ],
        'min_number': 0,
        'max_number': 9
    },
    'THREE_COLOR': {
        'lotteries': [
            'ä¸€åˆ†ä¸‰è‰²å½©', '30ç§’ä¸‰è‰²å½©', 'äº”åˆ†ä¸‰è‰²å½©', 'ä¸‰åˆ†ä¸‰è‰²å½©',
            'ä¸‰è‰²', 'ä¸‰è‰²å½©', 'ä¸‰è‰²çƒ'
        ],
        'min_number': 0,
        'max_number': 9
    }
}

THRESHOLD_CONFIG = {
    'PK10': {
        'multi_number': 8,
        'gyh_multi_number': 12,
        'position_multi': 8,
        'all_positions_bet': 10
    },
    'K3': {
        'multi_number': 5,
        'hezhi_multi_number': 13,
        'value_size_contradiction': 5,
        'dudan_multi_number': 5
    },
    'LHC': {
        'number_play': 31,
        'zodiac_play': 7,
        'tail_play': 7,
        'range_bet': 4,
        'lianxiao_threshold': 7,
        'lianwei_threshold': 7,
        'wave_bet': 3,
        'five_elements': 4
    },
    '3D': {
        'dingwei_multi': 7,  # å®šä½èƒ†å¤šç é˜ˆå€¼
        'two_sides_conflict': 2  # ä¸¤é¢çŸ›ç›¾æ£€æµ‹
    },
    'SSC': {
        'dingwei_multi': 8,
        'douniu_multi': 8,
        'two_sides_conflict': 2
    },
    'THREE_COLOR': {
        'zhengma_multi': 7,
        'two_sides_conflict': 2,
        'wave_conflict': 2
    }
}

# ==================== æ–°å¢ï¼šç²¾ç¡®é˜ˆå€¼ç®¡ç†å™¨ ====================
class PrecisionThresholdManager:
    """ç²¾ç¡®é˜ˆå€¼ç®¡ç†å™¨"""
    
    def get_threshold(self, lottery_type, play_category, detection_type):
        """è·å–ç²¾ç¡®é˜ˆå€¼"""
        base_config = THRESHOLD_CONFIG.get(lottery_type, {})
        
        # ç©æ³•ç‰¹å®šçš„é˜ˆå€¼é…ç½®
        play_specific_config = {
            'LHC': {
                'ç‰¹ç ': {'multi_number': 31},
                'æ­£ç ': {'multi_number': 25},
                'æ­£1ç‰¹': {'multi_number': 20},
                'æ­£2ç‰¹': {'multi_number': 20},
                'æ­£3ç‰¹': {'multi_number': 20},
                'æ­£4ç‰¹': {'multi_number': 20},
                'æ­£5ç‰¹': {'multi_number': 20},
                'æ­£6ç‰¹': {'multi_number': 20},
                'å°¾æ•°': {'multi_tail': 7},
                'ç‰¹å°¾': {'multi_tail': 5},
                'å…¨å°¾': {'multi_tail': 5},
                'å¹³ç‰¹': {'zodiac_play': 7},
                'ç‰¹è‚–': {'zodiac_play': 7},
                'ä¸€è‚–': {'zodiac_play': 7}
            },
            'K3': {
                'å’Œå€¼': {'hezhi_multi_number': 11},
                'ç‹¬èƒ†': {'dudan_multi_number': 5}
            },
            'PK10': {
                'å† å†›': {'multi_number': 8},
                'äºšå†›': {'multi_number': 8},
                'ç¬¬ä¸‰å': {'multi_number': 8},
                'å† äºšå’Œ': {'gyh_multi_number': 12}
            }
        }
        
        # ä¼˜å…ˆä½¿ç”¨ç©æ³•ç‰¹å®šé…ç½®
        play_config = play_specific_config.get(lottery_type, {}).get(play_category, {})
        if detection_type in play_config:
            return play_config[detection_type]
        
        # å›é€€åˆ°åŸºç¡€é…ç½®
        return base_config.get(detection_type, 5)  # é»˜è®¤é˜ˆå€¼

# ==================== æ—¥å¿—è®¾ç½® ====================
def setup_logging():
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    logger = logging.getLogger('LotteryAnalysis')
    logger.setLevel(logging.INFO)
    
    if not logger.handlers:
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # æ ¼å¼å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        console_handler.setFormatter(formatter)
        
        logger.addHandler(console_handler)
    
    return logger

logger = setup_logging()

# ==================== æ•°æ®å¤„ç†ç±» ====================
class DataProcessor:
    def __init__(self):
        self.required_columns = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'ç©æ³•', 'å†…å®¹', 'é‡‘é¢']
        self.column_mapping = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·', 'ç©å®¶è´¦å·', 'ç”¨æˆ·ID', 'ç©å®¶ID'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹', 'å½©ç¥¨ç±»å‹', 'æ¸¸æˆå½©ç§', 'å½©ç¥¨åç§°'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ', 'å¥–æœŸ', 'æœŸå·ä¿¡æ¯', 'æœŸå·ç¼–å·'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹', 'æŠ•æ³¨ç©æ³•', 'ç©æ³•ç±»å‹', 'åˆ†ç±»'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹', 'æŠ•æ³¨å·ç ', 'å·ç å†…å®¹', 'æŠ•æ³¨ä¿¡æ¯'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é‡‘é¢æ•°å€¼']
        }
    
    def smart_column_identification(self, df_columns):
        """æ™ºèƒ½åˆ—è¯†åˆ«"""
        identified_columns = {}
        actual_columns = [str(col).strip() for col in df_columns]
        
        with st.expander("ğŸ” åˆ—åè¯†åˆ«è¯¦æƒ…", expanded=False):
            st.info(f"æ£€æµ‹åˆ°çš„åˆ—å: {actual_columns}")
            
            for standard_col, possible_names in self.column_mapping.items():
                found = False
                for actual_col in actual_columns:
                    actual_col_lower = actual_col.lower().replace(' ', '').replace('_', '').replace('-', '')
                    
                    for possible_name in possible_names:
                        possible_name_lower = possible_name.lower().replace(' ', '').replace('_', '').replace('-', '')
                        
                        # å¢å¼ºä¼šå‘˜è´¦å·è¯†åˆ«
                        if standard_col == 'ä¼šå‘˜è´¦å·':
                            # æ›´å®½æ¾çš„åŒ¹é…è§„åˆ™
                            account_keywords = ['ä¼šå‘˜', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·', 'ç©å®¶', 'id']
                            if any(keyword in actual_col_lower for keyword in account_keywords):
                                identified_columns[actual_col] = standard_col
                                st.success(f"âœ… è¯†åˆ«åˆ—å: {actual_col} -> {standard_col}")
                                found = True
                                break
                        else:
                            # å…¶ä»–åˆ—çš„åŸæœ‰åŒ¹é…é€»è¾‘
                            if (possible_name_lower in actual_col_lower or 
                                actual_col_lower in possible_name_lower or
                                len(set(possible_name_lower) & set(actual_col_lower)) / len(possible_name_lower) > 0.7):
                                identified_columns[actual_col] = standard_col
                                st.success(f"âœ… è¯†åˆ«åˆ—å: {actual_col} -> {standard_col}")
                                found = True
                                break
                    
                    if found:
                        break
                
                if not found:
                    st.warning(f"âš ï¸ æœªè¯†åˆ«åˆ° {standard_col} å¯¹åº”çš„åˆ—å")
        
        return identified_columns
    
    def find_data_start(self, df):
        """æ™ºèƒ½æ‰¾åˆ°æ•°æ®èµ·å§‹ä½ç½®"""
        for row_idx in range(min(20, len(df))):
            for col_idx in range(min(10, len(df.columns))):
                cell_value = str(df.iloc[row_idx, col_idx])
                if pd.notna(cell_value) and any(keyword in cell_value for keyword in ['ä¼šå‘˜', 'è´¦å·', 'æœŸå·', 'å½©ç§', 'ç©æ³•', 'å†…å®¹', 'è®¢å•', 'ç”¨æˆ·']):
                    return row_idx, col_idx
        return 0, 0
    
    def validate_data_quality(self, df):
        """æ•°æ®è´¨é‡éªŒè¯"""
        logger.info("æ­£åœ¨è¿›è¡Œæ•°æ®è´¨é‡éªŒè¯...")
        issues = []
        
        # æ£€æŸ¥å¿…è¦åˆ—
        missing_cols = [col for col in self.required_columns if col not in df.columns]
        if missing_cols:
            issues.append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        
        # æ£€æŸ¥ç©ºå€¼
        for col in self.required_columns:
            if col in df.columns:
                null_count = df[col].isnull().sum()
                if null_count > 0:
                    issues.append(f"åˆ— '{col}' æœ‰ {null_count} ä¸ªç©ºå€¼")
        
        # ç‰¹åˆ«æ£€æŸ¥ä¼šå‘˜è´¦å·çš„å®Œæ•´æ€§
        if 'ä¼šå‘˜è´¦å·' in df.columns:
            # æ£€æŸ¥æ˜¯å¦æœ‰è¢«æˆªæ–­çš„è´¦å·
            truncated_accounts = df[df['ä¼šå‘˜è´¦å·'].str.contains(r'\.\.\.|â€¦', na=False)]
            if len(truncated_accounts) > 0:
                issues.append(f"å‘ç° {len(truncated_accounts)} ä¸ªå¯èƒ½è¢«æˆªæ–­çš„ä¼šå‘˜è´¦å·")
            
            # æ£€æŸ¥è´¦å·é•¿åº¦å¼‚å¸¸çš„æƒ…å†µ
            account_lengths = df['ä¼šå‘˜è´¦å·'].str.len()
            if account_lengths.max() > 50:  # å‡è®¾æ­£å¸¸è´¦å·é•¿åº¦ä¸è¶…è¿‡50ä¸ªå­—ç¬¦
                issues.append("å‘ç°å¼‚å¸¸é•¿åº¦çš„ä¼šå‘˜è´¦å·")
            
            # æ˜¾ç¤ºè´¦å·æ ¼å¼æ ·æœ¬
            unique_accounts = df['ä¼šå‘˜è´¦å·'].unique()[:5]
            sample_info = " | ".join([f"'{acc}'" for acc in unique_accounts])
            st.info(f"ä¼šå‘˜è´¦å·æ ¼å¼æ ·æœ¬: {sample_info}")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        if 'æœŸå·' in df.columns:
            # ä¿®å¤æœŸå·æ ¼å¼é—®é¢˜ï¼šå»æ‰.0
            df['æœŸå·'] = df['æœŸå·'].astype(str).str.replace(r'\.0$', '', regex=True)
            # å…è®¸æœŸå·åŒ…å«å­—æ¯å’Œæ•°å­—
            invalid_periods = df[~df['æœŸå·'].str.match(r'^[\dA-Za-z]+$')]
            if len(invalid_periods) > 0:
                issues.append(f"å‘ç° {len(invalid_periods)} æ¡æ— æ•ˆæœŸå·è®°å½•")
        
        # æ£€æŸ¥é‡å¤æ•°æ®
        duplicate_count = df.duplicated().sum()
        if duplicate_count > 0:
            issues.append(f"å‘ç° {duplicate_count} æ¡é‡å¤è®°å½•")
        
        if issues:
            with st.expander("âš ï¸ æ•°æ®è´¨é‡é—®é¢˜", expanded=True):
                for issue in issues:
                    st.warning(f"  - {issue}")
        else:
            st.success("âœ… æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡")
        
        return issues
    
    def clean_data(self, uploaded_file):
        """æ•°æ®æ¸…æ´—ä¸»å‡½æ•°"""
        try:
            # ç¬¬ä¸€æ¬¡è¯»å–ç”¨äºå®šä½
            df_temp = pd.read_excel(uploaded_file, header=None, nrows=50)
            st.info(f"åŸå§‹æ•°æ®ç»´åº¦: {df_temp.shape}")
            
            # æ‰¾åˆ°æ•°æ®èµ·å§‹ä½ç½®
            start_row, start_col = self.find_data_start(df_temp)
            st.info(f"æ•°æ®èµ·å§‹ä½ç½®: ç¬¬{start_row+1}è¡Œ, ç¬¬{start_col+1}åˆ—")
            
            # é‡æ–°è¯»å–æ•°æ® - ç‰¹åˆ«å¤„ç†å¸¸è§„æ ¼å¼å•å…ƒæ ¼
            df_clean = pd.read_excel(
                uploaded_file, 
                header=start_row,
                skiprows=range(start_row + 1) if start_row > 0 else None,
                dtype=str,  # å°†æ‰€æœ‰åˆ—è¯»å–ä¸ºå­—ç¬¦ä¸²
                na_filter=False,  # ä¸è¿‡æ»¤ç©ºå€¼
                keep_default_na=False,  # ä¸ä½¿ç”¨é»˜è®¤çš„NAå€¼å¤„ç†
                converters={}  # ä¸ºç©ºï¼Œè®©pandasä¸è¦è¿›è¡Œä»»ä½•è½¬æ¢
            )
            
            # åˆ é™¤èµ·å§‹åˆ—ä¹‹å‰çš„æ‰€æœ‰åˆ—
            if start_col > 0:
                df_clean = df_clean.iloc[:, start_col:]
            
            st.info(f"æ¸…ç†åæ•°æ®ç»´åº¦: {df_clean.shape}")
            
            # æ™ºèƒ½åˆ—è¯†åˆ«
            column_mapping = self.smart_column_identification(df_clean.columns)
            if column_mapping:
                df_clean = df_clean.rename(columns=column_mapping)
                st.success("âœ… åˆ—åè¯†åˆ«å®Œæˆ!")
                for old_col, new_col in column_mapping.items():
                    logger.info(f"  {old_col} -> {new_col}")
            
            # ç¡®ä¿å¿…è¦åˆ—å­˜åœ¨
            missing_columns = [col for col in self.required_columns if col not in df_clean.columns]
            if missing_columns and len(df_clean.columns) >= 4:
                st.warning("è‡ªåŠ¨æ˜ å°„åˆ—å...")
                manual_mapping = {}
                col_names = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'å†…å®¹', 'ç©æ³•', 'é‡‘é¢']
                for i, col_name in enumerate(col_names):
                    if i < len(df_clean.columns):
                        manual_mapping[df_clean.columns[i]] = col_name
                
                df_clean = df_clean.rename(columns=manual_mapping)
                st.info(f"æ‰‹åŠ¨é‡å‘½ååçš„åˆ—: {list(df_clean.columns)}")
            
            # æ•°æ®æ¸…ç†
            initial_count = len(df_clean)
            df_clean = df_clean.dropna(subset=[col for col in self.required_columns if col in df_clean.columns])
            df_clean = df_clean.dropna(axis=1, how='all')
            
            # æ•°æ®ç±»å‹è½¬æ¢ - ç‰¹åˆ«å°å¿ƒå¤„ç†ä¼šå‘˜è´¦å·
            for col in self.required_columns:
                if col in df_clean.columns:
                    if col == 'ä¼šå‘˜è´¦å·':
                        # ç‰¹åˆ«å¤„ç†ä¼šå‘˜è´¦å·ï¼šç¡®ä¿ä¸ä¸¢å¤±ä»»ä½•å­—ç¬¦
                        df_clean[col] = df_clean[col].apply(
                            lambda x: str(x) if pd.notna(x) else ''
                        )
                    else:
                        df_clean[col] = df_clean[col].astype(str).str.strip()
            
            # ä¿®å¤æœŸå·æ ¼å¼ï¼šå»æ‰.0
            if 'æœŸå·' in df_clean.columns:
                df_clean['æœŸå·'] = df_clean['æœŸå·'].str.replace(r'\.0$', '', regex=True)
            
            # æ•°æ®è´¨é‡éªŒè¯ - æ·»åŠ ä¼šå‘˜è´¦å·å®Œæ•´æ€§æ£€æŸ¥
            self.validate_data_quality(df_clean)
            
            st.success(f"âœ… æ•°æ®æ¸…æ´—å®Œæˆ: {initial_count} -> {len(df_clean)} æ¡è®°å½•")
            
            # åœ¨ clean_data æ–¹æ³•ä¸­ï¼Œä¿®æ”¹æ˜¾ç¤ºä¼šå‘˜è´¦å·æ ·æœ¬çš„éƒ¨åˆ†ï¼š
                
            st.info(f"ğŸ“Š å”¯ä¸€ä¼šå‘˜è´¦å·æ•°: {df_clean['ä¼šå‘˜è´¦å·'].nunique()}")
            
            # å½©ç§åˆ†å¸ƒæ˜¾ç¤º
            lottery_dist = df_clean['å½©ç§'].value_counts()
            with st.expander("ğŸ¯ å½©ç§åˆ†å¸ƒ", expanded=False):
                st.dataframe(lottery_dist.reset_index().rename(columns={'index': 'å½©ç§', 'å½©ç§': 'æ•°é‡'}))
            
            return df_clean
            
        except Exception as e:
            st.error(f"âŒ æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            logger.error(f"æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            return None

# ==================== å†…å®¹è§£æå™¨ ====================
class ContentParser:
    """ç»Ÿä¸€çš„æŠ•æ³¨å†…å®¹è§£æå™¨"""

    @staticmethod
    def parse_pk10_vertical_format(content):
        """
        è§£æPK10ç«–çº¿åˆ†éš”çš„å®šä½èƒ†æ ¼å¼
        æ ¼å¼ï¼šå·ç 1,å·ç 2|å·ç 3|å·ç 4,å·ç 5|å·ç 6|å·ç 7,å·ç 8,å·ç 9|å·ç 10
        æˆ–è€…ï¼š_|05|_|_|_ è¡¨ç¤ºåªæœ‰ç¬¬äºŒä¸ªä½ç½®æœ‰æŠ•æ³¨
        """
        content_str = str(content).strip()
        bets_by_position = defaultdict(list)
        
        if not content_str:
            return bets_by_position
        
        # å®šä¹‰ä½ç½®æ˜ å°„
        positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                    'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
        
        # æŒ‰ç«–çº¿åˆ†å‰²
        parts = content_str.split('|')
        
        for i, part in enumerate(parts):
            if i < len(positions):
                position = positions[i]
                part_clean = part.strip()
                
                # è·³è¿‡ç©ºä½æˆ–ä¸‹åˆ’çº¿
                if not part_clean or part_clean == '_' or part_clean == '':
                    continue
                
                # æå–æ•°å­—ï¼ˆå¯èƒ½æ˜¯å•ä¸ªæ•°å­—æˆ–å¤šä¸ªé€—å·åˆ†éš”çš„æ•°å­—ï¼‰
                numbers = []
                if ',' in part_clean:
                    # é€—å·åˆ†éš”çš„å¤šä¸ªæ•°å­—
                    number_strs = part_clean.split(',')
                    for num_str in number_strs:
                        num_clean = num_str.strip()
                        if num_clean.isdigit():
                            numbers.append(int(num_clean))
                else:
                    # å•ä¸ªæ•°å­—
                    if part_clean.isdigit():
                        numbers.append(int(part_clean))
                
                # æ·»åŠ åˆ°å¯¹åº”ä½ç½®
                bets_by_position[position].extend(numbers)
        
        return bets_by_position

    @staticmethod
    def parse_ssc_vertical_format(content):
        """
        è§£ææ—¶æ—¶å½©ç«–çº¿åˆ†éš”çš„å®šä½èƒ†æ ¼å¼
        æ ¼å¼ï¼šå·ç 1,å·ç 2|å·ç 3|å·ç 4,å·ç 5|å·ç 6|å·ç 7,å·ç 8,å·ç 9|å·ç 10
        æˆ–è€…ï¼š_|05|_|_|_ è¡¨ç¤ºåªæœ‰ç¬¬äºŒä¸ªä½ç½®æœ‰æŠ•æ³¨
        """
        content_str = str(content).strip()
        bets_by_position = defaultdict(list)
        
        if not content_str:
            return bets_by_position
        
        # å®šä¹‰ä½ç½®æ˜ å°„
        positions = ['ç¬¬1çƒ', 'ç¬¬2çƒ', 'ç¬¬3çƒ', 'ç¬¬4çƒ', 'ç¬¬5çƒ']
        
        # æŒ‰ç«–çº¿åˆ†å‰²
        parts = content_str.split('|')
        
        for i, part in enumerate(parts):
            if i < len(positions):
                position = positions[i]
                part_clean = part.strip()
                
                # è·³è¿‡ç©ºä½æˆ–ä¸‹åˆ’çº¿
                if not part_clean or part_clean == '_' or part_clean == '':
                    continue
                
                # æå–æ•°å­—ï¼ˆå¯èƒ½æ˜¯å•ä¸ªæ•°å­—æˆ–å¤šä¸ªé€—å·åˆ†éš”çš„æ•°å­—ï¼‰
                numbers = []
                if ',' in part_clean:
                    # é€—å·åˆ†éš”çš„å¤šä¸ªæ•°å­—
                    number_strs = part_clean.split(',')
                    for num_str in number_strs:
                        num_clean = num_str.strip()
                        if num_clean.isdigit():
                            numbers.append(int(num_clean))
                else:
                    # å•ä¸ªæ•°å­—
                    if part_clean.isdigit():
                        numbers.append(int(part_clean))
                
                # æ·»åŠ åˆ°å¯¹åº”ä½ç½®
                bets_by_position[position].extend(numbers)
        
        return bets_by_position
    
    @staticmethod
    def parse_positional_bets(content, position_keywords=None):
        """
        è§£æä½ç½®æŠ•æ³¨å†…å®¹
        æ ¼å¼ï¼šä½ç½®1-æŠ•æ³¨é¡¹1,æŠ•æ³¨é¡¹2,ä½ç½®2-æŠ•æ³¨é¡¹1,æŠ•æ³¨é¡¹2,...
        """
        content_str = str(content).strip()
        bets_by_position = defaultdict(list)
        
        if not content_str:
            return bets_by_position
        
        # æŒ‰é€—å·åˆ†å‰²æ‰€æœ‰éƒ¨åˆ†
        parts = [part.strip() for part in content_str.split(',')]
        
        current_position = None
        
        for part in parts:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä½ç½®å…³é”®è¯
            is_position = False
            if position_keywords:
                for keyword in position_keywords:
                    if keyword in part and '-' in part:
                        is_position = True
                        break
            
            # å¦‚æœåŒ…å«ä½ç½®ä¿¡æ¯æˆ–è€…æ˜¯æ˜ç¡®çš„"ä½ç½®-å†…å®¹"æ ¼å¼
            if '-' in part and (is_position or position_keywords is None):
                try:
                    position_part, bet_value = part.split('-', 1)
                    current_position = position_part.strip()
                    bets_by_position[current_position].append(bet_value.strip())
                except ValueError:
                    # åˆ†å‰²å¤±è´¥ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„ä½ç½®æ ¼å¼
                    if current_position:
                        bets_by_position[current_position].append(part)
            elif current_position:
                # å±äºå½“å‰ä½ç½®çš„æŠ•æ³¨é¡¹
                bets_by_position[current_position].append(part)
            else:
                # æ²¡æœ‰å½“å‰ä½ç½®ï¼Œå¯èƒ½æ˜¯ç‹¬ç«‹çš„æŠ•æ³¨é¡¹
                bets_by_position['æœªçŸ¥ä½ç½®'].append(part)
        
        return bets_by_position
    
    @staticmethod
    def parse_pk10_content(content):
        """è§£æPK10æŠ•æ³¨å†…å®¹ - å¢å¼ºç‰ˆï¼Œæ”¯æŒç«–çº¿æ ¼å¼"""
        pk10_positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                         'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå',
                         'ç¬¬1å', 'ç¬¬2å', 'ç¬¬3å', 'ç¬¬4å', 'ç¬¬5å',
                         'ç¬¬6å', 'ç¬¬7å', 'ç¬¬8å', 'ç¬¬9å', 'ç¬¬10å',
                         'å‰ä¸€', 'å‰äºŒ', 'å‰ä¸‰']
        
        content_str = str(content).strip()
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ç«–çº¿åˆ†éš”æ ¼å¼
        if '|' in content_str and any(char.isdigit() or char == '_' or char == ',' for char in content_str):
            vertical_result = ContentParser.parse_pk10_vertical_format(content_str)
            if any(vertical_result.values()):  # å¦‚æœæœ‰è§£æç»“æœ
                return vertical_result
        
        # ç‰¹æ®Šå¤„ç†"ä½ç½®:å·ç "æ ¼å¼
        if ':' in content_str and re.search(r'\d{2}', content_str):
            match = re.match(r'^(.+?):([\d,]+)$', content_str)
            if match:
                position = match.group(1).strip()
                numbers_str = match.group(2)
                bets_by_position = defaultdict(list)
                
                normalized_position = position
                if 'ä¹' in position or '9' in position:
                    normalized_position = 'ç¬¬ä¹å'
                
                numbers = re.findall(r'\d{2}', numbers_str)
                bets_by_position[normalized_position].extend([int(num) for num in numbers])
                return bets_by_position
        
        # åŸæœ‰çš„è§£æé€»è¾‘
        return ContentParser.parse_positional_bets(content, pk10_positions)
    
    @staticmethod
    def parse_lhc_zhengma_content(content):
        """
        è§£æå…­åˆå½©æ­£ç æŠ•æ³¨å†…å®¹ - å¢å¼ºç‰ˆæœ¬
        æ ¼å¼ï¼šä½ç½®1-æŠ•æ³¨é¡¹1,æŠ•æ³¨é¡¹2,ä½ç½®2-æŠ•æ³¨é¡¹1,æŠ•æ³¨é¡¹2,...
        """
        content_str = str(content).strip()
        bets_by_position = defaultdict(list)
        
        if not content_str:
            return bets_by_position
        
        # æŒ‰é€—å·åˆ†å‰²æ‰€æœ‰éƒ¨åˆ†
        parts = [part.strip() for part in content_str.split(',')]
        
        current_position = None
        
        for part in parts:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä½ç½®å…³é”®è¯
            is_position = False
            position_keywords = ['æ­£ç ä¸€', 'æ­£ç äºŒ', 'æ­£ç ä¸‰', 'æ­£ç å››', 'æ­£ç äº”', 'æ­£ç å…­',
                               'æ­£1', 'æ­£2', 'æ­£3', 'æ­£4', 'æ­£5', 'æ­£6',
                               'æ­£ç 1', 'æ­£ç 2', 'æ­£ç 3', 'æ­£ç 4', 'æ­£ç 5', 'æ­£ç 6']
            
            for keyword in position_keywords:
                if keyword in part and '-' in part:
                    is_position = True
                    break
            
            # å¦‚æœåŒ…å«ä½ç½®ä¿¡æ¯æˆ–è€…æ˜¯æ˜ç¡®çš„"ä½ç½®-å†…å®¹"æ ¼å¼
            if '-' in part and is_position:
                try:
                    position_part, bet_value = part.split('-', 1)
                    current_position = position_part.strip()
                    bets_by_position[current_position].append(bet_value.strip())
                except ValueError:
                    # åˆ†å‰²å¤±è´¥ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„ä½ç½®æ ¼å¼
                    if current_position:
                        bets_by_position[current_position].append(part)
            elif current_position:
                # å±äºå½“å‰ä½ç½®çš„æŠ•æ³¨é¡¹
                bets_by_position[current_position].append(part)
            else:
                # æ²¡æœ‰å½“å‰ä½ç½®ï¼Œå¯èƒ½æ˜¯ç‹¬ç«‹çš„æŠ•æ³¨é¡¹
                bets_by_position['æœªçŸ¥ä½ç½®'].append(part)
        
        return bets_by_position
    
    @staticmethod
    def parse_ssc_content(content):
        """è§£ææ—¶æ—¶å½©æŠ•æ³¨å†…å®¹ - å¢å¼ºç«–çº¿æ ¼å¼æ”¯æŒ"""
        ssc_positions = ['ç¬¬1çƒ', 'ç¬¬2çƒ', 'ç¬¬3çƒ', 'ç¬¬4çƒ', 'ç¬¬5çƒ',
                        'ä¸‡ä½', 'åƒä½', 'ç™¾ä½', 'åä½', 'ä¸ªä½']
        
        content_str = str(content).strip()
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ç«–çº¿åˆ†éš”æ ¼å¼
        if '|' in content_str and any(char.isdigit() or char == '_' or char == ',' for char in content_str):
            vertical_result = ContentParser.parse_ssc_vertical_format(content_str)
            if any(vertical_result.values()):  # å¦‚æœæœ‰è§£æç»“æœ
                return vertical_result
        
        # åŸæœ‰çš„è§£æé€»è¾‘
        return ContentParser.parse_positional_bets(content, ssc_positions)

    @staticmethod
    def parse_3d_vertical_format(content):
        """
        è§£æ3D/æ’åˆ—3ç«–çº¿åˆ†éš”çš„å®šä½èƒ†æ ¼å¼
        æ ¼å¼ï¼šå·ç 1,å·ç 2|å·ç 3|å·ç 4,å·ç 5,å·ç 6
        æˆ–è€…ï¼š_|05|_ è¡¨ç¤ºåªæœ‰ç¬¬äºŒä¸ªä½ç½®æœ‰æŠ•æ³¨
        """
        content_str = str(content).strip()
        bets_by_position = defaultdict(list)
        
        if not content_str:
            return bets_by_position
        
        # å®šä¹‰ä½ç½®æ˜ å°„ - 3Dé€šå¸¸æ˜¯ç™¾ä½ã€åä½ã€ä¸ªä½
        positions = ['ç™¾ä½', 'åä½', 'ä¸ªä½']
        
        # æŒ‰ç«–çº¿åˆ†å‰²
        parts = content_str.split('|')
        
        for i, part in enumerate(parts):
            if i < len(positions):
                position = positions[i]
                part_clean = part.strip()
                
                # è·³è¿‡ç©ºä½æˆ–ä¸‹åˆ’çº¿
                if not part_clean or part_clean == '_' or part_clean == '':
                    continue
                
                # æå–æ•°å­—ï¼ˆå¯èƒ½æ˜¯å•ä¸ªæ•°å­—æˆ–å¤šä¸ªé€—å·åˆ†éš”çš„æ•°å­—ï¼‰
                numbers = []
                if ',' in part_clean:
                    # é€—å·åˆ†éš”çš„å¤šä¸ªæ•°å­—
                    number_strs = part_clean.split(',')
                    for num_str in number_strs:
                        num_clean = num_str.strip()
                        if num_clean.isdigit():
                            numbers.append(int(num_clean))
                else:
                    # å•ä¸ªæ•°å­—
                    if part_clean.isdigit():
                        numbers.append(int(num_clean))
                
                # æ·»åŠ åˆ°å¯¹åº”ä½ç½®
                bets_by_position[position].extend(numbers)
        
        return bets_by_position

    @staticmethod
    def infer_position_from_content(content, lottery_type):
        """ä»å†…å®¹å’Œå½©ç§ç±»å‹æ¨æ–­ä½ç½®"""
        content_str = str(content)
        
        if lottery_type == 'PK10':
            # PK10ä½ç½®æ¨æ–­é€»è¾‘
            pk10_positions = {
                'å† å†›': ['å† å†›', 'ç¬¬1å', 'ç¬¬ä¸€å', 'å‰ä¸€'],
                'äºšå†›': ['äºšå†›', 'ç¬¬2å', 'ç¬¬äºŒå'],
                'ç¬¬ä¸‰å': ['ç¬¬ä¸‰å', 'å­£å†›', 'ç¬¬3å'],
                'ç¬¬å››å': ['ç¬¬å››å', 'ç¬¬4å'],
                'ç¬¬äº”å': ['ç¬¬äº”å', 'ç¬¬5å'],
                'ç¬¬å…­å': ['ç¬¬å…­å', 'ç¬¬6å'],
                'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå', 'ç¬¬7å'],
                'ç¬¬å…«å': ['ç¬¬å…«å', 'ç¬¬8å'],
                'ç¬¬ä¹å': ['ç¬¬ä¹å', 'ç¬¬9å'],
                'ç¬¬åå': ['ç¬¬åå', 'ç¬¬10å']
            }
            for position, keywords in pk10_positions.items():
                for keyword in keywords:
                    if keyword in content_str:
                        return position
        
        elif lottery_type == 'SSC':
            # æ—¶æ—¶å½©ä½ç½®æ¨æ–­é€»è¾‘
            ssc_positions = {
                'ç¬¬1çƒ': ['ç¬¬1çƒ', 'ä¸‡ä½', 'ç¬¬ä¸€ä½'],
                'ç¬¬2çƒ': ['ç¬¬2çƒ', 'åƒä½', 'ç¬¬äºŒä½'],
                'ç¬¬3çƒ': ['ç¬¬3çƒ', 'ç™¾ä½', 'ç¬¬ä¸‰ä½'],
                'ç¬¬4çƒ': ['ç¬¬4çƒ', 'åä½', 'ç¬¬å››ä½'],
                'ç¬¬5çƒ': ['ç¬¬5çƒ', 'ä¸ªä½', 'ç¬¬äº”ä½']
            }
            for position, keywords in ssc_positions.items():
                for keyword in keywords:
                    if keyword in content_str:
                        return position
        
        elif lottery_type == 'LHC':
            # å…­åˆå½©ä½ç½®æ¨æ–­é€»è¾‘
            lhc_positions = {
                'æ­£ç 1': ['æ­£ç ä¸€', 'æ­£1', 'æ­£ç 1'],
                'æ­£ç 2': ['æ­£ç äºŒ', 'æ­£2', 'æ­£ç 2'],
                'æ­£ç 3': ['æ­£ç ä¸‰', 'æ­£3', 'æ­£ç 3'],
                'æ­£ç 4': ['æ­£ç å››', 'æ­£4', 'æ­£ç 4'],
                'æ­£ç 5': ['æ­£ç äº”', 'æ­£5', 'æ­£ç 5'],
                'æ­£ç 6': ['æ­£ç å…­', 'æ­£6', 'æ­£ç 6']
            }
            for position, keywords in lhc_positions.items():
                for keyword in keywords:
                    if keyword in content_str:
                        return position
        
        return 'æœªçŸ¥ä½ç½®'

# ==================== æ•°æ®åˆ†æç±» ====================
class DataAnalyzer:
    def __init__(self):
        self.cache = {}
        self.content_parser = ContentParser()  # æ·»åŠ ç»Ÿä¸€è§£æå™¨
    
    @lru_cache(maxsize=10000)
    def extract_numbers_cached(self, content, min_num, max_num, is_pk10=False):
        """å¸¦ç¼“å­˜çš„å·ç æå–å‡½æ•°"""
        return self.extract_numbers_from_content(content, min_num, max_num, is_pk10)
    
    def extract_numbers_from_content(self, content, min_num=0, max_num=49, is_pk10=False):
        """ä»å†…å®¹ä¸­æå–æ•°å­— - å¢å¼ºä¸‰å†›æ ¼å¼å¤„ç†"""
        numbers = []
        content_str = str(content)
        
        try:
            # ç‰¹æ®Šå¤„ç†ä¸‰å†›æ ¼å¼ï¼š1,2,3,4,5,6
            if re.match(r'^(\d,)*\d$', content_str.strip()):
                numbers = [int(x.strip()) for x in content_str.split(',') if x.strip().isdigit()]
                # è¿‡æ»¤èŒƒå›´
                numbers = [num for num in numbers if min_num <= num <= max_num]
                return list(set(numbers))
            
            if is_pk10:
                # PKæ‹¾/èµ›è½¦ç‰¹æ®Šå¤„ç†ï¼šè¿‡æ»¤æ‰"ç¬¬Xå"ç­‰ç©æ³•æè¿°
                content_str = re.sub(r'ç¬¬\d+å-?', '', content_str)
            
            # æå–æ•°å­—
            number_matches = re.findall(r'\b\d{1,2}\b', content_str)
            for match in number_matches:
                num = int(match)
                if min_num <= num <= max_num:
                    numbers.append(num)
            
            return list(set(numbers))
        except Exception as e:
            logger.warning(f"å·ç æå–å¤±è´¥: {content}, é”™è¯¯: {str(e)}")
            return []
    
    def extract_zodiacs_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–ç”Ÿè‚–"""
        zodiacs = ['é¼ ', 'ç‰›', 'è™', 'å…”', 'é¾™', 'è›‡', 'é©¬', 'ç¾Š', 'çŒ´', 'é¸¡', 'ç‹—', 'çŒª']
        found_zodiacs = []
        
        content_str = str(content)
        for zodiac in zodiacs:
            if zodiac in content_str:
                found_zodiacs.append(zodiac)
        
        return list(set(found_zodiacs))
    
    def extract_tails_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–å°¾æ•°ï¼ˆè¿å°¾ä¸“ç”¨ï¼‰"""
        tails = []
        content_str = str(content)
        
        # åŒ¹é…å°¾æ•°æ¨¡å¼ï¼šå°¾0ã€å°¾1ã€0å°¾ã€1å°¾ç­‰
        tail_patterns = [
            r'å°¾([0-9])',  # å°¾0,å°¾1,...,å°¾9
            r'([0-9])å°¾',  # 0å°¾,1å°¾,...,9å°¾
        ]
        
        for pattern in tail_patterns:
            matches = re.findall(pattern, content_str)
            tails.extend([int(tail) for tail in matches])
        
        return list(set(tails))
    
    def extract_size_parity_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–å¤§å°å•åŒæœ¬"""
        content_str = str(content)
        size_parity = []
        
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„åŒ¹é…ï¼Œé¿å…è¯¯åŒ¹é…
        if re.search(r'(?<!åˆ)å¤§(?![å°å°¾])', content_str) or 'ç‰¹å¤§' in content_str:
            size_parity.append('å¤§')
        if re.search(r'(?<!åˆ)å°(?![å¤§å°¾])', content_str) or 'ç‰¹å°' in content_str:
            size_parity.append('å°')
        if re.search(r'(?<!åˆ)å•(?![åŒ])', content_str) or 'ç‰¹å•' in content_str:
            size_parity.append('å•')
        if re.search(r'(?<!åˆ)åŒ(?![å•])', content_str) or 'ç‰¹åŒ' in content_str:
            size_parity.append('åŒ')
        
        return list(set(size_parity))
    
    def extract_dragon_tiger_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–é¾™è™"""
        content_str = str(content)
        dragon_tiger = []
        
        if 'é¾™' in content_str and 'è™' not in content_str:
            dragon_tiger.append('é¾™')
        if 'è™' in content_str and 'é¾™' not in content_str:
            dragon_tiger.append('è™')
        
        return list(set(dragon_tiger))
    
    def extract_wave_color_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–æ³¢è‰² - å¢å¼ºç‰ˆï¼Œæ”¯æŒåŠæ³¢é¡¹è¯†åˆ«"""
        content_str = str(content)
        found_waves = []
        
        # æ³¢è‰²æ˜ å°„ï¼ˆåŒ…æ‹¬ä¸ƒè‰²æ³¢çš„æ‰€æœ‰é¢œè‰²ï¼‰
        wave_mappings = {
            'çº¢æ³¢': ['çº¢æ³¢', 'ç´…è‰²æ³¢', 'çº¢'],
            'è“æ³¢': ['è“æ³¢', 'è—æ³¢', 'è“', 'è—'],
            'ç»¿æ³¢': ['ç»¿æ³¢', 'ç¶ æ³¢', 'ç»¿', 'ç¶ '],
            'ç´«æ³¢': ['ç´«æ³¢', 'ç´«'],
            'æ©™æ³¢': ['æ©™æ³¢', 'æ©™'],
            'é»„æ³¢': ['é»„æ³¢', 'é»ƒæ³¢', 'é»„', 'é»ƒ'],
            'é’æ³¢': ['é’æ³¢', 'é’']
        }
        
        for wave_name, keywords in wave_mappings.items():
            for keyword in keywords:
                if keyword in content_str:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å¤åˆæŠ•æ³¨ï¼Œå¦‚"çº¢æ³¢-çº¢åŒ"
                    if '-' in content_str and f"{keyword}-" in content_str:
                        # è¿™ç§æƒ…å†µ"çº¢æ³¢"æ˜¯ç©æ³•éƒ¨åˆ†ï¼Œä¸æ˜¯å®é™…æŠ•æ³¨å†…å®¹
                        pass  # æ·»åŠ passè¯­å¥ï¼Œé¿å…ç©ºçš„ifåˆ†æ”¯
                    else:
                        # æ£€æŸ¥æ˜¯å¦è¢«åŠæ³¢é¡¹åŒ…å«ï¼ˆå¦‚"çº¢å¤§"åŒ…å«"çº¢"ï¼Œä½†ä¸æ˜¯æˆ‘ä»¬è¦çš„æ³¢è‰²ï¼‰
                        is_banbo_item = False
                        banbo_indicators = ['å¤§', 'å°', 'å•', 'åŒ']
                        for indicator in banbo_indicators:
                            if f"{keyword}{indicator}" in content_str or f"{keyword} {indicator}" in content_str:
                                is_banbo_item = True
                                break
                        
                        if not is_banbo_item:
                            found_waves.append(wave_name)
                    break  # æ‰¾åˆ°ä¸€ä¸ªå…³é”®è¯å°±è·³å‡ºå†…å±‚å¾ªç¯
        
        return list(set(found_waves))

    def extract_three_color_wave_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–ä¸‰è‰²å½©çš„æ³¢è‰² - åªæå–çº¢æ³¢ã€ç»¿æ³¢ã€ç´«æ³¢"""
        content_str = str(content)
        found_waves = []
        
        # å¤„ç†ç¹ä½“å­—å’Œç®€ä½“å­—
        if 'çº¢æ³¢' in content_str or 'ç´…æ³¢' in content_str:
            found_waves.append('çº¢æ³¢')
        if 'ç»¿æ³¢' in content_str or 'ç¶ æ³¢' in content_str:
            found_waves.append('ç»¿æ³¢')
        if 'ç´«æ³¢' in content_str:
            found_waves.append('ç´«æ³¢')
        
        return list(set(found_waves))
    
    def extract_five_elements_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–äº”è¡Œ"""
        content_str = str(content)
        elements = ['é‡‘', 'æœ¨', 'æ°´', 'ç«', 'åœŸ']
        found_elements = []
        
        for element in elements:
            if element in content_str:
                found_elements.append(element)
        
        return list(set(found_elements))
    
    def extract_douniu_types(self, content):
        """æå–æ–—ç‰›ç±»å‹"""
        content_str = str(content)
        bull_types = []
        
        # ç§»é™¤"æ–—ç‰›-"å‰ç¼€
        clean_content = content_str.replace('æ–—ç‰›-', '')
        
        # æ–—ç‰›ç±»å‹åˆ—è¡¨
        all_types = ['æ— ç‰›', 'ç‰›ä¸€', 'ç‰›äºŒ', 'ç‰›ä¸‰', 'ç‰›å››', 'ç‰›äº”', 
                    'ç‰›å…­', 'ç‰›ä¸ƒ', 'ç‰›å…«', 'ç‰›ä¹', 'ç‰›ç‰›']
        
        for bull_type in all_types:
            if bull_type in clean_content:
                bull_types.append(bull_type)
        
        return list(set(bull_types))
    
    def parse_pk10_gyh_content(self, content):
        """è§£æPK10å† äºšå’Œç©æ³•å†…å®¹"""
        content_str = str(content)
        result = {
            'numbers': set(),    # å’Œå€¼å·ç 
            'size_parity': set() # å¤§å°å•åŒ
        }
        
        # æå–å·ç ï¼ˆ3-19ï¼‰
        numbers = re.findall(r'\b(1[0-9]|[3-9])\b', content_str)
        result['numbers'].update([int(num) for num in numbers])
        
        # æå–å¤§å°å•åŒ
        content_lower = content_str.lower()
        if 'å¤§' in content_lower or 'å† äºšå¤§' in content_lower:
            result['size_parity'].add('å¤§')
        if 'å°' in content_lower or 'å† äºšå°' in content_lower:
            result['size_parity'].add('å°')
        if 'å•' in content_lower or 'å† äºšå•' in content_lower:
            result['size_parity'].add('å•')
        if 'åŒ' in content_lower or 'å† äºšåŒ' in content_lower:
            result['size_parity'].add('åŒ')
        
        return result
    
    def parse_pk10_number_content(self, content):
        """è§£æPK10å·ç ç±»ç©æ³•å†…å®¹ - å¢å¼ºç«–çº¿æ ¼å¼æ”¯æŒ"""
        content_str = str(content)
        numbers_by_position = defaultdict(list)
        
        # é¦–å…ˆå°è¯•ç«–çº¿åˆ†éš”æ ¼å¼
        if '|' in content_str and any(char.isdigit() or char == '_' or char == ',' for char in content_str):
            vertical_result = ContentParser.parse_pk10_vertical_format(content_str)
            if any(vertical_result.values()):
                return vertical_result
        
        # å¤„ç†ç«–çº¿åˆ†éš”çš„æ ¼å¼ï¼š01,02,03,04,05|07,08,06,09,10|...
        if '|' in content_str and re.search(r'\d{2}', content_str):
            positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å']
            parts = content_str.split('|')
            
            for i, part in enumerate(parts):
                if i < len(positions):
                    position = positions[i]
                    numbers = re.findall(r'\d{2}', part)
                    numbers_by_position[position].extend([int(num) for num in numbers])
        
        # å¤„ç†"ç¬¬ä¹å:01,02,05,06,07,08,09,03"è¿™ç§æ ¼å¼
        elif ':' in content_str and re.search(r'\d{2}', content_str):
            match = re.match(r'^(.+?):([\d,]+)$', content_str)
            if match:
                position = match.group(1).strip()
                numbers_str = match.group(2)
                position = self._normalize_pk10_position(position)
                if position:
                    numbers = re.findall(r'\d{2}', numbers_str)
                    numbers_by_position[position].extend([int(num) for num in numbers])
            else:
                parts = content_str.split(',')
                for part in parts:
                    if ':' in part:
                        position, numbers_str = part.split(':', 1)
                        position = self._normalize_pk10_position(position)
                        if position:
                            numbers = re.findall(r'\d{2}', numbers_str)
                            numbers_by_position[position].extend([int(num) for num in numbers])
        
        # å¤„ç†å† å†›-01,02,03æ ¼å¼
        elif '-' in content_str and re.search(r'\d{2}', content_str):
            parts = content_str.split(',')
            for part in parts:
                if '-' in part:
                    position, numbers_str = part.split('-', 1)
                    position = self._normalize_pk10_position(position)
                    numbers = re.findall(r'\d{2}', numbers_str)
                    numbers_by_position[position].extend([int(num) for num in numbers])
        
        # å¤„ç†çº¯æ•°å­—æ ¼å¼
        else:
            numbers = self.extract_numbers_from_content(content_str, 1, 10, is_pk10=True)
            if numbers:
                position = self._infer_pk10_position_from_content(content_str)
                numbers_by_position[position].extend(numbers)
        
        # å»é‡
        for position in numbers_by_position:
            numbers_by_position[position] = list(set(numbers_by_position[position]))
        
        return numbers_by_position
    
    def _infer_pk10_position_from_content(self, content):
        """æ¨æ–­PK10ä½ç½®"""
        content_str = str(content)
        
        position_mapping = {
            'å† å†›': ['å† å†›', 'ç¬¬1å', 'ç¬¬ä¸€å'],
            'äºšå†›': ['äºšå†›', 'ç¬¬2å', 'ç¬¬äºŒå'],
            'ç¬¬ä¸‰å': ['ç¬¬ä¸‰å', 'ç¬¬3å', 'å­£å†›'],
            'ç¬¬å››å': ['ç¬¬å››å', 'ç¬¬4å'],
            'ç¬¬äº”å': ['ç¬¬äº”å', 'ç¬¬5å'],
            'ç¬¬å…­å': ['ç¬¬å…­å', 'ç¬¬6å'],
            'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå', 'ç¬¬7å'],
            'ç¬¬å…«å': ['ç¬¬å…«å', 'ç¬¬8å'],
            'ç¬¬ä¹å': ['ç¬¬ä¹å', 'ç¬¬9å'],
            'ç¬¬åå': ['ç¬¬åå', 'ç¬¬10å']
        }
        
        for position, keywords in position_mapping.items():
            for keyword in keywords:
                if keyword in content_str:
                    return position
        
        return 'å† å†›'
    
    def _normalize_pk10_position(self, position):
        """å¢å¼ºçš„PK10ä½ç½®æ ‡å‡†åŒ–"""
        position_mapping = {
            'å† å†›': 'å† å†›', 'ç¬¬1å': 'å† å†›', 'ç¬¬ä¸€å': 'å† å†›', '1': 'å† å†›', '1st': 'å† å†›',
            'å‰ä¸€': 'å† å†›',
            'äºšå†›': 'äºšå†›', 'ç¬¬2å': 'äºšå†›', 'ç¬¬äºŒå': 'äºšå†›', '2': 'äºšå†›', '2nd': 'äºšå†›',
            'å­£å†›': 'ç¬¬ä¸‰å', 'ç¬¬3å': 'ç¬¬ä¸‰å', 'ç¬¬ä¸‰å': 'ç¬¬ä¸‰å', 'ä¸‰å': 'ç¬¬ä¸‰å', '3': 'ç¬¬ä¸‰å', '3rd': 'ç¬¬ä¸‰å',
            'ç¬¬4å': 'ç¬¬å››å', 'ç¬¬å››å': 'ç¬¬å››å', 'å››å': 'ç¬¬å››å', '4': 'ç¬¬å››å', '4th': 'ç¬¬å››å',
            'ç¬¬5å': 'ç¬¬äº”å', 'ç¬¬äº”å': 'ç¬¬äº”å', 'äº”å': 'ç¬¬äº”å', '5': 'ç¬¬äº”å', '5th': 'ç¬¬äº”å',
            'ç¬¬6å': 'ç¬¬å…­å', 'ç¬¬å…­å': 'ç¬¬å…­å', 'å…­å': 'ç¬¬å…­å', '6': 'ç¬¬å…­å', '6th': 'ç¬¬å…­å',
            'ç¬¬7å': 'ç¬¬ä¸ƒå', 'ç¬¬ä¸ƒå': 'ç¬¬ä¸ƒå', 'ä¸ƒå': 'ç¬¬ä¸ƒå', '7': 'ç¬¬ä¸ƒå', '7th': 'ç¬¬ä¸ƒå',
            'ç¬¬8å': 'ç¬¬å…«å', 'ç¬¬å…«å': 'ç¬¬å…«å', 'å…«å': 'ç¬¬å…«å', '8': 'ç¬¬å…«å', '8th': 'ç¬¬å…«å',
            'ç¬¬9å': 'ç¬¬ä¹å', 'ç¬¬ä¹å': 'ç¬¬ä¹å', 'ä¹å': 'ç¬¬ä¹å', '9': 'ç¬¬ä¹å', '9th': 'ç¬¬ä¹å',
            'ç¬¬10å': 'ç¬¬åå', 'ç¬¬åå': 'ç¬¬åå', 'åå': 'ç¬¬åå', '10': 'ç¬¬åå', '10th': 'ç¬¬åå'
        }
        
        position = position.strip()
        
        # ç›´æ¥æ˜ å°„
        if position in position_mapping:
            return position_mapping[position]
        
        # æ¨¡ç³ŠåŒ¹é… - å¢å¼ºé€»è¾‘
        for key, value in position_mapping.items():
            if key in position:
                return value
        
        # å¤„ç†å¸¦å†’å·çš„æ ¼å¼ï¼ˆå¦‚"ç¬¬ä¹å:"ï¼‰
        if position.endswith(':'):
            clean_position = position[:-1].strip()
            if clean_position in position_mapping:
                return position_mapping[clean_position]
            for key, value in position_mapping.items():
                if key in clean_position:
                    return value
        
        # å¦‚æœè¿˜æ˜¯æ— æ³•è¯†åˆ«ï¼Œå°è¯•æ›´å®½æ¾çš„åŒ¹é…
        position_lower = position.lower()
        if 'ä¹' in position_lower or '9' in position_lower:
            return 'ç¬¬ä¹å'
        
        return position  # è¿”å›åŸä½ç½®è€Œä¸æ˜¯æœªçŸ¥

    def parse_3d_content(self, content):
        """è§£æ3DæŠ•æ³¨å†…å®¹ - å¢å¼ºç«–çº¿æ ¼å¼æ”¯æŒ"""
        content_str = str(content).strip()
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ç«–çº¿åˆ†éš”æ ¼å¼
        if '|' in content_str and any(char.isdigit() or char == '_' or char == ',' for char in content_str):
            vertical_result = ContentParser.parse_3d_vertical_format(content_str)
            if any(vertical_result.values()):  # å¦‚æœæœ‰è§£æç»“æœ
                return vertical_result
        
        # åŸæœ‰çš„è§£æé€»è¾‘
        return ContentParser.parse_positional_bets(content, ['ç™¾ä½', 'åä½', 'ä¸ªä½'])
    
    def parse_lhc_special_content(self, content):
        """è§£æå…­åˆå½©ç‰¹æ®Šç©æ³•å†…å®¹ï¼ŒæŒ‰ç…§ç©æ³•-æŠ•æ³¨å†…å®¹æ ¼å¼è§£æ"""
        content_str = str(content)
        
        # æ–°çš„è§£æé€»è¾‘ï¼šæŒ‰ç…§"ç©æ³•-æŠ•æ³¨å†…å®¹"æ ¼å¼è§£æ
        if '-' in content_str:
            parts = content_str.split('-', 1)  # åªåˆ†å‰²ç¬¬ä¸€ä¸ª"-"
            play_method = parts[0].strip()      # ç©æ³•éƒ¨åˆ†
            bet_content = parts[1].strip()      # æŠ•æ³¨å†…å®¹éƒ¨åˆ†
            
            # è°ƒè¯•ä¿¡æ¯ - æ˜¾ç¤ºè§£æè¿‡ç¨‹
            
            # è¿”å›æŠ•æ³¨å†…å®¹éƒ¨åˆ†ï¼Œè¿™æ‰æ˜¯å®é™…çš„ä¸‹æ³¨å†…å®¹
            return bet_content
        else:
            # å¦‚æœæ²¡æœ‰"-"ï¼Œæ•´ä¸ªå†…å®¹ä½œä¸ºæŠ•æ³¨å†…å®¹
            return content_str.strip()
    
    def extract_lhc_two_sides_content(self, content):
        """ä¸“é—¨æå–å…­åˆå½©ä¸¤é¢ç©æ³•çš„å„ç§æŠ•æ³¨ç±»å‹"""
        content_str = str(content)
        result = {
            'normal_size': set(),    # æ™®é€šå¤§å°ï¼šå¤§/å°
            'tail_size': set(),      # å°¾å¤§å°ï¼šå°¾å¤§/å°¾å°
            'parity': set(),         # å•åŒï¼šå•/åŒ
            'sum_parity': set(),     # åˆæ•°å•åŒï¼šåˆå•/åˆåŒ
            'range_bet': set(),      # åŒºé—´ï¼š1-10,11-20,21-30,31-40,41-49
            'animal_type': set(),    # å®¶ç¦½é‡å…½ï¼šå®¶ç¦½/é‡å…½
            'zodiac': set(),         # ç”Ÿè‚–
            'wave': set(),           # æ³¢è‰²ï¼šçº¢æ³¢/è“æ³¢/ç»¿æ³¢
            'other': set()           # å…¶ä»–
        }
    
        # é¦–å…ˆè§£æç©æ³•-æŠ•æ³¨å†…å®¹æ ¼å¼
        clean_content = content_str
        if '-' in content_str:
            parts = content_str.split('-', 1)
            clean_content = parts[1].strip()  # åªä½¿ç”¨æŠ•æ³¨å†…å®¹éƒ¨åˆ†
    
        # æ–°å¢ï¼šç‰¹å•ã€ç‰¹åŒæ˜ å°„åˆ°æ™®é€šå•åŒ
        if 'ç‰¹å•' in clean_content:
            result['parity'].add('å•')
        if 'ç‰¹åŒ' in clean_content:
            result['parity'].add('åŒ')
        
        # æ–°å¢ï¼šç‰¹å®¶è‚–æ˜ å°„åˆ°å®¶ç¦½ï¼Œç‰¹é‡è‚–æ˜ å°„åˆ°é‡å…½
        if 'ç‰¹å®¶è‚–' in clean_content or 'å®¶è‚–' in clean_content:
            result['animal_type'].add('å®¶ç¦½')
        if 'ç‰¹é‡è‚–' in clean_content or 'é‡è‚–' in clean_content:
            result['animal_type'].add('é‡å…½')
    
        # æ³¢è‰²æ£€æµ‹
        if 'çº¢æ³¢' in clean_content and 'çº¢æ³¢-' not in content_str:
            result['wave'].add('çº¢æ³¢')
        if 'è“æ³¢' in clean_content and 'è“æ³¢-' not in content_str:
            result['wave'].add('è“æ³¢')
        if 'ç»¿æ³¢' in clean_content and 'ç»¿æ³¢-' not in content_str:
            result['wave'].add('ç»¿æ³¢')
    
        # æ™®é€šå¤§å°æ£€æµ‹
        if 'å¤§' in clean_content and 'å°¾å¤§' not in clean_content and 'åˆå¤§' not in clean_content and 'ç‰¹å¤§' not in clean_content:
            result['normal_size'].add('å¤§')
        if 'å°' in clean_content and 'å°¾å°' not in clean_content and 'åˆå°' not in clean_content and 'ç‰¹å°' not in clean_content:
            result['normal_size'].add('å°')
    
        # å°¾å¤§å°æ£€æµ‹
        if 'å°¾å¤§' in clean_content:
            result['tail_size'].add('å°¾å¤§')
        if 'å°¾å°' in clean_content:
            result['tail_size'].add('å°¾å°')
    
        # å•åŒæ£€æµ‹ï¼ˆç‰¹å•ç‰¹åŒå·²ç»åœ¨ä¸Šé¢å¤„ç†äº†ï¼Œè¿™é‡Œå¤„ç†æ™®é€šå•åŒï¼‰
        if 'å•' in clean_content and 'åˆå•' not in clean_content and 'ç‰¹å•' not in clean_content:
            result['parity'].add('å•')
        if 'åŒ' in clean_content and 'åˆåŒ' not in clean_content and 'ç‰¹åŒ' not in clean_content:
            result['parity'].add('åŒ')
    
        # åˆæ•°å•åŒæ£€æµ‹
        if 'åˆå•' in clean_content:
            result['sum_parity'].add('åˆå•')
        if 'åˆåŒ' in clean_content:
            result['sum_parity'].add('åˆåŒ')
    
        # åŒºé—´æ£€æµ‹
        range_keywords = ['1-10', '11-20', '21-30', '31-40', '41-49']
        for range_keyword in range_keywords:
            if range_keyword in clean_content:
                result['range_bet'].add(range_keyword)
    
        # å®¶ç¦½é‡å…½æ£€æµ‹ï¼ˆç‰¹å®¶è‚–ç‰¹é‡è‚–å·²ç»åœ¨ä¸Šé¢å¤„ç†äº†ï¼Œè¿™é‡Œå¤„ç†æ™®é€šçš„å®¶ç¦½é‡å…½ï¼‰
        if 'å®¶ç¦½' in clean_content:
            result['animal_type'].add('å®¶ç¦½')
        if 'é‡å…½' in clean_content:
            result['animal_type'].add('é‡å…½')
    
        # ç”Ÿè‚–æ£€æµ‹
        zodiacs = ['é¼ ', 'ç‰›', 'è™', 'å…”', 'é¾™', 'è›‡', 'é©¬', 'ç¾Š', 'çŒ´', 'é¸¡', 'ç‹—', 'çŒª']
        for zodiac in zodiacs:
            if zodiac in clean_content:
                result['zodiac'].add(zodiac)
    
        # æ¸…ç†ç©ºé›†åˆ
        for key in list(result.keys()):
            if not result[key]:
                del result[key]
    
        return result

# ==================== ç©æ³•åˆ†ç±»ç»Ÿä¸€ ====================
class PlayCategoryNormalizer:
    def __init__(self):
        self.category_mapping = self._create_category_mapping()
    
    def _create_category_mapping(self):
        """åˆ›å»ºç©æ³•åˆ†ç±»æ˜ å°„çš„å®Œæ•´æ˜ å°„"""
        mapping = {
            # å¿«ä¸‰ç©æ³•
            'å’Œå€¼': 'å’Œå€¼',
            'å’Œå€¼_å¤§å°å•åŒ': 'å’Œå€¼',
            'ä¸¤é¢': 'ä¸¤é¢',
            'äºŒä¸åŒå·': 'äºŒä¸åŒå·',
            'ä¸‰ä¸åŒå·': 'ä¸‰ä¸åŒå·',
            # æ³¨é‡Šæ‰åŒå·ç©æ³•
            # 'äºŒåŒå·': 'äºŒåŒå·',
            # 'ä¸‰åŒå·': 'ä¸‰åŒå·',
            'ç‹¬èƒ†': 'ç‹¬èƒ†',
            # æ–°å¢ç‚¹æ•°æ˜ å°„
            'ç‚¹æ•°': 'å’Œå€¼',
            # å¢å¼ºä¸‰å†›æ˜ å°„
            'ä¸‰å†›': 'ç‹¬èƒ†',
            'ä¸‰è»': 'ç‹¬èƒ†',
            'ä¸‰å†›_å¤§å°': 'ç‹¬èƒ†',
            'ä¸‰å†›_å•åŒ': 'ç‹¬èƒ†',
            
            # å…­åˆå½©ç©æ³•å®Œæ•´æ˜ å°„ - å°¾æ•°ç‹¬ç«‹æ˜ å°„
            'ç‰¹ç ': 'ç‰¹ç ',
            'æ­£1ç‰¹': 'æ­£1ç‰¹',
            'æ­£ç ç‰¹_æ­£ä¸€ç‰¹': 'æ­£1ç‰¹',
            'æ­£2ç‰¹': 'æ­£2ç‰¹',
            'æ­£ç ç‰¹_æ­£äºŒç‰¹': 'æ­£2ç‰¹',
            'æ­£3ç‰¹': 'æ­£3ç‰¹',
            'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹': 'æ­£3ç‰¹',
            'æ­£4ç‰¹': 'æ­£4ç‰¹',
            'æ­£ç ç‰¹_æ­£å››ç‰¹': 'æ­£4ç‰¹',
            'æ­£5ç‰¹': 'æ­£5ç‰¹',
            'æ­£ç ç‰¹_æ­£äº”ç‰¹': 'æ­£5ç‰¹',
            'æ­£6ç‰¹': 'æ­£6ç‰¹',
            'æ­£ç ç‰¹_æ­£å…­ç‰¹': 'æ­£6ç‰¹',
            'æ­£ç ': 'æ­£ç ',
            'æ­£ç‰¹': 'æ­£ç‰¹',
            'æ­£ç›ç‰¹': 'æ­£ç‰¹',
            'æ­£ç 1-6': 'æ­£ç ',
            
            # å°¾æ•°ç›¸å…³ç©æ³•ç‹¬ç«‹æ˜ å°„
            'å°¾æ•°': 'å°¾æ•°',
            'å°¾æ•°_å¤´å°¾æ•°': 'å°¾æ•°_å¤´å°¾æ•°',  # ç‹¬ç«‹æ˜ å°„
            'ç‰¹å°¾': 'ç‰¹å°¾',              # ç‹¬ç«‹æ˜ å°„
            'å…¨å°¾': 'å…¨å°¾',              # ç‹¬ç«‹æ˜ å°„
            'å°¾æ•°_æ­£ç‰¹å°¾æ•°': 'å°¾æ•°',
            
            # å…¶ä»–å…­åˆå½©ç©æ³•
            'ç‰¹è‚–': 'ç‰¹è‚–',
            'ç”Ÿè‚–_ç‰¹è‚–': 'ç‰¹è‚–',
            'å¹³ç‰¹': 'å¹³ç‰¹',
            'ç”Ÿè‚–_æ­£è‚–': 'å¹³ç‰¹',
            'ç”Ÿè‚–_ä¸€è‚–': 'ä¸€è‚–',
            'è¿è‚–': 'è¿è‚–',
            'è¿å°¾': 'è¿å°¾',
            'é¾™è™': 'é¾™è™',
            'äº”è¡Œ': 'äº”è¡Œ',

            # è¿è‚–ç©æ³•æ˜ å°„
            'äºŒè¿è‚–': 'äºŒè¿è‚–',
            'ä¸‰è¿è‚–': 'ä¸‰è¿è‚–', 
            'å››è¿è‚–': 'å››è¿è‚–',
            'äº”è¿è‚–': 'äº”è¿è‚–',
            'äºŒè¿è‚–(ä¸­)': 'äºŒè¿è‚–',
            'ä¸‰è¿è‚–(ä¸­)': 'ä¸‰è¿è‚–',
            'å››è¿è‚–(ä¸­)': 'å››è¿è‚–', 
            'äº”è¿è‚–(ä¸­)': 'äº”è¿è‚–',
            'è¿è‚–è¿å°¾_äºŒè¿è‚–': 'äºŒè¿è‚–',
            'è¿è‚–è¿å°¾_ä¸‰è¿è‚–': 'ä¸‰è¿è‚–',
            'è¿è‚–è¿å°¾_å››è¿è‚–': 'å››è¿è‚–',
            'è¿è‚–è¿å°¾_äº”è¿è‚–': 'äº”è¿è‚–',
            'è¿è‚–': 'è¿è‚–',  # é€šç”¨è¿è‚–
            
            # è¿å°¾ç©æ³•æ˜ å°„
            'äºŒè¿å°¾': 'äºŒè¿å°¾',
            'ä¸‰è¿å°¾': 'ä¸‰è¿å°¾',
            'å››è¿å°¾': 'å››è¿å°¾',
            'äº”è¿å°¾': 'äº”è¿å°¾',
            'è¿è‚–è¿å°¾_äºŒè¿å°¾': 'äºŒè¿å°¾',
            'è¿è‚–è¿å°¾_ä¸‰è¿å°¾': 'ä¸‰è¿å°¾',
            'è¿è‚–è¿å°¾_å››è¿å°¾': 'å››è¿å°¾',
            'è¿è‚–è¿å°¾_äº”è¿å°¾': 'äº”è¿å°¾',
            'è¿å°¾': 'è¿å°¾',  # é€šç”¨è¿å°¾

            # æ³¢è‰²ç›¸å…³ç©æ³•
            'è‰²æ³¢': 'è‰²æ³¢',
            'ä¸ƒè‰²æ³¢': 'è‰²æ³¢',
            'æ³¢è‰²': 'è‰²æ³¢',

            #åŠæ³¢ç›¸å…³ç©æ³•æ˜ å°„
            'åŠæ³¢': 'åŠæ³¢',
            'è“æ³¢': 'åŠæ³¢',
            'ç»¿æ³¢': 'åŠæ³¢',
            'çº¢æ³¢': 'åŠæ³¢',
            'åŠæ³¢_çº¢æ³¢': 'åŠæ³¢',
            'åŠæ³¢_è“æ³¢': 'åŠæ³¢',
            'åŠæ³¢_ç»¿æ³¢': 'åŠæ³¢',

            # æ­£ç 1-6ç›¸å…³æ˜ å°„
            'æ­£ç 1-6': 'æ­£ç 1-6',
            'æ­£ç 1~6': 'æ­£ç 1-6',
            'æ­£ç 1-6ç‰¹': 'æ­£ç 1-6',
            'æ­£ç 1~6ç‰¹': 'æ­£ç 1-6',

            # 3Dç³»åˆ—ç©æ³•æ˜ å°„
            'ä¸¤é¢': 'ä¸¤é¢',
            'å¤§å°å•åŒ': 'ä¸¤é¢',
            'ç™¾ä½': 'ç™¾ä½',
            'åä½': 'åä½', 
            'ä¸ªä½': 'ä¸ªä½',
            'ç™¾å': 'ç™¾å',
            'ç™¾ä¸ª': 'ç™¾ä¸ª',
            'åä¸ª': 'åä¸ª',
            'ç™¾åä¸ª': 'ç™¾åä¸ª',
            'å®šä½èƒ†': 'å®šä½èƒ†',
            'å®šä½èƒ†_ç™¾ä½': 'å®šä½èƒ†_ç™¾ä½',
            'å®šä½èƒ†_åä½': 'å®šä½èƒ†_åä½',
            'å®šä½èƒ†_ä¸ªä½': 'å®šä½èƒ†_ä¸ªä½',
            'ç™¾ä½(å®šä½)': 'å®šä½èƒ†_ç™¾ä½',
            'åä½(å®šä½)': 'å®šä½èƒ†_åä½',
            'ä¸ªä½(å®šä½)': 'å®šä½èƒ†_ä¸ªä½',
            
            # æ—¶æ—¶å½©ç©æ³•
            'æ–—ç‰›': 'æ–—ç‰›',
            '1-5çƒ': '1-5çƒ',
            'ç¬¬1çƒ': 'ç¬¬1çƒ',
            'ç¬¬2çƒ': 'ç¬¬2çƒ',
            'ç¬¬3çƒ': 'ç¬¬3çƒ',
            'ç¬¬4çƒ': 'ç¬¬4çƒ',
            'ç¬¬5çƒ': 'ç¬¬5çƒ',
            'æ€»å’Œ': 'æ€»å’Œ',
            'æ­£ç ': 'æ­£ç ',
            'æ­£ç ç‰¹': 'æ­£ç ',
            'æ­£ç _ç‰¹': 'æ­£ç ',
            'å®šä½èƒ†': 'å®šä½èƒ†',
            'å®šä½_ä¸‡ä½': 'å®šä½_ä¸‡ä½',
            'å®šä½_åƒä½': 'å®šä½_åƒä½',
            'å®šä½_ç™¾ä½': 'å®šä½_ç™¾ä½',
            'å®šä½_åä½': 'å®šä½_åä½',
            'å®šä½_ä¸ªä½': 'å®šä½_ä¸ªä½',
            'ä¸¤é¢': 'ä¸¤é¢',
            
            # PKæ‹¾/èµ›è½¦ç©æ³•
            'å‰ä¸€': 'å† å†›',  # å‰ä¸€å°±æ˜¯å† å†›
            'å®šä½èƒ†': 'å®šä½èƒ†',
            '1-5å': '1-5å',
            '6-10å': '6-10å',
            'å† å†›': 'å† å†›',
            'äºšå†›': 'äºšå†›',
            'å­£å†›': 'ç¬¬ä¸‰å',
            'ç¬¬3å': 'ç¬¬ä¸‰å',
            'ç¬¬4å': 'ç¬¬å››å',
            'ç¬¬5å': 'ç¬¬äº”å',
            'ç¬¬6å': 'ç¬¬å…­å',
            'ç¬¬7å': 'ç¬¬ä¸ƒå',
            'ç¬¬8å': 'ç¬¬å…«å',
            'ç¬¬9å': 'ç¬¬ä¹å',
            'ç¬¬10å': 'ç¬¬åå',
            'åŒé¢': 'ä¸¤é¢',
            'å† äºšå’Œ': 'å† äºšå’Œ',
            'å† äºšå’Œ_å¤§å°å•åŒ': 'å† äºšå’Œ_å¤§å°å•åŒ',
            'å† äºšå’Œ_å’Œå€¼': 'å† äºšå’Œ_å’Œå€¼',
            
            # å¤§å°å•åŒç‹¬ç«‹ç©æ³•
            'å¤§å°_å† å†›': 'å¤§å°_å† å†›',
            'å¤§å°_äºšå†›': 'å¤§å°_äºšå†›',
            'å¤§å°_å­£å†›': 'å¤§å°_å­£å†›',
            'å•åŒ_å† å†›': 'å•åŒ_å† å†›',
            'å•åŒ_äºšå†›': 'å•åŒ_äºšå†›',
            'å•åŒ_å­£å†›': 'å•åŒ_å­£å†›',
            
            # é¾™è™ç‹¬ç«‹ç©æ³•
            'é¾™è™_å† å†›': 'é¾™è™_å† å†›',
            'é¾™è™_å†  å†›': 'é¾™è™_å† å†›',
            'é¾™è™_äºšå†›': 'é¾™è™_äºšå†›',
            'é¾™è™_äºš å†›': 'é¾™è™_äºšå†›',
            'é¾™è™_å­£å†›': 'é¾™è™_å­£å†›',
            'é¾™è™_å­£ å†›': 'é¾™è™_å­£å†›',
            
            # å®šä½èƒ†ç»†åˆ†
            'å®šä½èƒ†_ç¬¬1~5å': 'å®šä½èƒ†_ç¬¬1~5å',
            'å®šä½èƒ†_ç¬¬6~10å': 'å®šä½èƒ†_ç¬¬6~10å',
            'å®šä½èƒ†_1~5': 'å®šä½èƒ†_ç¬¬1~5å',
            'å®šä½èƒ†_6~10': 'å®šä½èƒ†_ç¬¬6~10å',
            'å®šä½èƒ†_1-5': 'å®šä½èƒ†_ç¬¬1~5å', 
            'å®šä½èƒ†_6-10': 'å®šä½èƒ†_ç¬¬6~10å',
            'å®šä½èƒ†_1~5å': 'å®šä½èƒ†_ç¬¬1~5å',
            'å®šä½èƒ†_6~10å': 'å®šä½èƒ†_ç¬¬6~10å',
            
            # å¤§å°å•åŒç©æ³•å˜ä½“
            'å¤§å°å•åŒ': 'ä¸¤é¢',
            'å¤§å°': 'å¤§å°',
            'å•åŒ': 'å•åŒ',
            
            # é¾™è™ç©æ³•å˜ä½“
            'é¾™è™æ–—': 'é¾™è™',
            'å† äºšé¾™è™': 'é¾™è™_å† å†›',
            'å† å†›é¾™è™': 'é¾™è™_å† å†›',
            
            # æ—¶æ—¶å½©å®šä½èƒ†å˜ä½“
            'å®šä½_ä¸‡ä½': 'å®šä½_ä¸‡ä½',
            'å®šä½_åƒä½': 'å®šä½_åƒä½', 
            'å®šä½_ç™¾ä½': 'å®šä½_ç™¾ä½',
            'å®šä½_åä½': 'å®šä½_åä½',
            'å®šä½_ä¸ªä½': 'å®šä½_ä¸ªä½',
            'ä¸‡ä½': 'å®šä½_ä¸‡ä½',
            'åƒä½': 'å®šä½_åƒä½',
            'ç™¾ä½': 'å®šä½_ç™¾ä½',
            'åä½': 'å®šä½_åä½',
            'ä¸ªä½': 'å®šä½_ä¸ªä½',
            
            # å…­åˆå½©ç©æ³•å˜ä½“
            'ç‰¹ç A': 'ç‰¹ç ',
            'ç‰¹ç B': 'ç‰¹ç ', 
            'æ­£ç A': 'æ­£ç ',
            'æ­£ç B': 'æ­£ç ',
            'æ­£ç 1': 'æ­£1ç‰¹',
            'æ­£ç 2': 'æ­£2ç‰¹',
            'æ­£ç 3': 'æ­£3ç‰¹',
            'æ­£ç 4': 'æ­£4ç‰¹',
            'æ­£ç 5': 'æ­£5ç‰¹',
            'æ­£ç 6': 'æ­£6ç‰¹',
            
            # ä¸‰è‰²å½©
            'æ­£ç ': 'æ­£ç ',
            'ä¸¤é¢': 'ä¸¤é¢',
            'è‰²æ³¢': 'è‰²æ³¢',
            'ç‰¹ç ': 'ç‰¹ç '
        }
        return mapping
    
    def normalize_category(self, category):
        """ç»Ÿä¸€ç©æ³•åˆ†ç±»åç§°"""
        category_str = str(category).strip()
        
        # ç›´æ¥æ˜ å°„
        if category_str in self.category_mapping:
            return self.category_mapping[category_str]
        
        # å…³é”®è¯åŒ¹é…
        for key, value in self.category_mapping.items():
            if key in category_str:
                return value
        
        category_lower = category_str.lower()
        
        # PK10/èµ›è½¦æ™ºèƒ½åŒ¹é… - è¡¥å……æ›´å¤šå˜ä½“
        if any(word in category_lower for word in ['å®šä½èƒ†_ç¬¬1~5å', 'å®šä½èƒ†1~5', 'å®šä½èƒ†1-5']):
            return 'å®šä½èƒ†_ç¬¬1~5å'
        elif any(word in category_lower for word in ['å®šä½èƒ†_ç¬¬6~10å', 'å®šä½èƒ†6~10', 'å®šä½èƒ†6-10']):
            return 'å®šä½èƒ†_ç¬¬6~10å'
        elif any(word in category_lower for word in ['1-5å', '1~5å', '1-5', '1~5']):
            return '1-5å'
        elif any(word in category_lower for word in ['6-10å', '6~10å', '6-10', '6~10']):
            return '6-10å'
        elif any(word in category_lower for word in ['å† å†›', 'ç¬¬ä¸€å', 'ç¬¬1å', '1st']):
            return 'å† å†›'
        elif any(word in category_lower for word in ['äºšå†›', 'ç¬¬äºŒå', 'ç¬¬2å', '2nd']):
            return 'äºšå†›'
        elif any(word in category_lower for word in ['ç¬¬ä¸‰å', 'ç¬¬3å', 'å­£å†›', '3rd']):
            return 'ç¬¬ä¸‰å'
        elif any(word in category_lower for word in ['ç¬¬å››å', 'ç¬¬4å', '4th']):
            return 'ç¬¬å››å'
        elif any(word in category_lower for word in ['ç¬¬äº”å', 'ç¬¬5å', '5th']):
            return 'ç¬¬äº”å'
        elif any(word in category_lower for word in ['ç¬¬å…­å', 'ç¬¬6å', '6th']):
            return 'ç¬¬å…­å'
        elif any(word in category_lower for word in ['ç¬¬ä¸ƒå', 'ç¬¬7å', '7th']):
            return 'ç¬¬ä¸ƒå'
        elif any(word in category_lower for word in ['ç¬¬å…«å', 'ç¬¬8å', '8th']):
            return 'ç¬¬å…«å'
        elif any(word in category_lower for word in ['ç¬¬ä¹å', 'ç¬¬9å', '9th']):
            return 'ç¬¬ä¹å'
        elif any(word in category_lower for word in ['ç¬¬åå', 'ç¬¬10å', '10th']):
            return 'ç¬¬åå'
        elif any(word in category_lower for word in ['å‰ä¸€']):
            return 'å† å†›'  # å‰ä¸€å°±æ˜¯å† å†›
        
        # æ—¶æ—¶å½©å®šä½èƒ†æ™ºèƒ½åŒ¹é…
        elif any(word in category_lower for word in ['ä¸‡ä½', 'ç¬¬ä¸€ä½', 'ç¬¬ä¸€çƒ']):
            return 'å®šä½_ä¸‡ä½'
        elif any(word in category_lower for word in ['åƒä½', 'ç¬¬äºŒä½', 'ç¬¬äºŒçƒ']):
            return 'å®šä½_åƒä½'
        elif any(word in category_lower for word in ['ç™¾ä½', 'ç¬¬ä¸‰ä½', 'ç¬¬ä¸‰çƒ']):
            return 'å®šä½_ç™¾ä½'
        elif any(word in category_lower for word in ['åä½', 'ç¬¬å››ä½', 'ç¬¬å››çƒ']):
            return 'å®šä½_åä½'
        elif any(word in category_lower for word in ['ä¸ªä½', 'ç¬¬äº”ä½', 'ç¬¬äº”çƒ']):
            return 'å®šä½_ä¸ªä½'
        elif any(word in category_lower for word in ['å®šä½èƒ†']):
            return 'å®šä½èƒ†'
        
        # å…­åˆå½©æ™ºèƒ½åŒ¹é…
        elif any(word in category_lower for word in ['ç‰¹ç ']):
            return 'ç‰¹ç '
        elif any(word in category_lower for word in ['æ­£ç ']):
            return 'æ­£ç '
        elif any(word in category_lower for word in ['æ­£ç‰¹', 'æ­£ç›ç‰¹']):
            return 'æ­£ç‰¹'
        elif any(word in category_lower for word in ['å°¾æ•°']):
            return 'å°¾æ•°'
        elif any(word in category_lower for word in ['å¹³ç‰¹']):
            return 'å¹³ç‰¹'
        elif any(word in category_lower for word in ['ç‰¹è‚–']):
            return 'ç‰¹è‚–'
        elif any(word in category_lower for word in ['ä¸€è‚–']):
            return 'ä¸€è‚–'
        elif any(word in category_lower for word in ['è¿è‚–']):
            return 'è¿è‚–'
        elif any(word in category_lower for word in ['è¿å°¾']):
            return 'è¿å°¾'
        elif any(word in category_lower for word in ['é¾™è™']):
            return 'é¾™è™'
        elif any(word in category_lower for word in ['äº”è¡Œ']):
            return 'äº”è¡Œ'
        elif any(word in category_lower for word in ['è‰²æ³¢', 'ä¸ƒè‰²æ³¢', 'æ³¢è‰²']):  # ç»Ÿä¸€è‰²æ³¢è¯†åˆ«
            return 'è‰²æ³¢'
        elif any(word in category_lower for word in ['åŠæ³¢']):
            return 'åŠæ³¢'
        
        # å¿«ä¸‰æ™ºèƒ½åŒ¹é… - å¢å¼ºä¸‰å†›è¯†åˆ«
        elif any(word in category_lower for word in ['å’Œå€¼', 'ç‚¹æ•°']):
            return 'å’Œå€¼'
        elif any(word in category_lower for word in ['ç‹¬èƒ†', 'ä¸‰å†›', 'ä¸‰è»']):  # å¢å¼ºä¸‰å†›è¯†åˆ«
            return 'ç‹¬èƒ†'
        elif any(word in category_lower for word in ['äºŒä¸åŒå·']):
            return 'äºŒä¸åŒå·'
        elif any(word in category_lower for word in ['ä¸‰ä¸åŒå·']):
            return 'ä¸‰ä¸åŒå·'
        
        return category_str

# ==================== æ›¿æ¢ï¼šç»Ÿä¸€åˆ†æå™¨ ====================
class UnifiedAnalyzer:
    """ç»Ÿä¸€åˆ†æå™¨ - å¤„ç†æ‰€æœ‰å½©ç§"""
    
    def __init__(self):
        self.content_parser = ContentParser()
        self.normalizer = PlayCategoryNormalizer()
        self.data_analyzer = DataAnalyzer()
        self.threshold_manager = PrecisionThresholdManager()
        self.seen_records = set()
    
    def analyze_all_patterns(self, df):
        """ç»Ÿä¸€åˆ†æå…¥å£"""
        all_results = {}
        
        # é‡ç½®ç¼“å­˜
        self.seen_records = set()
        
        # ä½¿ç”¨è¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # æŒ‰å½©ç§ç±»å‹åˆ†åˆ«åˆ†æ
        lottery_types = ['LHC', 'K3', 'PK10', 'SSC', '3D', 'THREE_COLOR']
        
        for i, lottery_type in enumerate(lottery_types):
            status_text.text(f"æ­£åœ¨åˆ†æ {lottery_type}...")
            
            df_target = self._filter_by_lottery_type(df, lottery_type)
            if len(df_target) > 0:
                lottery_results = self._analyze_lottery_type(df_target, lottery_type)
                all_results[lottery_type] = lottery_results
            
            progress_bar.progress((i + 1) / len(lottery_types))
        
        status_text.text("åˆ†æå®Œæˆï¼")
        return all_results
    
    def _filter_by_lottery_type(self, df, lottery_type):
        """è¿‡æ»¤æŒ‡å®šå½©ç§ç±»å‹çš„æ•°æ®"""
        return df[df['å½©ç§'].apply(self._identify_lottery_type) == lottery_type]
    
    def _identify_lottery_type(self, lottery_name):
        """è¯†åˆ«å½©ç§ç±»å‹ - å¤ç”¨åŸæœ‰é€»è¾‘"""
        lottery_str = str(lottery_name).strip()
        
        for lottery_type, config in LOTTERY_CONFIGS.items():
            for lottery in config['lotteries']:
                if lottery in lottery_str:
                    return lottery_type
        
        lottery_lower = lottery_str.lower()
        
        if any(word in lottery_lower for word in ['pk', 'é£è‰‡', 'èµ›è½¦', 'å¹¸è¿10', 'pk10', 'pkæ‹¾', 'èµ›è»Š']):
            return 'PK10'
        elif any(word in lottery_lower for word in ['å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰']):
            return 'K3'
        elif any(word in lottery_lower for word in ['å…­åˆ', 'lhc', 'å…­åˆå½©', 'â‘¥åˆ', '6åˆ']):
            return 'LHC'
        elif any(word in lottery_lower for word in ['æ—¶æ—¶å½©', 'ssc', 'åˆ†åˆ†å½©', 'æ—¶æ—¶å½©', 'æ™‚æ™‚å½©']):
            return 'SSC'
        elif any(word in lottery_lower for word in ['ä¸‰è‰²', 'ä¸‰è‰²å½©', 'ä¸‰è‰²çƒ']):
            return 'THREE_COLOR'
        elif any(word in lottery_lower for word in ['æ’åˆ—ä¸‰', 'æ’åˆ—3', 'ç¦å½©3d', '3d', 'æé€Ÿ3d', 'æ’åˆ—', 'p3', 'pä¸‰']):
            return '3D'
        
        return None
    
    def _analyze_lottery_type(self, df, lottery_type):
        """åˆ†ææŒ‡å®šå½©ç§ç±»å‹"""
        results = defaultdict(list)
        
        # æŒ‰è´¦æˆ·æœŸå·åˆ†ç»„åˆ†æ
        grouped = df.groupby(['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·'])
        
        for (account, lottery, period), group in grouped:
            # æŒ‰ç©æ³•åˆ†ç±»åˆ†åˆ«åˆ†æ
            for play_category, category_group in group.groupby('ç©æ³•åˆ†ç±»'):
                category_results = self._analyze_by_play_category(
                    account, lottery, period, category_group, play_category, lottery_type
                )
                for result_type, records in category_results.items():
                    results[result_type].extend(records)
        
        return results
    
    def _analyze_by_play_category(self, account, lottery, period, group, play_category, lottery_type):
        """æŒ‰ç©æ³•åˆ†ç±»åˆ†æ"""
        # è·¯ç”±åˆ°å¯¹åº”çš„åˆ†ææ–¹æ³•
        analysis_routes = {
            'LHC': self._analyze_lhc_play_category,
            'K3': self._analyze_k3_play_category,
            'PK10': self._analyze_pk10_play_category,
            'SSC': self._analyze_ssc_play_category, 
            '3D': self._analyze_3d_play_category,
            'THREE_COLOR': self._analyze_three_color_play_category
        }
        
        if lottery_type in analysis_routes:
            return analysis_routes[lottery_type](account, lottery, period, group, play_category)
        
        return defaultdict(list)
    
    # ==================== å…­åˆå½©åˆ†ææ–¹æ³• ====================
    def _analyze_lhc_play_category(self, account, lottery, period, group, play_category):
        """å…­åˆå½©ç©æ³•åˆ†ç±»åˆ†æ"""
        results = defaultdict(list)
        
        # å…­åˆå½©ç©æ³•è·¯ç”±
        lhc_analysis_methods = {
            'ç‰¹ç ': self._analyze_lhc_tema,
            'æ­£ç ': self._analyze_lhc_zhengma,
            'æ­£1ç‰¹': self._analyze_lhc_zhengte,
            'æ­£2ç‰¹': self._analyze_lhc_zhengte,
            'æ­£3ç‰¹': self._analyze_lhc_zhengte,
            'æ­£4ç‰¹': self._analyze_lhc_zhengte,
            'æ­£5ç‰¹': self._analyze_lhc_zhengte,
            'æ­£6ç‰¹': self._analyze_lhc_zhengte,
            'å°¾æ•°': self._analyze_lhc_tail,
            'ç‰¹å°¾': self._analyze_lhc_tail,
            'å…¨å°¾': self._analyze_lhc_tail,
            'å¹³ç‰¹': self._analyze_lhc_zodiac,
            'ç‰¹è‚–': self._analyze_lhc_zodiac,
            'ä¸€è‚–': self._analyze_lhc_zodiac,
            'ä¸¤é¢': self._analyze_lhc_two_sides,
            'è‰²æ³¢': self._analyze_lhc_wave,
            'åŠæ³¢': self._analyze_lhc_banbo,
            'äº”è¡Œ': self._analyze_lhc_five_elements,
            'äºŒè¿è‚–': self._analyze_lhc_lianxiao,
            'ä¸‰è¿è‚–': self._analyze_lhc_lianxiao,
            'å››è¿è‚–': self._analyze_lhc_lianxiao,
            'äº”è¿è‚–': self._analyze_lhc_lianxiao,
            'äºŒè¿å°¾': self._analyze_lhc_lianwei,
            'ä¸‰è¿å°¾': self._analyze_lhc_lianwei,
            'å››è¿å°¾': self._analyze_lhc_lianwei,
            'äº”è¿å°¾': self._analyze_lhc_lianwei
        }
        
        if play_category in lhc_analysis_methods:
            method = lhc_analysis_methods[play_category]
            return method(account, lottery, period, group, play_category)
        
        return defaultdict(list)
    
    def _analyze_lhc_tema(self, account, lottery, period, group, play_category):
        """å…­åˆå½©ç‰¹ç åˆ†æ"""
        return self._analyze_number_bets(account, lottery, period, group, play_category, 'LHC', 'ç‰¹ç å¤šç ')
    
    def _analyze_lhc_zhengma(self, account, lottery, period, group, play_category):
        """å…­åˆå½©æ­£ç åˆ†æ"""
        return self._analyze_number_bets(account, lottery, period, group, play_category, 'LHC', 'æ­£ç å¤šç ')
    
    def _analyze_lhc_zhengte(self, account, lottery, period, group, play_category):
        """å…­åˆå½©æ­£ç ç‰¹åˆ†æ"""
        results = defaultdict(list)
        
        all_numbers = set()
        all_bets = defaultdict(set)
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            clean_content = self._parse_lhc_content(content)
            
            numbers = self.data_analyzer.extract_numbers_from_content(clean_content, 1, 49)
            all_numbers.update(numbers)
            
            two_sides_analysis = self.data_analyzer.extract_lhc_two_sides_content(content)
            for bet_type, bets in two_sides_analysis.items():
                all_bets[bet_type].update(bets)
        
        # å¤šç æ£€æµ‹
        threshold = self.threshold_manager.get_threshold('LHC', play_category, 'multi_number')
        if len(all_numbers) >= threshold:
            record = self._create_number_record(
                account, lottery, period, play_category, all_numbers, 'æ­£ç‰¹å¤šç '
            )
            self._add_unique_result(results, 'æ­£ç‰¹å¤šç ', record)
        
        # çŸ›ç›¾æ£€æµ‹
        conflicts = []
        wave_set = all_bets.get('wave', set())
        
        if 'å¤§' in all_bets.get('normal_size', set()) and 'å°' in all_bets.get('normal_size', set()):
            conflicts.append('å¤§å°çŸ›ç›¾')
        if 'å•' in all_bets.get('parity', set()) and 'åŒ' in all_bets.get('parity', set()):
            conflicts.append('å•åŒçŸ›ç›¾')
        if len(wave_set) >= THRESHOLD_CONFIG['LHC']['wave_bet']:
            conflicts.append('æ³¢è‰²å¤šç»„æŠ•æ³¨')
        
        if conflicts:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'æ­£ç‰¹çŸ›ç›¾')
            }
            self._add_unique_result(results, 'æ­£ç‰¹çŸ›ç›¾', record)
        
        return results
    
    def _analyze_lhc_tail(self, account, lottery, period, group, play_category):
        """å…­åˆå½©å°¾æ•°åˆ†æ"""
        results = defaultdict(list)
        
        all_tails = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            clean_content = self._parse_lhc_content(content)
            tails = self.data_analyzer.extract_tails_from_content(clean_content)
            all_tails.update(tails)
        
        # æ ¹æ®ä¸åŒçš„å°¾æ•°ç©æ³•ä½¿ç”¨ä¸åŒçš„ç»“æœé”®
        if play_category == 'å°¾æ•°':
            result_key = 'å°¾æ•°å¤šç '
        elif play_category == 'ç‰¹å°¾':
            result_key = 'ç‰¹å°¾å¤šå°¾'
        elif play_category == 'å…¨å°¾':
            result_key = 'å…¨å°¾å¤šå°¾'
        else:
            result_key = 'å°¾æ•°å¤šç '
        
        threshold = self.threshold_manager.get_threshold('LHC', play_category, 'multi_tail')
        if len(all_tails) >= threshold:
            bet_content = ', '.join([f"{tail}å°¾" for tail in sorted(all_tails)])
            
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': f"{play_category}ï¼ˆ{len(all_tails)}å°¾ï¼‰",
                'å°¾æ•°æ•°é‡': len(all_tails),
                'æŠ•æ³¨å†…å®¹': bet_content,
                'æ’åºæƒé‡': self._calculate_sort_weight({'å°¾æ•°æ•°é‡': len(all_tails)}, result_key)
            }
            self._add_unique_result(results, result_key, record)
        
        return results
    
    def _analyze_lhc_zodiac(self, account, lottery, period, group, play_category):
        """å…­åˆå½©ç”Ÿè‚–åˆ†æ"""
        results = defaultdict(list)
        
        all_zodiacs = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            clean_content = self._parse_lhc_content(content)
            zodiacs = self.data_analyzer.extract_zodiacs_from_content(clean_content)
            all_zodiacs.update(zodiacs)
        
        threshold = self.threshold_manager.get_threshold('LHC', play_category, 'zodiac_play')
        if len(all_zodiacs) >= threshold:
            # æ ¹æ®ç©æ³•åˆ†ç±»ç¡®å®šç»“æœé”®
            if play_category == 'å¹³ç‰¹':
                result_key = 'å¹³ç‰¹å¤šè‚–'
            elif play_category == 'ç‰¹è‚–':
                result_key = 'ç‰¹è‚–å¤šè‚–'
            elif play_category == 'ä¸€è‚–':
                result_key = 'ä¸€è‚–å¤šè‚–'
            else:
                result_key = 'ç”Ÿè‚–å¤šè‚–'
            
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'ç”Ÿè‚–æ•°é‡': len(all_zodiacs),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(all_zodiacs)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'ç”Ÿè‚–æ•°é‡': len(all_zodiacs)}, result_key)
            }
            self._add_unique_result(results, result_key, record)
        
        return results
    
    def _analyze_lhc_two_sides(self, account, lottery, period, group, play_category):
        """å…­åˆå½©ä¸¤é¢ç©æ³•åˆ†æ"""
        results = defaultdict(list)
        
        all_bets = {
            'range_bet': set(),
            'normal_size': set(),
            'tail_size': set(),
            'parity': set(),
            'sum_parity': set(),
            'animal_type': set(),
            'zodiac': set(),
            'wave': set()
        }
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            two_sides_analysis = self.data_analyzer.extract_lhc_two_sides_content(content)
            
            for bet_type in two_sides_analysis:
                if bet_type in all_bets:
                    all_bets[bet_type].update(two_sides_analysis[bet_type])
        
        # åŒºé—´å¤šç»„æ£€æµ‹
        if len(all_bets['range_bet']) >= THRESHOLD_CONFIG['LHC']['range_bet']:
            sorted_ranges = sorted(list(all_bets['range_bet']))
            bet_content = ', '.join(sorted_ranges)
            
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'æŠ•æ³¨åŒºé—´æ•°': len(all_bets['range_bet']),
                'æŠ•æ³¨åŒºé—´': sorted_ranges,
                'æŠ•æ³¨å†…å®¹': bet_content,
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨åŒºé—´æ•°': len(all_bets['range_bet'])}, 'åŒºé—´å¤šç»„')
            }
            self._add_unique_result(results, 'åŒºé—´å¤šç»„', record)
        
        # çŸ›ç›¾æ£€æµ‹
        conflict_types = []
        
        if 'å¤§' in all_bets.get('normal_size', set()) and 'å°' in all_bets.get('normal_size', set()):
            conflict_types.append('å¤§å°çŸ›ç›¾')
        if 'å°¾å¤§' in all_bets.get('tail_size', set()) and 'å°¾å°' in all_bets.get('tail_size', set()):
            conflict_types.append('å°¾å¤§å°çŸ›ç›¾')
        if 'å•' in all_bets.get('parity', set()) and 'åŒ' in all_bets.get('parity', set()):
            conflict_types.append('å•åŒçŸ›ç›¾')
        if 'åˆå•' in all_bets.get('sum_parity', set()) and 'åˆåŒ' in all_bets.get('sum_parity', set()):
            conflict_types.append('åˆæ•°å•åŒçŸ›ç›¾')
        if 'å®¶ç¦½' in all_bets.get('animal_type', set()) and 'é‡å…½' in all_bets.get('animal_type', set()):
            conflict_types.append('å®¶ç¦½é‡å…½çŸ›ç›¾')
        
        if conflict_types:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types),
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types)}, 'ä¸¤é¢ç©æ³•çŸ›ç›¾')
            }
            self._add_unique_result(results, 'ä¸¤é¢ç©æ³•çŸ›ç›¾', record)
        
        # æ³¢è‰²æ£€æµ‹
        wave_set = all_bets.get('wave', set())
        if len(wave_set) >= THRESHOLD_CONFIG['LHC']['wave_bet']:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'æŠ•æ³¨æ³¢è‰²æ•°': len(wave_set),
                'æŠ•æ³¨æ³¢è‰²': sorted(list(wave_set)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨æ³¢è‰²æ•°': len(wave_set)}, 'æ³¢è‰²ä¸‰ç»„')
            }
            self._add_unique_result(results, 'æ³¢è‰²ä¸‰ç»„', record)
        
        return results

    def _analyze_lhc_wave(self, account, lottery, period, group, play_category):
        """å…­åˆå½©æ³¢è‰²ç²¾ç¡®åˆ†æ"""
        results = defaultdict(list)
        
        all_wave_bets = set()
        all_banbo_bets = set()
        
        # å®šä¹‰åŠæ³¢æŠ•æ³¨é¡¹
        banbo_items = {
            'çº¢å¤§', 'çº¢å°', 'çº¢å•', 'çº¢åŒ',
            'è“å¤§', 'è“å°', 'è“å•', 'è“åŒ', 
            'ç»¿å¤§', 'ç»¿å°', 'ç»¿å•', 'ç»¿åŒ'
        }
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            clean_content = self._parse_lhc_content(content)
            
            # æå–ä¼ ç»Ÿæ³¢è‰²
            waves = self.data_analyzer.extract_wave_color_from_content(clean_content)
            all_wave_bets.update(waves)
            
            # æå–åŠæ³¢æŠ•æ³¨é¡¹
            for item in banbo_items:
                if item in clean_content:
                    all_banbo_bets.add(item)
        
        # ä¼ ç»Ÿè‰²æ³¢å…¨åŒ…æ£€æµ‹
        traditional_waves = {'çº¢æ³¢', 'è“æ³¢', 'ç»¿æ³¢'}
        if traditional_waves.issubset(all_wave_bets):
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'è¿è§„ç±»å‹': 'è‰²æ³¢å…¨åŒ…',
                'æŠ•æ³¨æ³¢è‰²æ•°': len(traditional_waves),
                'æŠ•æ³¨æ³¢è‰²': sorted(list(traditional_waves)),
                'æŠ•æ³¨å†…å®¹': f"è‰²æ³¢å…¨åŒ…: {', '.join(sorted(traditional_waves))}",
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨æ³¢è‰²æ•°': len(traditional_waves)}, 'è‰²æ³¢å…¨åŒ…')
            }
            self._add_unique_result(results, 'è‰²æ³¢å…¨åŒ…', record)
        
        return results
    
    def _analyze_lhc_banbo(self, account, lottery, period, group, play_category):
        """å…­åˆå½©åŠæ³¢ç²¾ç¡®åˆ†æ"""
        results = defaultdict(list)
        
        all_banbo_bets = set()
        
        # å®šä¹‰åŠæ³¢æŠ•æ³¨é¡¹
        size_full_set = {'çº¢å¤§', 'çº¢å°', 'è“å¤§', 'è“å°', 'ç»¿å¤§', 'ç»¿å°'}
        parity_full_set = {'çº¢å•', 'çº¢åŒ', 'è“å•', 'è“åŒ', 'ç»¿å•', 'ç»¿åŒ'}
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            
            # è§£æç©æ³•-æŠ•æ³¨å†…å®¹æ ¼å¼
            if '-' in content:
                parts = content.split('-', 1)
                bet_content = parts[1].strip()
            else:
                bet_content = content
            
            # æå–æ‰€æœ‰åŠæ³¢æŠ•æ³¨é¡¹
            for bet in size_full_set.union(parity_full_set):
                if bet in bet_content:
                    all_banbo_bets.add(bet)
        
        # å¤§å°å…¨åŒ…æ£€æµ‹
        if size_full_set.issubset(all_banbo_bets):
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'è¿è§„ç±»å‹': 'åŠæ³¢å¤§å°å…¨åŒ…',
                'æŠ•æ³¨åŠæ³¢æ•°': len(size_full_set),
                'æŠ•æ³¨åŠæ³¢': sorted(list(size_full_set)),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(size_full_set)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨åŠæ³¢æ•°': len(size_full_set)}, 'åŠæ³¢å¤§å°å…¨åŒ…')
            }
            self._add_unique_result(results, 'åŠæ³¢å¤§å°å…¨åŒ…', record)
        
        # å•åŒå…¨åŒ…æ£€æµ‹
        if parity_full_set.issubset(all_banbo_bets):
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'è¿è§„ç±»å‹': 'åŠæ³¢å•åŒå…¨åŒ…',
                'æŠ•æ³¨åŠæ³¢æ•°': len(parity_full_set),
                'æŠ•æ³¨åŠæ³¢': sorted(list(parity_full_set)),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(parity_full_set)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨åŠæ³¢æ•°': len(parity_full_set)}, 'åŠæ³¢å•åŒå…¨åŒ…')
            }
            self._add_unique_result(results, 'åŠæ³¢å•åŒå…¨åŒ…', record)
        
        return results
    
    def _analyze_lhc_five_elements(self, account, lottery, period, group, play_category):
        """å…­åˆå½©äº”è¡Œç²¾ç¡®åˆ†æ"""
        results = defaultdict(list)
        
        all_elements = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            clean_content = self._parse_lhc_content(content)
            elements = self.data_analyzer.extract_five_elements_from_content(clean_content)
            all_elements.update(elements)
        
        if len(all_elements) >= THRESHOLD_CONFIG['LHC']['five_elements']:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'æŠ•æ³¨äº”è¡Œæ•°': len(all_elements),
                'æŠ•æ³¨äº”è¡Œ': sorted(list(all_elements)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨äº”è¡Œæ•°': len(all_elements)}, 'äº”è¡Œå¤šç»„')
            }
            self._add_unique_result(results, 'äº”è¡Œå¤šç»„', record)
        
        return results
    
    def _analyze_lhc_lianxiao(self, account, lottery, period, group, play_category):
        """å…­åˆå½©è¿è‚–ç²¾ç¡®åˆ†æ"""
        results = defaultdict(list)
        
        all_zodiacs = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            
            # è§£æç©æ³•-æŠ•æ³¨å†…å®¹æ ¼å¼
            if '-' in content:
                parts = content.split('-', 1)
                bet_content = parts[1].strip()
            else:
                bet_content = content
                
            zodiacs = self.data_analyzer.extract_zodiacs_from_content(bet_content)
            all_zodiacs.update(zodiacs)
        
        # è¿è‚–ç±»å‹é˜ˆå€¼é…ç½®
        lianxiao_thresholds = {
            'äºŒè¿è‚–': 7,
            'ä¸‰è¿è‚–': 7,
            'å››è¿è‚–': 7,
            'äº”è¿è‚–': 8
        }
        
        threshold = lianxiao_thresholds.get(play_category, 6)
        
        if len(all_zodiacs) >= threshold:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': f"{play_category}ï¼ˆ{len(all_zodiacs)}ç”Ÿè‚–ï¼‰",
                'è¿è§„ç±»å‹': f'{play_category}å¤šè‚–',
                'ç”Ÿè‚–æ•°é‡': len(all_zodiacs),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(all_zodiacs)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'ç”Ÿè‚–æ•°é‡': len(all_zodiacs)}, f'{play_category}å¤šè‚–')
            }
            self._add_unique_result(results, f'{play_category}å¤šè‚–', record)
        
        return results
    
    def _analyze_lhc_lianwei(self, account, lottery, period, group, play_category):
        """å…­åˆå½©è¿å°¾ç²¾ç¡®åˆ†æ"""
        results = defaultdict(list)
        
        all_tails = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            tails = self.data_analyzer.extract_tails_from_content(content)
            all_tails.update(tails)
        
        # è¿å°¾ç±»å‹é˜ˆå€¼é…ç½®
        lianwei_thresholds = {
            'äºŒè¿å°¾': 7,
            'ä¸‰è¿å°¾': 7,
            'å››è¿å°¾': 7,
            'äº”è¿å°¾': 8
        }
        
        threshold = lianwei_thresholds.get(play_category, 6)
        
        if len(all_tails) >= threshold:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': f"{play_category}ï¼ˆ{len(all_tails)}å°¾ï¼‰",
                'è¿è§„ç±»å‹': f'{play_category}å¤šå°¾',
                'å°¾æ•°æ•°é‡': len(all_tails),
                'æŠ•æ³¨å†…å®¹': ', '.join([f"{tail}å°¾" for tail in sorted(all_tails)]),
                'æ’åºæƒé‡': self._calculate_sort_weight({'å°¾æ•°æ•°é‡': len(all_tails)}, f'{play_category}å¤šå°¾')
            }
            self._add_unique_result(results, f'{play_category}å¤šå°¾', record)
        
        return results

    # ==================== å¿«ä¸‰åˆ†ææ–¹æ³• ====================
    def _analyze_k3_play_category(self, account, lottery, period, group, play_category):
        """å¿«ä¸‰ç©æ³•åˆ†ç±»åˆ†æ"""
        results = defaultdict(list)
        
        # å¿«ä¸‰ç©æ³•è·¯ç”±
        k3_analysis_methods = {
            'å’Œå€¼': self._analyze_k3_hezhi,
            'å’Œå€¼_å¤§å°å•åŒ': self._analyze_k3_hezhi,
            'ç‹¬èƒ†': self._analyze_k3_dudan,
            'äºŒä¸åŒå·': self._analyze_k3_different,
            'ä¸‰ä¸åŒå·': self._analyze_k3_different,
            'ä¸¤é¢': self._analyze_k3_two_sides
        }
        
        if play_category in k3_analysis_methods:
            method = k3_analysis_methods[play_category]
            return method(account, lottery, period, group, play_category)
        
        return defaultdict(list)
    
    def _analyze_k3_hezhi(self, account, lottery, period, group, play_category):
        """å¿«ä¸‰å’Œå€¼åˆ†æ"""
        results = defaultdict(list)
        
        all_numbers = set()
        all_contents = []
        has_big = False
        has_small = False
        has_single = False
        has_double = False
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            
            # æå–æ•°å­—
            numbers = self.data_analyzer.extract_numbers_from_content(
                content,
                LOTTERY_CONFIGS['K3']['hezhi_min'],
                LOTTERY_CONFIGS['K3']['hezhi_max']
            )
            all_numbers.update(numbers)
            all_contents.append(content)
            
            # æ£€æŸ¥å¤§å°å•åŒ
            content_lower = content.lower()
            if 'å¤§' in content_lower:
                has_big = True
            if 'å°' in content_lower:
                has_small = True
            if 'å•' in content_lower:
                has_single = True
            if 'åŒ' in content_lower:
                has_double = True
        
        # å’Œå€¼å¤šç æ£€æµ‹
        threshold = self.threshold_manager.get_threshold('K3', play_category, 'hezhi_multi_number')
        if len(all_numbers) >= threshold:
            bet_content = ', '.join([str(num) for num in sorted(all_numbers)])
            
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'å·ç æ•°é‡': len(all_numbers),
                'æŠ•æ³¨å†…å®¹': bet_content,
                'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'å’Œå€¼å¤šç ')
            }
            self._add_unique_result(results, 'å’Œå€¼å¤šç ', record)
            return results  # é¿å…é‡å¤è®°å½•
        
        # å’Œå€¼çŸ›ç›¾æ£€æµ‹
        conflict_types = []
        if has_big and has_small:
            conflict_types.append('å¤§å°')
        if has_single and has_double:
            conflict_types.append('å•åŒ')
        
        if conflict_types:
            bet_content_parts = []
            if has_big:
                bet_content_parts.append('å¤§')
            if has_small:
                bet_content_parts.append('å°')
            if has_single:
                bet_content_parts.append('å•')
            if has_double:
                bet_content_parts.append('åŒ')
            bet_content = ', '.join(bet_content_parts)
            
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types),
                'æŠ•æ³¨å†…å®¹': bet_content,
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types)}, 'å’Œå€¼çŸ›ç›¾')
            }
            self._add_unique_result(results, 'å’Œå€¼çŸ›ç›¾', record)
        
        # å’Œå€¼å¤§å°çŸ›ç›¾æ£€æµ‹
        if all_numbers and len(all_numbers) < threshold:
            small_values = [num for num in all_numbers if 3 <= num <= 10]
            big_values = [num for num in all_numbers if 11 <= num <= 18]
            single_values = [num for num in all_numbers if num % 2 == 1]
            double_values = [num for num in all_numbers if num % 2 == 0]
            
            # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„çŸ›ç›¾
            possible_contradictions = []
            
            if has_small and len(big_values) >= THRESHOLD_CONFIG['K3']['value_size_contradiction']:
                contradiction_value = len(big_values)
                description = f"æŠ•æ³¨å°ä½†åŒ…å«å¤šä¸ªå¤§å·ç (å°{len(small_values)}ä¸ª,å¤§{len(big_values)}ä¸ª)"
                possible_contradictions.append(('å¤§å°çŸ›ç›¾', description, contradiction_value))
            
            if has_big and len(small_values) >= THRESHOLD_CONFIG['K3']['value_size_contradiction']:
                contradiction_value = len(small_values)
                description = f"æŠ•æ³¨å¤§ä½†åŒ…å«å¤šä¸ªå°å·ç (å°{len(small_values)}ä¸ª,å¤§{len(big_values)}ä¸ª)"
                possible_contradictions.append(('å¤§å°çŸ›ç›¾', description, contradiction_value))
            
            if has_single and len(double_values) >= THRESHOLD_CONFIG['K3']['value_size_contradiction']:
                contradiction_value = len(double_values)
                description = f"æŠ•æ³¨å•ä½†åŒ…å«å¤šä¸ªåŒå·ç (å•{len(single_values)}ä¸ª,åŒ{len(double_values)}ä¸ª)"
                possible_contradictions.append(('å•åŒçŸ›ç›¾', description, contradiction_value))
            
            if has_double and len(single_values) >= THRESHOLD_CONFIG['K3']['value_size_contradiction']:
                contradiction_value = len(single_values)
                description = f"æŠ•æ³¨åŒä½†åŒ…å«å¤šä¸ªå•å·ç (å•{len(single_values)}ä¸ª,åŒ{len(double_values)}ä¸ª)"
                possible_contradictions.append(('å•åŒçŸ›ç›¾', description, contradiction_value))
            
            if possible_contradictions:
                possible_contradictions.sort(key=lambda x: x[2], reverse=True)
                best_contradiction = possible_contradictions[0]
                contradiction_type, contradiction_desc, contradiction_value = best_contradiction
                
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': play_category,
                    'çŸ›ç›¾ç±»å‹': contradiction_desc,
                    'çŸ›ç›¾å€¼': contradiction_value,
                    'å¤§å·ç æ•°é‡': len(big_values),
                    'å°å·ç æ•°é‡': len(small_values),
                    'å•å·ç æ•°é‡': len(single_values),
                    'åŒå·ç æ•°é‡': len(double_values),
                    'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾å€¼': contradiction_value}, 'å’Œå€¼å¤§å°çŸ›ç›¾')
                }
                self._add_unique_result(results, 'å’Œå€¼å¤§å°çŸ›ç›¾', record)
        
        return results
    
    def _analyze_k3_dudan(self, account, lottery, period, group, play_category):
        """å¿«ä¸‰ç‹¬èƒ†åˆ†æ"""
        results = defaultdict(list)
        
        # èšåˆåŒä¸€è´¦æˆ·åŒä¸€æœŸå·çš„æ‰€æœ‰ç‹¬èƒ†æŠ•æ³¨
        all_numbers = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            numbers = self.data_analyzer.extract_numbers_from_content(content, 1, 6)
            all_numbers.update(numbers)
        
        threshold = self.threshold_manager.get_threshold('K3', play_category, 'dudan_multi_number')
        if len(all_numbers) >= threshold:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'å·ç æ•°é‡': len(all_numbers),
                'æŠ•æ³¨å†…å®¹': f"èšåˆæŠ•æ³¨: {', '.join([str(num) for num in sorted(all_numbers)])}",
                'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'ç‹¬èƒ†å¤šç ')
            }
            self._add_unique_result(results, 'ç‹¬èƒ†å¤šç ', record)
        
        return results
    
    def _analyze_k3_different(self, account, lottery, period, group, play_category):
        """å¿«ä¸‰ä¸åŒå·åˆ†æ"""
        results = defaultdict(list)
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            numbers = self.data_analyzer.extract_numbers_from_content(content, 1, 6)
            
            if len(numbers) == 6:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': play_category,
                    'å·ç æ•°é‡': len(numbers),
                    'æŠ•æ³¨å†…å®¹': ', '.join([str(num) for num in sorted(numbers)]),
                    'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(numbers)}, 'ä¸åŒå·å…¨åŒ…')
                }
                self._add_unique_result(results, 'ä¸åŒå·å…¨åŒ…', record)
        
        return results
    
    def _analyze_k3_two_sides(self, account, lottery, period, group, play_category):
        """å¿«ä¸‰ä¸¤é¢åˆ†æ"""
        results = defaultdict(list)
        
        has_big = False
        has_small = False
        has_single = False
        has_double = False
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            content_lower = content.lower()
            
            if 'å¤§' in content_lower:
                has_big = True
            if 'å°' in content_lower:
                has_small = True
            if 'å•' in content_lower:
                has_single = True
            if 'åŒ' in content_lower:
                has_double = True
        
        conflict_types = []
        if has_big and has_small:
            conflict_types.append('å¤§å°')
        if has_single and has_double:
            conflict_types.append('å•åŒ')
        
        if conflict_types:
            bet_content_parts = []
            if has_big:
                bet_content_parts.append('å¤§')
            if has_small:
                bet_content_parts.append('å°')
            if has_single:
                bet_content_parts.append('å•')
            if has_double:
                bet_content_parts.append('åŒ')
            bet_content = ', '.join(bet_content_parts)
            
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types),
                'æŠ•æ³¨å†…å®¹': bet_content,
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types)}, 'ä¸¤é¢çŸ›ç›¾')
            }
            self._add_unique_result(results, 'ä¸¤é¢çŸ›ç›¾', record)
        
        return results

    # ==================== PK10/èµ›è½¦åˆ†ææ–¹æ³• ====================
    def _analyze_pk10_play_category(self, account, lottery, period, group, play_category):
        """PK10ç©æ³•åˆ†ç±»åˆ†æ"""
        results = defaultdict(list)
        
        # PK10ç©æ³•è·¯ç”±
        pk10_analysis_methods = {
            'å† å†›': self._analyze_pk10_position,
            'äºšå†›': self._analyze_pk10_position,
            'ç¬¬ä¸‰å': self._analyze_pk10_position,
            'ç¬¬å››å': self._analyze_pk10_position,
            'ç¬¬äº”å': self._analyze_pk10_position,
            'ç¬¬å…­å': self._analyze_pk10_position,
            'ç¬¬ä¸ƒå': self._analyze_pk10_position,
            'ç¬¬å…«å': self._analyze_pk10_position,
            'ç¬¬ä¹å': self._analyze_pk10_position,
            'ç¬¬åå': self._analyze_pk10_position,
            'å‰ä¸€': self._analyze_pk10_position,
            '1-5å': self._analyze_pk10_range,
            '6-10å': self._analyze_pk10_range,
            'å®šä½èƒ†': self._analyze_pk10_dingwei,
            'å®šä½èƒ†_ç¬¬1~5å': self._analyze_pk10_dingwei,
            'å®šä½èƒ†_ç¬¬6~10å': self._analyze_pk10_dingwei,
            'å† äºšå’Œ': self._analyze_pk10_gyh,
            'å† äºšå’Œ_å¤§å°å•åŒ': self._analyze_pk10_gyh,
            'å† äºšå’Œ_å’Œå€¼': self._analyze_pk10_gyh,
            'ä¸¤é¢': self._analyze_pk10_two_sides,
            'åŒé¢': self._analyze_pk10_two_sides,
            'å¤§å°_å† å†›': self._analyze_pk10_independent,
            'å¤§å°_äºšå†›': self._analyze_pk10_independent,
            'å¤§å°_å­£å†›': self._analyze_pk10_independent,
            'å•åŒ_å† å†›': self._analyze_pk10_independent,
            'å•åŒ_äºšå†›': self._analyze_pk10_independent,
            'å•åŒ_å­£å†›': self._analyze_pk10_independent,
            'é¾™è™_å† å†›': self._analyze_pk10_dragon_tiger,
            'é¾™è™_äºšå†›': self._analyze_pk10_dragon_tiger,
            'é¾™è™_å­£å†›': self._analyze_pk10_dragon_tiger
        }
        
        if play_category in pk10_analysis_methods:
            method = pk10_analysis_methods[play_category]
            return method(account, lottery, period, group, play_category)
        
        return defaultdict(list)
    
    def _analyze_pk10_position(self, account, lottery, period, group, play_category):
        """PK10ä½ç½®å·ç åˆ†æ"""
        results = defaultdict(list)
        
        all_numbers = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            
            # ä½¿ç”¨ç»Ÿä¸€è§£æå™¨è§£æPK10å†…å®¹
            bets_by_position = ContentParser.parse_pk10_content(content)
            
            for position, numbers in bets_by_position.items():
                # å¦‚æœè§£æå‡ºçš„ä½ç½®åŒ¹é…å½“å‰ç©æ³•åˆ†ç±»ï¼Œåˆ™æ”¶é›†å·ç 
                if self._is_position_match(position, play_category):
                    all_numbers.update(numbers)
        
        # å¤šç æ£€æµ‹
        threshold = self.threshold_manager.get_threshold('PK10', play_category, 'multi_number')
        if len(all_numbers) >= threshold:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'ä½ç½®': play_category,
                'å·ç æ•°é‡': len(all_numbers),
                'æŠ•æ³¨å†…å®¹': f"{play_category}-{','.join([f'{num:02d}' for num in sorted(all_numbers)])}",
                'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'è¶…ç ')
            }
            self._add_unique_result(results, 'è¶…ç ', record)
        
        return results
    
    def _is_position_match(self, position, play_category):
        """æ£€æŸ¥ä½ç½®æ˜¯å¦åŒ¹é…ç©æ³•åˆ†ç±»"""
        position_mapping = {
            'å† å†›': ['å† å†›', 'å‰ä¸€'],
            'äºšå†›': ['äºšå†›'],
            'ç¬¬ä¸‰å': ['ç¬¬ä¸‰å', 'å­£å†›'],
            'ç¬¬å››å': ['ç¬¬å››å'],
            'ç¬¬äº”å': ['ç¬¬äº”å'],
            'ç¬¬å…­å': ['ç¬¬å…­å'],
            'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå'],
            'ç¬¬å…«å': ['ç¬¬å…«å'],
            'ç¬¬ä¹å': ['ç¬¬ä¹å'],
            'ç¬¬åå': ['ç¬¬åå']
        }
        
        for key, values in position_mapping.items():
            if play_category == key and position in values:
                return True
        
        return play_category == position
    
    def _analyze_pk10_range(self, account, lottery, period, group, play_category):
        """PK10èŒƒå›´åˆ†æï¼ˆ1-5åã€6-10åï¼‰"""
        results = defaultdict(list)
        
        all_numbers = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            numbers = self.data_analyzer.extract_numbers_from_content(content, 1, 10, is_pk10=True)
            all_numbers.update(numbers)
        
        threshold = self.threshold_manager.get_threshold('PK10', play_category, 'multi_number')
        if len(all_numbers) >= threshold:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'å·ç æ•°é‡': len(all_numbers),
                'æŠ•æ³¨å†…å®¹': f"{play_category}: {', '.join([f'{num:02d}' for num in sorted(all_numbers)])}",
                'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'è¶…ç ')
            }
            self._add_unique_result(results, 'è¶…ç ', record)
        
        return results
    
    def _analyze_pk10_dingwei(self, account, lottery, period, group, play_category):
        """PK10å®šä½èƒ†åˆ†æ"""
        results = defaultdict(list)
        
        position_numbers = defaultdict(set)
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            
            # ä½¿ç”¨ç»Ÿä¸€è§£æå™¨è§£æå®šä½èƒ†å†…å®¹
            bets_by_position = ContentParser.parse_pk10_content(content)
            
            for position, numbers in bets_by_position.items():
                position_numbers[position].update(numbers)
        
        # æ£€æŸ¥æ¯ä¸ªä½ç½®çš„è¶…ç 
        for position, numbers in position_numbers.items():
            threshold = self.threshold_manager.get_threshold('PK10', 'å®šä½èƒ†', 'multi_number')
            if len(numbers) >= threshold:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': play_category,
                    'ä½ç½®': position,
                    'å·ç æ•°é‡': len(numbers),
                    'æŠ•æ³¨å†…å®¹': f"{position}-{','.join([f'{num:02d}' for num in sorted(numbers)])}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(numbers)}, 'è¶…ç ')
                }
                self._add_unique_result(results, 'è¶…ç ', record)
        
        return results
    
    def _analyze_pk10_gyh(self, account, lottery, period, group, play_category):
        """PK10å† äºšå’Œåˆ†æ"""
        results = defaultdict(list)
        
        all_numbers = set()
        all_size_parity = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            
            # æå–å† äºšå’Œå·ç 
            numbers = re.findall(r'\b\d{1,2}\b', content)
            numbers = [int(num) for num in numbers if 1 <= int(num) <= 19]
            all_numbers.update(numbers)
            
            # æå–å¤§å°å•åŒ
            size_parity = self.data_analyzer.extract_size_parity_from_content(content)
            all_size_parity.update(size_parity)
        
        # å† äºšå’Œå¤šç æ£€æµ‹
        threshold = self.threshold_manager.get_threshold('PK10', 'å† äºšå’Œ', 'gyh_multi_number')
        if len(all_numbers) >= threshold:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'å·ç æ•°é‡': len(all_numbers),
                'æŠ•æ³¨å†…å®¹': ', '.join([str(num) for num in sorted(all_numbers)]),
                'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'å† äºšå’Œå¤šç ')
            }
            self._add_unique_result(results, 'å† äºšå’Œå¤šç ', record)
            return results
        
        # å† äºšå’ŒçŸ›ç›¾æ£€æµ‹
        conflicts = []
        if 'å¤§' in all_size_parity and 'å°' in all_size_parity:
            conflicts.append('å¤§å°')
        if 'å•' in all_size_parity and 'åŒ' in all_size_parity:
            conflicts.append('å•åŒ')
        
        if conflicts:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(all_size_parity)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'å† äºšå’ŒçŸ›ç›¾')
            }
            self._add_unique_result(results, 'å† äºšå’ŒçŸ›ç›¾', record)
        
        return results
    
    def _analyze_pk10_two_sides(self, account, lottery, period, group, play_category):
        """PK10ä¸¤é¢ç©æ³•åˆ†æ"""
        results = defaultdict(list)
        
        position_bets = defaultdict(set)
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            
            if '-' in content:
                parts = content.split(',')
                for part in parts:
                    if '-' in part:
                        try:
                            position, bet_option = part.split('-', 1)
                            position = self.data_analyzer._normalize_pk10_position(position)
                            bet_option = bet_option.strip()
                            
                            if bet_option in ['å¤§', 'å°', 'å•', 'åŒ', 'é¾™', 'è™']:
                                position_bets[position].add(bet_option)
                        except ValueError:
                            continue
        
        for position, bets in position_bets.items():
            conflicts = []
            
            if 'å¤§' in bets and 'å°' in bets:
                conflicts.append('å¤§å°')
            if 'å•' in bets and 'åŒ' in bets:
                conflicts.append('å•åŒ')
            if 'é¾™' in bets and 'è™' in bets:
                conflicts.append('é¾™è™')
            
            if conflicts:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': play_category,
                    'ä½ç½®': position,
                    'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                    'æŠ•æ³¨å†…å®¹': f"{position}-{','.join(sorted(bets))}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'ä¸¤é¢çŸ›ç›¾')
                }
                self._add_unique_result(results, 'ä¸¤é¢çŸ›ç›¾', record)
        
        return results
    
    def _analyze_pk10_independent(self, account, lottery, period, group, play_category):
        """PK10ç‹¬ç«‹ç©æ³•åˆ†æï¼ˆå¤§å°å•åŒï¼‰"""
        results = defaultdict(list)
        
        position_bets = defaultdict(set)
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            category = str(row['ç©æ³•åˆ†ç±»'])
            
            # ç¡®å®šä½ç½®
            if 'å† å†›' in category or 'å‰ä¸€' in category:
                position = 'å† å†›'
            elif 'äºšå†›' in category:
                position = 'äºšå†›'
            elif 'å­£å†›' in category:
                position = 'ç¬¬ä¸‰å'
            else:
                continue
            
            if 'å¤§å°' in category:
                bets = self.data_analyzer.extract_size_parity_from_content(content)
            elif 'å•åŒ' in category:
                bets = self.data_analyzer.extract_size_parity_from_content(content)
            else:
                bets = []
            
            position_bets[position].update(bets)
        
        for position, bets in position_bets.items():
            conflicts = []
            
            if 'å¤§' in bets and 'å°' in bets:
                conflicts.append('å¤§å°')
            if 'å•' in bets and 'åŒ' in bets:
                conflicts.append('å•åŒ')
            
            if conflicts:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': play_category,
                    'ä½ç½®': position,
                    'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                    'æŠ•æ³¨å†…å®¹': f"{position}-{','.join(sorted(bets))}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'ç‹¬ç«‹ç©æ³•çŸ›ç›¾')
                }
                self._add_unique_result(results, 'ç‹¬ç«‹ç©æ³•çŸ›ç›¾', record)
        
        return results
    
    def _analyze_pk10_dragon_tiger(self, account, lottery, period, group, play_category):
        """PK10é¾™è™åˆ†æ"""
        results = defaultdict(list)
        
        position_bets = defaultdict(set)
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            category = str(row['ç©æ³•åˆ†ç±»'])
            
            # ç¡®å®šä½ç½®
            if 'å† å†›' in category:
                position = 'å† å†›'
            elif 'äºšå†›' in category:
                position = 'äºšå†›'
            elif 'å­£å†›' in category:
                position = 'ç¬¬ä¸‰å'
            else:
                # ä»å†…å®¹æ¨æ–­ä½ç½®
                position = self.data_analyzer._infer_pk10_position_from_content(content)
            
            # æå–é¾™è™æŠ•æ³¨
            dragon_tiger = self.data_analyzer.extract_dragon_tiger_from_content(content)
            position_bets[position].update(dragon_tiger)
        
        # æ£€æŸ¥çŸ›ç›¾
        for position, bets in position_bets.items():
            if 'é¾™' in bets and 'è™' in bets:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': play_category,
                    'ä½ç½®': position,
                    'çŸ›ç›¾ç±»å‹': 'é¾™è™çŸ›ç›¾',
                    'æŠ•æ³¨å†…å®¹': f"{position}-{','.join(sorted(bets))}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'é¾™è™çŸ›ç›¾'}, 'é¾™è™çŸ›ç›¾')
                }
                self._add_unique_result(results, 'é¾™è™çŸ›ç›¾', record)
        
        return results

    # ==================== æ—¶æ—¶å½©åˆ†ææ–¹æ³• ====================
    def _analyze_ssc_play_category(self, account, lottery, period, group, play_category):
        """æ—¶æ—¶å½©ç©æ³•åˆ†ç±»åˆ†æ"""
        results = defaultdict(list)
        
        # æ—¶æ—¶å½©ç©æ³•è·¯ç”±
        ssc_analysis_methods = {
            'ç¬¬1çƒ': self._analyze_ssc_position,
            'ç¬¬2çƒ': self._analyze_ssc_position,
            'ç¬¬3çƒ': self._analyze_ssc_position,
            'ç¬¬4çƒ': self._analyze_ssc_position,
            'ç¬¬5çƒ': self._analyze_ssc_position,
            'ä¸‡ä½': self._analyze_ssc_position,
            'åƒä½': self._analyze_ssc_position,
            'ç™¾ä½': self._analyze_ssc_position,
            'åä½': self._analyze_ssc_position,
            'ä¸ªä½': self._analyze_ssc_position,
            '1-5çƒ': self._analyze_ssc_range,
            'å®šä½èƒ†': self._analyze_ssc_dingwei,
            'å®šä½_ä¸‡ä½': self._analyze_ssc_position,
            'å®šä½_åƒä½': self._analyze_ssc_position,
            'å®šä½_ç™¾ä½': self._analyze_ssc_position,
            'å®šä½_åä½': self._analyze_ssc_position,
            'å®šä½_ä¸ªä½': self._analyze_ssc_position,
            'ä¸¤é¢': self._analyze_ssc_two_sides,
            'æ€»å’Œ': self._analyze_ssc_zonghe,
            'æ–—ç‰›': self._analyze_ssc_douniu
        }
        
        if play_category in ssc_analysis_methods:
            method = ssc_analysis_methods[play_category]
            return method(account, lottery, period, group, play_category)
        
        return defaultdict(list)
    
    def _analyze_ssc_position(self, account, lottery, period, group, play_category):
        """æ—¶æ—¶å½©ä½ç½®åˆ†æ"""
        results = defaultdict(list)
        
        all_numbers = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            
            # ä½¿ç”¨ç»Ÿä¸€è§£æå™¨è§£ææ—¶æ—¶å½©å†…å®¹
            bets_by_position = ContentParser.parse_ssc_content(content)
            
            for position, numbers in bets_by_position.items():
                # å¦‚æœè§£æå‡ºçš„ä½ç½®åŒ¹é…å½“å‰ç©æ³•åˆ†ç±»ï¼Œåˆ™æ”¶é›†å·ç 
                if self._is_ssc_position_match(position, play_category):
                    all_numbers.update(numbers)
        
        # å¤šç æ£€æµ‹
        threshold = self.threshold_manager.get_threshold('SSC', play_category, 'dingwei_multi')
        if len(all_numbers) >= threshold:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'ä½ç½®': play_category,
                'å·ç æ•°é‡': len(all_numbers),
                'æŠ•æ³¨å†…å®¹': f"{play_category}-{','.join([str(num) for num in sorted(all_numbers)])}",
                'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'å®šä½èƒ†å¤šç ')
            }
            self._add_unique_result(results, 'å®šä½èƒ†å¤šç ', record)
        
        return results
    
    def _is_ssc_position_match(self, position, play_category):
        """æ£€æŸ¥æ—¶æ—¶å½©ä½ç½®æ˜¯å¦åŒ¹é…ç©æ³•åˆ†ç±»"""
        position_mapping = {
            'ç¬¬1çƒ': ['ç¬¬1çƒ', 'ä¸‡ä½', 'å®šä½_ä¸‡ä½'],
            'ç¬¬2çƒ': ['ç¬¬2çƒ', 'åƒä½', 'å®šä½_åƒä½'],
            'ç¬¬3çƒ': ['ç¬¬3çƒ', 'ç™¾ä½', 'å®šä½_ç™¾ä½'],
            'ç¬¬4çƒ': ['ç¬¬4çƒ', 'åä½', 'å®šä½_åä½'],
            'ç¬¬5çƒ': ['ç¬¬5çƒ', 'ä¸ªä½', 'å®šä½_ä¸ªä½']
        }
        
        for key, values in position_mapping.items():
            if play_category == key and position in values:
                return True
        
        return play_category == position
    
    def _analyze_ssc_range(self, account, lottery, period, group, play_category):
        """æ—¶æ—¶å½©èŒƒå›´åˆ†æï¼ˆ1-5çƒï¼‰"""
        results = defaultdict(list)
        
        all_numbers = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            numbers = self.data_analyzer.extract_numbers_from_content(content, 0, 9)
            all_numbers.update(numbers)
        
        threshold = self.threshold_manager.get_threshold('SSC', play_category, 'dingwei_multi')
        if len(all_numbers) >= threshold:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'å·ç æ•°é‡': len(all_numbers),
                'æŠ•æ³¨å†…å®¹': f"{play_category}: {', '.join([str(num) for num in sorted(all_numbers)])}",
                'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'å®šä½èƒ†å¤šç ')
            }
            self._add_unique_result(results, 'å®šä½èƒ†å¤šç ', record)
        
        return results
    
    def _analyze_ssc_dingwei(self, account, lottery, period, group, play_category):
        """æ—¶æ—¶å½©å®šä½èƒ†åˆ†æ"""
        results = defaultdict(list)
        
        position_numbers = defaultdict(set)
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            
            # ä½¿ç”¨ç»Ÿä¸€è§£æå™¨è§£æå®šä½èƒ†å†…å®¹
            bets_by_position = ContentParser.parse_ssc_content(content)
            
            for position, numbers in bets_by_position.items():
                position_numbers[position].update(numbers)
        
        # æ£€æŸ¥æ¯ä¸ªä½ç½®çš„è¶…ç 
        for position, numbers in position_numbers.items():
            threshold = self.threshold_manager.get_threshold('SSC', 'å®šä½èƒ†', 'dingwei_multi')
            if len(numbers) >= threshold:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': play_category,
                    'ä½ç½®': position,
                    'å·ç æ•°é‡': len(numbers),
                    'æŠ•æ³¨å†…å®¹': f"{position}-{','.join([str(num) for num in sorted(numbers)])}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(numbers)}, 'å®šä½èƒ†å¤šç ')
                }
                self._add_unique_result(results, 'å®šä½èƒ†å¤šç ', record)
        
        return results
    
    def _analyze_ssc_two_sides(self, account, lottery, period, group, play_category):
        """æ—¶æ—¶å½©ä¸¤é¢ç©æ³•åˆ†æ"""
        results = defaultdict(list)
        
        total_bets = set()
        ball_bets = defaultdict(set)
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            
            if 'æ€»å’Œã€é¾™è™-' in content:
                clean_content = content.replace('æ€»å’Œã€é¾™è™-', '')
                bets = clean_content.split(',')
                for bet in bets:
                    if 'æ€»å’Œå¤§' in bet:
                        total_bets.add('å¤§')
                    elif 'æ€»å’Œå°' in bet:
                        total_bets.add('å°')
                    elif 'æ€»å’Œå•' in bet:
                        total_bets.add('å•')
                    elif 'æ€»å’ŒåŒ' in bet:
                        total_bets.add('åŒ')
                    elif 'é¾™' in bet:
                        total_bets.add('é¾™')
                    elif 'è™' in bet:
                        total_bets.add('è™')
            
            for i in range(1, 6):
                ball_key = f'ç¬¬{i}çƒ'
                if ball_key in content:
                    bets = self.data_analyzer.extract_size_parity_from_content(content)
                    ball_bets[ball_key].update(bets)
        
        conflicts = []
        if 'å¤§' in total_bets and 'å°' in total_bets:
            conflicts.append('æ€»å’Œå¤§/å°')
        if 'å•' in total_bets and 'åŒ' in total_bets:
            conflicts.append('æ€»å’Œå•/åŒ')
        if 'é¾™' in total_bets and 'è™' in total_bets:
            conflicts.append('é¾™/è™')
        
        if conflicts:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                'æŠ•æ³¨å†…å®¹': f"æ€»å’Œ:{','.join(sorted(total_bets))}",
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'ä¸¤é¢çŸ›ç›¾')
            }
            self._add_unique_result(results, 'ä¸¤é¢çŸ›ç›¾', record)
        
        for ball, bets in ball_bets.items():
            ball_conflicts = []
            if 'å¤§' in bets and 'å°' in bets:
                ball_conflicts.append('å¤§å°')
            if 'å•' in bets and 'åŒ' in bets:
                ball_conflicts.append('å•åŒ')
            
            if ball_conflicts:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': play_category,
                    'çŸ›ç›¾ç±»å‹': f"{ball}{'ã€'.join(ball_conflicts)}",
                    'æŠ•æ³¨å†…å®¹': f"{ball}:{','.join(sorted(bets))}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': f"{ball}{'ã€'.join(ball_conflicts)}"}, 'ä¸¤é¢çŸ›ç›¾')
                }
                self._add_unique_result(results, 'ä¸¤é¢çŸ›ç›¾', record)
        
        return results
    
    def _analyze_ssc_zonghe(self, account, lottery, period, group, play_category):
        """æ—¶æ—¶å½©æ€»å’Œåˆ†æ"""
        results = defaultdict(list)
        
        all_bets = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            bets = self.data_analyzer.extract_size_parity_from_content(content)
            all_bets.update(bets)
        
        conflicts = []
        if 'å¤§' in all_bets and 'å°' in all_bets:
            conflicts.append('å¤§å°')
        if 'å•' in all_bets and 'åŒ' in all_bets:
            conflicts.append('å•åŒ')
        
        if conflicts:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                'æŠ•æ³¨å†…å®¹': ', '.join(sorted(all_bets)),
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'æ€»å’ŒçŸ›ç›¾')
            }
            self._add_unique_result(results, 'æ€»å’ŒçŸ›ç›¾', record)
        
        return results
    
    def _analyze_ssc_douniu(self, account, lottery, period, group, play_category):
        """æ—¶æ—¶å½©æ–—ç‰›åˆ†æ"""
        results = defaultdict(list)
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            bull_types = self.data_analyzer.extract_douniu_types(content)
            
            if len(bull_types) >= THRESHOLD_CONFIG['SSC']['douniu_multi']:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': play_category,
                    'å·ç æ•°é‡': len(bull_types),
                    'æŠ•æ³¨å†…å®¹': ', '.join(sorted(bull_types)),
                    'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(bull_types)}, 'æ–—ç‰›å¤šç ')
                }
                self._add_unique_result(results, 'æ–—ç‰›å¤šç ', record)
        
        return results

    # ==================== 3Dåˆ†ææ–¹æ³• ====================
    def _analyze_3d_play_category(self, account, lottery, period, group, play_category):
        """3Dç©æ³•åˆ†ç±»åˆ†æ"""
        results = defaultdict(list)
        
        # 3Dç©æ³•è·¯ç”±
        three_d_analysis_methods = {
            'ä¸¤é¢': self._analyze_3d_two_sides,
            'å¤§å°å•åŒ': self._analyze_3d_two_sides,
            'å®šä½èƒ†': self._analyze_3d_dingwei,
            'å®šä½èƒ†_ç™¾ä½': self._analyze_3d_position,
            'å®šä½èƒ†_åä½': self._analyze_3d_position,
            'å®šä½èƒ†_ä¸ªä½': self._analyze_3d_position,
            'ç™¾ä½': self._analyze_3d_position,
            'åä½': self._analyze_3d_position,
            'ä¸ªä½': self._analyze_3d_position
        }
        
        if play_category in three_d_analysis_methods:
            method = three_d_analysis_methods[play_category]
            return method(account, lottery, period, group, play_category)
        
        return defaultdict(list)
    
    def _analyze_3d_two_sides(self, account, lottery, period, group, play_category):
        """3Dä¸¤é¢ç©æ³•åˆ†æ"""
        results = defaultdict(list)
        
        # æŒ‰ä½ç½®åˆ†ç±»æ”¶é›†æŠ•æ³¨
        position_bets = defaultdict(set)
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            
            # é¦–å…ˆå°è¯•è§£æç«–çº¿æ ¼å¼
            bets_by_position = self.data_analyzer.parse_3d_content(content)
            if bets_by_position:
                # ç«–çº¿æ ¼å¼è§£ææˆåŠŸ
                for position, bets in bets_by_position.items():
                    for bet in bets:
                        # æå–å¤§å°å•åŒä¿¡æ¯
                        if isinstance(bet, str):
                            if 'å¤§' in bet:
                                position_bets[position].add('å¤§')
                            if 'å°' in bet:
                                position_bets[position].add('å°')
                            if 'å•' in bet:
                                position_bets[position].add('å•')
                            if 'åŒ' in bet:
                                position_bets[position].add('åŒ')
            else:
                # åŸæœ‰çš„è§£æé€»è¾‘
                positions = ['ç™¾ä½', 'åä½', 'ä¸ªä½', 'ç™¾å', 'ç™¾ä¸ª', 'åä¸ª', 'ç™¾åä¸ª']
                bets = ['å¤§', 'å°', 'å•', 'åŒ', 'è´¨', 'åˆ', 'å’Œå¤§', 'å’Œå°', 'å’Œå•', 'å’ŒåŒ', 
                       'å’Œå°¾å¤§', 'å’Œå°¾å°', 'å’Œå°¾è´¨', 'å’Œå°¾åˆ']
                
                # å¤„ç†å¤šç§æ ¼å¼
                parts = [part.strip() for part in content.split(',')]
                
                current_position = None
                
                for part in parts:
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«ä½ç½®ä¿¡æ¯
                    position_found = False
                    for position in positions:
                        if position in part:
                            current_position = position
                            position_found = True
                            break
                    
                    if position_found:
                        # æå–è¯¥ä½ç½®çš„æ‰€æœ‰æŠ•æ³¨é€‰é¡¹
                        for bet in bets:
                            if bet in part:
                                position_bets[current_position].add(bet)
                    elif current_position:
                        # å¦‚æœæ²¡æœ‰ä½ç½®ä¿¡æ¯ä½†æœ‰å½“å‰ä¸Šä¸‹æ–‡ä½ç½®ï¼Œæ£€æŸ¥æŠ•æ³¨é€‰é¡¹
                        for bet in bets:
                            if bet in part:
                                position_bets[current_position].add(bet)
        
        # æ£€æŸ¥æ¯ä¸ªä½ç½®çš„çŸ›ç›¾
        for position, bet_options in position_bets.items():
            conflicts = []
            
            # åŸºæœ¬å¤§å°å•åŒè´¨åˆçŸ›ç›¾
            if 'å¤§' in bet_options and 'å°' in bet_options:
                conflicts.append('å¤§å°çŸ›ç›¾')
            if 'å•' in bet_options and 'åŒ' in bet_options:
                conflicts.append('å•åŒçŸ›ç›¾')
            if 'è´¨' in bet_options and 'åˆ' in bet_options:
                conflicts.append('è´¨åˆçŸ›ç›¾')
            
            # å’Œæ•°å±æ€§çŸ›ç›¾
            if 'å’Œå¤§' in bet_options and 'å’Œå°' in bet_options:
                conflicts.append('å’Œå¤§å°çŸ›ç›¾')
            if 'å’Œå•' in bet_options and 'å’ŒåŒ' in bet_options:
                conflicts.append('å’Œå•åŒçŸ›ç›¾')
            if 'å’Œå°¾å¤§' in bet_options and 'å’Œå°¾å°' in bet_options:
                conflicts.append('å’Œå°¾å¤§å°çŸ›ç›¾')
            if 'å’Œå°¾è´¨' in bet_options and 'å’Œå°¾åˆ' in bet_options:
                conflicts.append('å’Œå°¾è´¨åˆçŸ›ç›¾')
            
            if conflicts:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': play_category,
                    'ä½ç½®': position,
                    'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts),
                    'æŠ•æ³¨å†…å®¹': f"{position}:{','.join(sorted(bet_options))}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflicts)}, 'ä¸¤é¢çŸ›ç›¾')
                }
                self._add_unique_result(results, 'ä¸¤é¢çŸ›ç›¾', record)
        
        return results
    
    def _analyze_3d_dingwei(self, account, lottery, period, group, play_category):
        """3Då®šä½èƒ†åˆ†æ"""
        results = defaultdict(list)
        
        position_numbers = defaultdict(set)
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            
            # ä½¿ç”¨ç»Ÿä¸€è§£æå™¨è§£æ3Då†…å®¹
            bets_by_position = self.data_analyzer.parse_3d_content(content)
            if bets_by_position:
                # å¦‚æœæœ‰è§£æç»“æœï¼Œä½¿ç”¨è§£æå‡ºçš„ä½ç½®å’Œå·ç 
                for position, numbers in bets_by_position.items():
                    position_numbers[position].update(numbers)
                continue
            
            # å¦‚æœæ²¡æœ‰ç«–çº¿æ ¼å¼ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
            # ç¡®å®šä½ç½®
            if 'ç™¾ä½' in content:
                position = 'ç™¾ä½'
            elif 'åä½' in content:
                position = 'åä½'
            elif 'ä¸ªä½' in content:
                position = 'ä¸ªä½'
            else:
                position = 'æœªçŸ¥ä½ç½®'
            
            # æå–å·ç 
            numbers = self.data_analyzer.extract_numbers_from_content(content, 0, 9)
            position_numbers[position].update(numbers)
        
        # æ£€æŸ¥æ¯ä¸ªä½ç½®çš„è¶…ç 
        for position, numbers in position_numbers.items():
            threshold = self.threshold_manager.get_threshold('3D', 'å®šä½èƒ†', 'dingwei_multi')
            if len(numbers) >= threshold:
                record = {
                    'ä¼šå‘˜è´¦å·': account,
                    'å½©ç§': lottery,
                    'æœŸå·': period,
                    'ç©æ³•åˆ†ç±»': play_category,
                    'ä½ç½®': position,
                    'å·ç æ•°é‡': len(numbers),
                    'æŠ•æ³¨å†…å®¹': f"{position}-{','.join([str(num) for num in sorted(numbers)])}",
                    'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(numbers)}, 'å®šä½èƒ†å¤šç ')
                }
                self._add_unique_result(results, 'å®šä½èƒ†å¤šç ', record)
        
        return results
    
    def _analyze_3d_position(self, account, lottery, period, group, play_category):
        """3Dä½ç½®åˆ†æ"""
        results = defaultdict(list)
        
        all_numbers = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            
            # ä½¿ç”¨ç»Ÿä¸€è§£æå™¨è§£æ3Då†…å®¹
            bets_by_position = self.data_analyzer.parse_3d_content(content)
            
            for position, numbers in bets_by_position.items():
                # å¦‚æœè§£æå‡ºçš„ä½ç½®åŒ¹é…å½“å‰ç©æ³•åˆ†ç±»ï¼Œåˆ™æ”¶é›†å·ç 
                if self._is_3d_position_match(position, play_category):
                    all_numbers.update(numbers)
        
        # å¤šç æ£€æµ‹
        threshold = self.threshold_manager.get_threshold('3D', play_category, 'dingwei_multi')
        if len(all_numbers) >= threshold:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'ä½ç½®': play_category,
                'å·ç æ•°é‡': len(all_numbers),
                'æŠ•æ³¨å†…å®¹': f"{play_category}-{','.join([str(num) for num in sorted(all_numbers)])}",
                'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'å®šä½èƒ†å¤šç ')
            }
            self._add_unique_result(results, 'å®šä½èƒ†å¤šç ', record)
        
        return results
    
    def _is_3d_position_match(self, position, play_category):
        """æ£€æŸ¥3Dä½ç½®æ˜¯å¦åŒ¹é…ç©æ³•åˆ†ç±»"""
        position_mapping = {
            'å®šä½èƒ†_ç™¾ä½': ['ç™¾ä½'],
            'å®šä½èƒ†_åä½': ['åä½'],
            'å®šä½èƒ†_ä¸ªä½': ['ä¸ªä½']
        }
        
        for key, values in position_mapping.items():
            if play_category == key and position in values:
                return True
        
        return play_category == position

    # ==================== ä¸‰è‰²å½©åˆ†ææ–¹æ³• ====================
    def _analyze_three_color_play_category(self, account, lottery, period, group, play_category):
        """ä¸‰è‰²å½©ç©æ³•åˆ†ç±»åˆ†æ"""
        results = defaultdict(list)
        
        # ä¸‰è‰²å½©ç©æ³•è·¯ç”±
        three_color_analysis_methods = {
            'æ­£ç ': self._analyze_three_color_zhengma,
            'ä¸¤é¢': self._analyze_three_color_two_sides,
            'è‰²æ³¢': self._analyze_three_color_wave,
            'ç‰¹ç ': self._analyze_three_color_tema
        }
        
        if play_category in three_color_analysis_methods:
            method = three_color_analysis_methods[play_category]
            return method(account, lottery, period, group, play_category)
        
        return defaultdict(list)
    
    def _analyze_three_color_zhengma(self, account, lottery, period, group, play_category):
        """ä¸‰è‰²å½©æ­£ç åˆ†æ"""
        results = defaultdict(list)
        
        all_numbers = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            numbers = self.data_analyzer.extract_numbers_from_content(content, 0, 9)
            all_numbers.update(numbers)
        
        threshold = self.threshold_manager.get_threshold('THREE_COLOR', play_category, 'zhengma_multi')
        if len(all_numbers) >= threshold:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'å·ç æ•°é‡': len(all_numbers),
                'æŠ•æ³¨å†…å®¹': ', '.join([str(num) for num in sorted(all_numbers)]),
                'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(all_numbers)}, 'æ­£ç å¤šç ')
            }
            self._add_unique_result(results, 'æ­£ç å¤šç ', record)
        
        return results
    
    def _analyze_three_color_two_sides(self, account, lottery, period, group, play_category):
        """ä¸‰è‰²å½©ä¸¤é¢åˆ†æ"""
        results = defaultdict(list)
        
        has_big = False
        has_small = False
        has_single = False
        has_double = False
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            bets = self.data_analyzer.extract_size_parity_from_content(content)
            
            if 'å¤§' in bets:
                has_big = True
            if 'å°' in bets:
                has_small = True
            if 'å•' in bets:
                has_single = True
            if 'åŒ' in bets:
                has_double = True
        
        conflict_types = []
        if has_big and has_small:
            conflict_types.append('å¤§å°')
        if has_single and has_double:
            conflict_types.append('å•åŒ')
        
        if conflict_types:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types),
                'æ’åºæƒé‡': self._calculate_sort_weight({'çŸ›ç›¾ç±»å‹': 'ã€'.join(conflict_types)}, 'ä¸¤é¢çŸ›ç›¾')
            }
            self._add_unique_result(results, 'ä¸¤é¢çŸ›ç›¾', record)
        
        return results
    
    def _analyze_three_color_wave(self, account, lottery, period, group, play_category):
        """ä¸‰è‰²å½©æ³¢è‰²åˆ†æ"""
        results = defaultdict(list)
        
        # æ”¶é›†è¯¥æœŸå·å†…æ‰€æœ‰æ³¢è‰²æŠ•æ³¨
        all_waves = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            # ä½¿ç”¨ä¸‰è‰²å½©ä¸“ç”¨çš„æ³¢è‰²æå–æ–¹æ³•
            waves = self.data_analyzer.extract_three_color_wave_from_content(content)
            all_waves.update(waves)
        
        # æ£€æŸ¥æ˜¯å¦åœ¨åŒä¸€æœŸå·å†…åŒæ—¶æŠ•æ³¨äº†çº¢æ³¢å’Œç»¿æ³¢
        if 'çº¢æ³¢' in all_waves and 'ç»¿æ³¢' in all_waves:
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'æŠ•æ³¨æ³¢è‰²æ•°': len(all_waves),
                'æŠ•æ³¨æ³¢è‰²': sorted(list(all_waves)),
                'æŠ•æ³¨å†…å®¹': f"åŒä¸€æœŸå·å†…æŠ•æ³¨: {', '.join(sorted(all_waves))}",
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨æ³¢è‰²æ•°': len(all_waves)}, 'è‰²æ³¢çº¢ç»¿æŠ•æ³¨')
            }
            self._add_unique_result(results, 'è‰²æ³¢çº¢ç»¿æŠ•æ³¨', record)
        
        # æ£€æŸ¥æ³¢è‰²å…¨åŒ…
        if len(all_waves) >= 3:  # çº¢æ³¢ã€ç»¿æ³¢ã€ç´«æ³¢å…¨åŒ…
            record = {
                'ä¼šå‘˜è´¦å·': account,
                'å½©ç§': lottery,
                'æœŸå·': period,
                'ç©æ³•åˆ†ç±»': play_category,
                'è¿è§„ç±»å‹': 'è‰²æ³¢å…¨åŒ…',
                'æŠ•æ³¨æ³¢è‰²æ•°': len(all_waves),
                'æŠ•æ³¨æ³¢è‰²': sorted(list(all_waves)),
                'æŠ•æ³¨å†…å®¹': f"è‰²æ³¢å…¨åŒ…: {', '.join(sorted(all_waves))}",
                'æ’åºæƒé‡': self._calculate_sort_weight({'æŠ•æ³¨æ³¢è‰²æ•°': len(all_waves)}, 'è‰²æ³¢å…¨åŒ…')
            }
            self._add_unique_result(results, 'è‰²æ³¢å…¨åŒ…', record)
        
        return results
    
    def _analyze_three_color_tema(self, account, lottery, period, group, play_category):
        """ä¸‰è‰²å½©ç‰¹ç åˆ†æ"""
        return self._analyze_number_bets(account, lottery, period, group, play_category, 'THREE_COLOR', 'ç‰¹ç å¤šç ')

    # ==================== é€šç”¨å·¥å…·æ–¹æ³• ====================
    def _parse_lhc_content(self, content):
        """è§£æå…­åˆå½©å†…å®¹"""
        content_str = str(content)
        
        if '-' in content_str:
            parts = content_str.split('-', 1)
            return parts[1].strip()
        
        return content_str
    
    def _analyze_number_bets(self, account, lottery, period, group, play_category, lottery_type, result_key):
        """é€šç”¨å·ç æŠ•æ³¨åˆ†æ"""
        results = defaultdict(list)
        
        all_numbers = set()
        
        for _, row in group.iterrows():
            content = str(row['å†…å®¹'])
            
            if lottery_type == 'LHC':
                clean_content = self._parse_lhc_content(content)
            else:
                clean_content = content
                
            config = LOTTERY_CONFIGS.get(lottery_type, {})
            min_num = config.get('min_number', 0)
            max_num = config.get('max_number', 49)
            
            numbers = self.data_analyzer.extract_numbers_from_content(clean_content, min_num, max_num)
            all_numbers.update(numbers)
        
        threshold = self.threshold_manager.get_threshold(lottery_type, play_category, 'multi_number')
        if len(all_numbers) >= threshold:
            record = self._create_number_record(
                account, lottery, period, play_category, all_numbers, result_key
            )
            self._add_unique_result(results, result_key, record)
        
        return results
    
    def _create_number_record(self, account, lottery, period, play_category, numbers, result_key):
        """åˆ›å»ºå·ç è®°å½•"""
        return {
            'ä¼šå‘˜è´¦å·': account,
            'å½©ç§': lottery,
            'æœŸå·': period,
            'ç©æ³•åˆ†ç±»': play_category,
            'å·ç æ•°é‡': len(numbers),
            'æŠ•æ³¨å†…å®¹': ', '.join([f"{num:02d}" for num in sorted(numbers)]),
            'æ’åºæƒé‡': self._calculate_sort_weight({'å·ç æ•°é‡': len(numbers)}, result_key)
        }
    
    def _get_record_hash(self, record):
        """ç”Ÿæˆè®°å½•çš„å”¯ä¸€å“ˆå¸Œå€¼"""
        key_parts = [
            record['ä¼šå‘˜è´¦å·'],
            record['å½©ç§'], 
            record['æœŸå·'],
            record.get('ç©æ³•åˆ†ç±»', ''),
            record.get('è¿è§„ç±»å‹', ''),
            record.get('ä½ç½®', ''),
            str(record.get('å·ç æ•°é‡', 0)),
            record.get('çŸ›ç›¾ç±»å‹', '')
        ]
        return hashlib.md5('|'.join(key_parts).encode()).hexdigest()
    
    def _add_unique_result(self, results, result_type, record):
        """æ·»åŠ å”¯ä¸€çš„ç»“æœè®°å½•"""
        record_hash = self._get_record_hash(record)
        
        if record_hash not in self.seen_records:
            self.seen_records.add(record_hash)
            results[result_type].append(record)
            return True
        return False
    
    def _calculate_sort_weight(self, record, result_type):
        """è®¡ç®—æ’åºæƒé‡"""
        weight = 0
        
        # åŸºäºå·ç æ•°é‡
        if record.get('å·ç æ•°é‡', 0) > 0:
            weight += record['å·ç æ•°é‡'] * 10
        
        # åŸºäºçŸ›ç›¾ç±»å‹å¤æ‚åº¦
        if record.get('çŸ›ç›¾ç±»å‹'):
            conflict_count = len(record['çŸ›ç›¾ç±»å‹'].split('ã€'))
            weight += conflict_count * 15
        
        # åŸºäºå…¶ä»–æ•°é‡å­—æ®µ
        for field in ['ç”Ÿè‚–æ•°é‡', 'å°¾æ•°æ•°é‡', 'æŠ•æ³¨åŒºé—´æ•°', 'æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨äº”è¡Œæ•°']:
            if record.get(field, 0) > 0:
                weight += record[field] * 8
        
        # åŸºäºçŸ›ç›¾å€¼
        if record.get('çŸ›ç›¾å€¼', 0) > 0:
            weight += record['çŸ›ç›¾å€¼'] * 5
        
        # åŸºäºæ£€æµ‹ç±»å‹é‡è¦æ€§
        if 'å¤šå·ç ' in result_type:
            weight += 25
        elif 'çŸ›ç›¾' in result_type:
            weight += 20
        elif 'å…¨åŒ…' in result_type:
            weight += 30
        elif 'ä¸‰ç»„' in result_type:
            weight += 35
        
        return weight

# ==================== ç»“æœå¤„ç†å™¨ ====================
class ResultProcessor:
    def __init__(self):
        self.behavior_names = {
            'PKæ‹¾èµ›è½¦': {
                'è¶…ç ': 'è¶…ç ',
                'å† äºšå’Œå¤šç ': 'å† äºšå’Œå¤šç ',
                'å† äºšå’ŒçŸ›ç›¾': 'å† äºšå’ŒçŸ›ç›¾',
                'ä¸¤é¢çŸ›ç›¾': 'ä¸¤é¢çŸ›ç›¾',
                'ç‹¬ç«‹ç©æ³•çŸ›ç›¾': 'ç‹¬ç«‹ç©æ³•çŸ›ç›¾',
                'å‰ä¸€å¤šç ': 'å‰ä¸€å¤šç ',
                'é¾™è™çŸ›ç›¾': 'é¾™è™çŸ›ç›¾',
                'åä¸ªä½ç½®å…¨æŠ•': 'åä¸ªä½ç½®å…¨æŠ•'
            },
            'å¿«ä¸‰': {
                'å’Œå€¼å¤šç ': 'å’Œå€¼å¤šç ',
                'å’Œå€¼çŸ›ç›¾': 'å’Œå€¼çŸ›ç›¾',  # å¤§å°å•åŒåŒæ—¶ä¸‹æ³¨
                'å’Œå€¼å¤§å°çŸ›ç›¾': 'å’Œå€¼å¤§å°çŸ›ç›¾',  # æŠ•æ³¨æ–¹å‘ä¸å·ç åˆ†å¸ƒçŸ›ç›¾
                'ç‹¬èƒ†å¤šç ': 'ç‹¬èƒ†å¤šç ',
                'ä¸åŒå·å…¨åŒ…': 'ä¸åŒå·å…¨åŒ…',
                'ä¸¤é¢çŸ›ç›¾': 'ä¸¤é¢çŸ›ç›¾'
            },
            'å…­åˆå½©': {
                'æ•°å­—ç±»å¤šç ': 'æ•°å­—ç±»å¤šç ',
                'ç‰¹ç å¤šç ': 'ç‰¹ç å¤šç ',
                'æ­£ç å¤šç ': 'æ­£ç å¤šç ',
                'æ­£ç 1-6å¤šç ': 'æ­£ç 1-6å¤šç ',
                'æ­£ç‰¹å¤šç ': 'æ­£ç‰¹å¤šç ',
                'ç”Ÿè‚–ç±»å¤šç ': 'ç”Ÿè‚–ç±»å¤šç ',
                'å¹³ç‰¹å¤šè‚–': 'å¹³ç‰¹å¤šè‚–',
                'ç‰¹è‚–å¤šè‚–': 'ç‰¹è‚–å¤šè‚–',
                'ä¸€è‚–å¤šè‚–': 'ä¸€è‚–å¤šè‚–',
                # å°¾æ•°ç›¸å…³è¡Œä¸ºç±»å‹ç‹¬ç«‹æ˜¾ç¤º
                'å°¾æ•°å¤šç ': 'å°¾æ•°å¤šç ',
                'å°¾æ•°å¤´å°¾å¤šç ': 'å°¾æ•°å¤´å°¾å¤šç ',
                'ç‰¹å°¾å¤šå°¾': 'ç‰¹å°¾å¤šå°¾',
                'å…¨å°¾å¤šå°¾': 'å…¨å°¾å¤šå°¾',
                'ä¸¤é¢ç©æ³•çŸ›ç›¾': 'ä¸¤é¢ç©æ³•çŸ›ç›¾',
                'æ­£ç 1-6çŸ›ç›¾': 'æ­£ç 1-6çŸ›ç›¾',
                'æ­£ç‰¹çŸ›ç›¾': 'æ­£ç‰¹çŸ›ç›¾',
                'åŒºé—´å¤šç»„': 'åŒºé—´å¤šç»„',
                'æ³¢è‰²ä¸‰ç»„': 'æ³¢è‰²ä¸‰ç»„',
                'è‰²æ³¢ä¸‰ç»„': 'è‰²æ³¢ä¸‰ç»„',
                # è¿è‚–ç›¸å…³ - å…·ä½“ç±»å‹
                'äºŒè¿è‚–å¤šè‚–': 'äºŒè¿è‚–å¤šè‚–',
                'ä¸‰è¿è‚–å¤šè‚–': 'ä¸‰è¿è‚–å¤šè‚–', 
                'å››è¿è‚–å¤šè‚–': 'å››è¿è‚–å¤šè‚–',
                'äº”è¿è‚–å¤šè‚–': 'äº”è¿è‚–å¤šè‚–',
                'è¿è‚–å¤šè‚–': 'è¿è‚–å¤šè‚–',  # ä¿ç•™é€šç”¨ç±»å‹ä½œä¸ºåå¤‡
                # æ­£ç æ³¢è‰²ç›¸å…³
                'æ­£ç æ³¢è‰²å…¨åŒ…': 'æ­£ç æ³¢è‰²å…¨åŒ…',           
                # è¿å°¾ç›¸å…³ - å…·ä½“ç±»å‹
                'äºŒè¿å°¾å¤šå°¾': 'äºŒè¿å°¾å¤šå°¾',
                'ä¸‰è¿å°¾å¤šå°¾': 'ä¸‰è¿å°¾å¤šå°¾',
                'å››è¿å°¾å¤šå°¾': 'å››è¿å°¾å¤šå°¾',
                'äº”è¿å°¾å¤šå°¾': 'äº”è¿å°¾å¤šå°¾',
                'è¿å°¾å¤šå°¾': 'è¿å°¾å¤šå°¾',  # ä¿ç•™é€šç”¨ç±»å‹ä½œä¸ºåå¤‡
                # æ³¢è‰²ç›¸å…³è¡Œä¸º
                'è‰²æ³¢å…¨åŒ…': 'è‰²æ³¢å…¨åŒ…',                   # ä¼ ç»Ÿè‰²æ³¢å…¨åŒ…
                'ä¸ƒè‰²æ³¢å¤šè‰²': 'ä¸ƒè‰²æ³¢å¤šè‰²',
                'è‰²æ³¢ä¸­åŠæ³¢å…¨åŒ…': 'è‰²æ³¢ä¸­åŠæ³¢å…¨åŒ…',       # è‰²æ³¢ç©æ³•ä¸­çš„åŠæ³¢å…¨åŒ…
                'åŠæ³¢å¤§å°å…¨åŒ…': 'åŠæ³¢å¤§å°å…¨åŒ…',           # åŠæ³¢ç©æ³•ä¸­çš„å¤§å°å…¨åŒ…
                'åŠæ³¢å•åŒå…¨åŒ…': 'åŠæ³¢å•åŒå…¨åŒ…',           # åŠæ³¢ç©æ³•ä¸­çš„å•åŒå…¨åŒ…
                'äº”è¡Œå¤šç»„': 'äº”è¡Œå¤šç»„',
                'è¿è‚–å¤šè‚–': 'è¿è‚–å¤šè‚–',
                'è¿å°¾å¤šå°¾': 'è¿å°¾å¤šå°¾'
            },
            '3Dç³»åˆ—': {
                'ä¸¤é¢çŸ›ç›¾': 'ä¸¤é¢çŸ›ç›¾',
                'å®šä½èƒ†å¤šç ': 'å®šä½èƒ†å¤šç '
            },
            'æ—¶æ—¶å½©': {
                'ä¸¤é¢çŸ›ç›¾': 'ä¸¤é¢çŸ›ç›¾',
                'æ–—ç‰›å¤šç ': 'æ–—ç‰›å¤šç ',
                'å®šä½èƒ†å¤šç ': 'å®šä½èƒ†å¤šç ',
                'æ€»å’ŒçŸ›ç›¾': 'æ€»å’ŒçŸ›ç›¾'
            },
            'ä¸‰è‰²å½©': {
                'æ­£ç å¤šç ': 'æ­£ç å¤šç ',
                'ä¸¤é¢çŸ›ç›¾': 'ä¸¤é¢çŸ›ç›¾',
                'è‰²æ³¢å…¨åŒ…': 'è‰²æ³¢å…¨åŒ…',
                'è‰²æ³¢çº¢ç»¿æŠ•æ³¨': 'è‰²æ³¢çº¢ç»¿æŠ•æ³¨'
            }
        }
        self.displayed_records_cache = set()  # ç¼“å­˜å·²æ˜¾ç¤ºçš„è®°å½•
    
    def organize_results_by_account(self, all_results):
        """ç»„ç»‡ç»“æœæŒ‰è´¦æˆ·åˆ†ç±»æœ¬"""
        account_results = defaultdict(lambda: {
            'violations': [],
            'periods': set(),
            'violation_types': set(),
            'violation_count': 0,
            'lottery_types': set(),
            'violations_by_type': defaultdict(list),
            'violations_by_lottery': defaultdict(lambda: defaultdict(list))
        })
        
        for lottery_type, results in all_results.items():
            for result_type, records in results.items():
                for record in records:
                    account = record['ä¼šå‘˜è´¦å·']
                    period = record['æœŸå·']
                    lottery = record['å½©ç§']
                    
                    violation_record = {
                        'å½©ç§': lottery,
                        'æœŸå·': period,
                        'ç©æ³•åˆ†ç±»': record['ç©æ³•åˆ†ç±»'],
                        'è¿è§„ç±»å‹': result_type,
                        'è¯¦ç»†ä¿¡æ¯': self._get_violation_details(record, result_type),
                        'æŠ•æ³¨å†…å®¹': record.get('æŠ•æ³¨å†…å®¹', ''),
                        'å·ç æ•°é‡': record.get('å·ç æ•°é‡', 0),
                        'çŸ›ç›¾ç±»å‹': record.get('çŸ›ç›¾ç±»å‹', ''),
                        'ä½ç½®': record.get('ä½ç½®', ''),
                        'æ’åºæƒé‡': record.get('æ’åºæƒé‡', 0)
                    }
                    
                    account_results[account]['violations'].append(violation_record)
                    account_results[account]['violations_by_type'][result_type].append(violation_record)
                    account_results[account]['violations_by_lottery'][lottery][result_type].append(violation_record)
                    account_results[account]['periods'].add(period)
                    account_results[account]['violation_types'].add(result_type)
                    account_results[account]['violation_count'] += 1
                    account_results[account]['lottery_types'].add(lottery)
        
        return account_results
    
    def _get_violation_details(self, record, result_type):
        """è·å–è¿è§„è¯¦æƒ…"""
        details = []
        
        # ä¸“é—¨å¤„ç†å’Œå€¼å¤§å°çŸ›ç›¾çš„æ˜¾ç¤º
        if 'å’Œå€¼å¤§å°çŸ›ç›¾' in result_type:
            # å’Œå€¼å¤§å°çŸ›ç›¾æ˜¾ç¤ºçŸ›ç›¾ç±»å‹å’ŒçŸ›ç›¾å€¼
            if record.get('çŸ›ç›¾ç±»å‹'):
                details.append(f"çŸ›ç›¾ç±»å‹: {record['çŸ›ç›¾ç±»å‹']}")
            if record.get('çŸ›ç›¾å€¼', 0) > 0:
                details.append(f"çŸ›ç›¾å€¼: {record['çŸ›ç›¾å€¼']}")
            return ' | '.join(details) if details else 'æ— è¯¦æƒ…'
        
        # ä¸“é—¨å¤„ç†å’Œå€¼çŸ›ç›¾çš„æ˜¾ç¤º
        elif 'å’Œå€¼çŸ›ç›¾' in result_type:
            # å’Œå€¼çŸ›ç›¾åªæ˜¾ç¤ºçŸ›ç›¾ç±»å‹
            if record.get('çŸ›ç›¾ç±»å‹'):
                details.append(f"çŸ›ç›¾ç±»å‹: {record['çŸ›ç›¾ç±»å‹']}")
            return ' | '.join(details) if details else 'æ— è¯¦æƒ…'
        
        # å°¾æ•°å¤šç çš„ç‰¹æ®Šå¤„ç†
        elif 'å°¾æ•°' in result_type:
            # ä¼˜å…ˆä½¿ç”¨å°¾æ•°æ•°é‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å·ç æ•°é‡
            tail_count = record.get('å°¾æ•°æ•°é‡', record.get('å·ç æ•°é‡', 0))
            details.append(f"å°¾æ•°æ•°é‡: {tail_count}ä¸ª")
        
        # æ­£å¸¸å¤„ç†å…¶ä»–ç±»å‹
        else:
            if 'å·ç æ•°é‡' in record and record['å·ç æ•°é‡'] > 0:
                details.append(f"å·ç æ•°é‡: {record['å·ç æ•°é‡']}")
            if 'çŸ›ç›¾ç±»å‹' in record:
                details.append(f"çŸ›ç›¾ç±»å‹: {record['çŸ›ç›¾ç±»å‹']}")
            if 'ä½ç½®' in record:
                details.append(f"ä½ç½®: {record['ä½ç½®']}")
            if 'ç”Ÿè‚–æ•°é‡' in record and record['ç”Ÿè‚–æ•°é‡'] > 0:
                details.append(f"ç”Ÿè‚–æ•°é‡: {record['ç”Ÿè‚–æ•°é‡']}")
            if 'æŠ•æ³¨åŒºé—´æ•°' in record and record['æŠ•æ³¨åŒºé—´æ•°'] > 0:
                details.append(f"æŠ•æ³¨åŒºé—´æ•°: {record['æŠ•æ³¨åŒºé—´æ•°']}")
            if 'æŠ•æ³¨æ³¢è‰²æ•°' in record and record['æŠ•æ³¨æ³¢è‰²æ•°'] > 0:
                details.append(f"æŠ•æ³¨æ³¢è‰²æ•°: {record['æŠ•æ³¨æ³¢è‰²æ•°']}")
            if 'æŠ•æ³¨äº”è¡Œæ•°' in record and record['æŠ•æ³¨äº”è¡Œæ•°'] > 0:
                details.append(f"æŠ•æ³¨äº”è¡Œæ•°: {record['æŠ•æ³¨äº”è¡Œæ•°']}")
        
        return ' | '.join(details) if details else 'æ— è¯¦æƒ…'
    
    def optimize_display_records(self, records, max_records=5):
        """ä¼˜åŒ–æ˜¾ç¤ºè®°å½•"""
        if not records:
            return []
        
        # é‡ç½®ç¼“å­˜ï¼ˆæ¯æ¬¡è°ƒç”¨æ—¶é‡æ–°è®¡ç®—ï¼‰
        self.displayed_records_cache = set()
        
        def get_record_key(record):
            """ç”Ÿæˆè®°å½•çš„å”¯ä¸€é”®"""
            return (
                record.get('ä¼šå‘˜è´¦å·', ''),
                record.get('æœŸå·', ''),
                record.get('ç©æ³•åˆ†ç±»', ''),
                record.get('è¿è§„ç±»å‹', ''),
                record.get('ä½ç½®', ''),
                record.get('çŸ›ç›¾ç±»å‹', '')
            )
        
        # å»é‡å¹¶æ’åº
        unique_records = []
        seen_keys = set()
        
        for record in records:
            record_key = get_record_key(record)
            if record_key not in seen_keys:
                seen_keys.add(record_key)
                unique_records.append(record)
        
        # æŒ‰æ’åºæƒé‡æ’åº
        unique_records.sort(key=lambda x: x.get('æ’åºæƒé‡', 0), reverse=True)
        
        # å¯¹äºå’Œå€¼çŸ›ç›¾ï¼Œç¡®ä¿å±•ç¤ºå¤šæ ·æ€§
        if unique_records and 'å’Œå€¼çŸ›ç›¾' in unique_records[0].get('è¿è§„ç±»å‹', ''):
            return self._ensure_variety_in_display(unique_records, max_records)
        else:
            return unique_records[:max_records]
    
    def _ensure_variety_in_display(self, records, max_records=5):
        """ç¡®ä¿å±•ç¤ºçš„è®°å½•åŒ…å«ä¸åŒç±»å‹çš„çŸ›ç›¾"""
        if len(records) <= max_records:
            return records
        
        # æŒ‰çŸ›ç›¾ç±»å‹åˆ†ç»„
        conflict_groups = {
            'å¤§å°': [],
            'å•åŒ': [], 
            'å¤§å°å•åŒ': [],
            'å…¶ä»–': []
        }
        
        for record in records:
            conflict_type = record.get('çŸ›ç›¾ç±»å‹', '')
            if 'å¤§å°' in conflict_type and 'å•åŒ' in conflict_type:
                conflict_groups['å¤§å°å•åŒ'].append(record)
            elif 'å¤§å°' in conflict_type:
                conflict_groups['å¤§å°'].append(record)
            elif 'å•åŒ' in conflict_type:
                conflict_groups['å•åŒ'].append(record)
            else:
                conflict_groups['å…¶ä»–'].append(record)
        
        # ä¼˜å…ˆä»æ¯ä¸ªç±»å‹ä¸­é€‰å–ä»£è¡¨æ€§è®°å½•
        selected_records = []
        
        # ç¬¬ä¸€è½®ï¼šä»æ¯ä¸ªéç©ºç±»å‹ä¸­å„å–1æ¡
        for group_name in ['å¤§å°å•åŒ', 'å¤§å°', 'å•åŒ', 'å…¶ä»–']:
            if conflict_groups[group_name] and len(selected_records) < max_records:
                selected_records.append(conflict_groups[group_name][0])
        
        # å¦‚æœè¿˜æ²¡å–æ»¡ï¼Œç»§ç»­æŒ‰åŸæœ‰é¡ºåºè¡¥å……
        if len(selected_records) < max_records:
            # è·å–å·²é€‰è®°å½•çš„ç´¢å¼•ï¼Œé¿å…é‡å¤
            selected_indices = set(records.index(r) for r in selected_records)
            
            for record in records:
                if records.index(record) not in selected_indices and len(selected_records) < max_records:
                    selected_records.append(record)
        
        return selected_records
    
    def create_summary_stats(self, account_results, df_clean):
        """åˆ›å»ºæ±‡æ€»ç»Ÿè®¡"""
        total_violations = sum(data['violation_count'] for data in account_results.values())
        
        summary = {
            'æ€»è®°å½•æ•°': len(df_clean),
            'æ€»ä¼šå‘˜æ•°': df_clean['ä¼šå‘˜è´¦å·'].nunique(),
            'è¿è§„è´¦æˆ·æ•°': len(account_results),
            'æ€»è¿è§„è®°å½•æ•°': total_violations,
            'æ€»è¿è§„æœŸæ•°': sum(len(data['periods']) for data in account_results.values()),
            'å½©ç§åˆ†å¸ƒ': df_clean['å½©ç§'].value_counts().to_dict(),
            'è¿è§„ç±»å‹ç»Ÿè®¡': defaultdict(int),
            'è´¦æˆ·è¿è§„ç»Ÿè®¡': []
        }
        
        for account, data in account_results.items():
            for violation_type in data['violation_types']:
                summary['è¿è§„ç±»å‹ç»Ÿè®¡'][violation_type] += len(data['violations_by_type'][violation_type])
            
            summary['è´¦æˆ·è¿è§„ç»Ÿè®¡'].append({
                'è´¦æˆ·': account,
                'è¿è§„æœŸæ•°': len(data['periods']),
                'è¿è§„æ¬¡æ•°': data['violation_count'],
                'è¿è§„ç±»å‹æ•°': len(data['violation_types']),
                'å½©ç§æ•°': len(data['lottery_types'])
            })
        
        summary['è´¦æˆ·è¿è§„ç»Ÿè®¡'] = sorted(summary['è´¦æˆ·è¿è§„ç»Ÿè®¡'], key=lambda x: x['è¿è§„æ¬¡æ•°'], reverse=True)
        
        return summary
    
    def display_summary(self, summary):
        """æ˜¾ç¤ºæ±‡æ€»ç»Ÿè®¡"""
        st.subheader("ğŸ“Š æ±‡æ€»ç»Ÿè®¡")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»è®°å½•æ•°", summary['æ€»è®°å½•æ•°'])
        with col2:
            st.metric("æ€»ä¼šå‘˜æ•°", summary['æ€»ä¼šå‘˜æ•°'])
        with col3:
            st.metric("è¿è§„è´¦æˆ·æ•°", summary['è¿è§„è´¦æˆ·æ•°'])
        with col4:
            st.metric("æ€»è¿è§„è®°å½•æ•°", summary['æ€»è¿è§„è®°å½•æ•°'])
        
        if summary['è¿è§„ç±»å‹ç»Ÿè®¡']:
            with st.expander("ğŸ“ˆ è¿è§„ç±»å‹åˆ†å¸ƒ", expanded=False):
                violation_df = pd.DataFrame({
                    'è¿è§„ç±»å‹': list(summary['è¿è§„ç±»å‹ç»Ÿè®¡'].keys()),
                    'æ•°é‡': list(summary['è¿è§„ç±»å‹ç»Ÿè®¡'].values())
                }).sort_values('æ•°é‡', ascending=False)
                
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.bar_chart(violation_df.set_index('è¿è§„ç±»å‹'))
                with col2:
                    st.dataframe(violation_df, hide_index=True)
        
        if summary['è´¦æˆ·è¿è§„ç»Ÿè®¡']:
            with st.expander("ğŸ† è´¦æˆ·è¿è§„æ’å", expanded=False):
                top_accounts = summary['è´¦æˆ·è¿è§„ç»Ÿè®¡'][:10]
                account_df = pd.DataFrame(top_accounts)
                st.dataframe(account_df, hide_index=True)
    
    def display_account_results(self, account_results):
        """æ˜¾ç¤ºè´¦æˆ·ç»“æœæœ¬"""
        if not account_results:
            st.info("ğŸ‰ æœªå‘ç°å¯ç–‘æŠ•æ³¨è¡Œä¸º")
            return
        
        st.subheader("ğŸ” è¿è§„è´¦æˆ·è¯¦æƒ…")
        
        sorted_accounts = sorted(account_results.items(), 
                               key=lambda x: x[1]['violation_count'], 
                               reverse=True)
        
        for account_index, (account, data) in enumerate(sorted_accounts, 1):
            # è½¬ä¹‰è´¦å·ä¸­çš„ä¸‹åˆ’çº¿
            account_display = account.replace('_', '\\_')
            
            with st.container():
                col1, col2, col3 = st.columns([3, 2, 1])
                
                with col1:
                    st.subheader(f"{account_index}. {account_display}")  # ä½¿ç”¨è½¬ä¹‰åçš„è´¦å·
                    # ä½¿ç”¨ data ä¸­çš„ lottery_types
                    lottery_types_list = list(data['lottery_types'])
                    st.write(f"**æ¶‰åŠå½©ç§:** {', '.join(lottery_types_list[:5])}{'...' if len(lottery_types_list) > 5 else ''}")

                with col2:
                    # ä½¿ç”¨ data ä¸­çš„ violation_types
                    violation_types_list = list(data['violation_types'])
                    violation_text = "ã€".join(violation_types_list[:5])
                    if len(violation_types_list) > 5:
                        violation_text += f" ç­‰{len(violation_types_list)}ç§"
                    st.write(f"**è¿è§„å†…å®¹:** {violation_text}")

                with col3:
                    # ä½¿ç”¨ data ä¸­çš„ periods å’Œ violation_count
                    st.write(f"**è¿è§„æœŸæ•°:** {len(data['periods'])}")
                    st.write(f"**è¿è§„æ¬¡æ•°:** {data['violation_count']}")
                
                # æŒ‰å½©ç§å’Œè¿è§„ç±»å‹åˆ†ç»„æ˜¾ç¤ºï¼Œé¿å…é‡å¤
                displayed_violations = set()
                
                for lottery in sorted(data['violations_by_lottery'].keys()):
                    lottery_violations = data['violations_by_lottery'][lottery]
                    
                    with st.expander(f"ğŸ¯ {lottery} (å…±{sum(len(v) for v in lottery_violations.values())}æ¬¡è¿è§„)", expanded=True):
                        
                        for violation_type in sorted(lottery_violations.keys()):
                            type_violations = lottery_violations[violation_type]
                            
                            # ä½¿ç”¨ä¼˜åŒ–æ˜¾ç¤ºæ–¹æ³•
                            representative_records = self.optimize_display_records(type_violations, max_records=5)
                            other_records_count = len(type_violations) - len(representative_records)
                            
                            if representative_records:
                                st.write(f"**{violation_type}** ({len(type_violations)}æ¬¡)")
                                
                                # å‡†å¤‡æ˜¾ç¤ºæ•°æ®
                                display_data = []
                                for record in representative_records:
                                    display_record = {
                                        'æœŸå·': record['æœŸå·'],
                                        'ç©æ³•åˆ†ç±»': record['ç©æ³•åˆ†ç±»'],
                                        'è¿è§„ç±»å‹': violation_type,
                                        'è¯¦ç»†ä¿¡æ¯': record.get('è¯¦ç»†ä¿¡æ¯', ''),
                                        'æŠ•æ³¨å†…å®¹': record.get('æŠ•æ³¨å†…å®¹', '')
                                    }
                                    # æ·»åŠ ä½ç½®ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                                    if record.get('ä½ç½®'):
                                        display_record['ä½ç½®'] = record['ä½ç½®']
                                    display_data.append(display_record)
                                
                                df_display = pd.DataFrame(display_data)
                                container = st.container()
                                with container:
                                    st.dataframe(
                                        df_display,
                                        use_container_width=True,
                                        hide_index=True,
                                        height=min(300, len(representative_records) * 35 + 38)
                                    )
                                
                                if other_records_count > 0:
                                    st.info(f"è¿˜æœ‰ {other_records_count} æ¡ç›¸å…³è®°å½•...")
                
                st.markdown("---")

# ==================== å¯¼å‡ºåŠŸèƒ½ ====================
class Exporter:
    """ç»“æœå¯¼å‡ºå™¨"""
    
    def prepare_export_data(self, account_summary):
        """å‡†å¤‡å¯¼å‡ºæ•°æ®"""
        export_data = []
        
        for account, summary in account_summary.items():
            for lottery, lottery_data in summary['violations_by_lottery'].items():
                for behavior_type, records in lottery_data.items():
                    for record in records:
                        export_record = {
                            'ä¼šå‘˜è´¦å·': account,
                            'å½©ç§': lottery,
                            'æœŸå·': record['æœŸå·'],
                            'ç©æ³•åˆ†ç±»': record['ç©æ³•åˆ†ç±»'],
                            'è¡Œä¸ºç±»å‹': behavior_type
                        }
                        
                        # æ·»åŠ çŸ›ç›¾ç±»å‹
                        if 'çŸ›ç›¾ç±»å‹' in record:
                            export_record['çŸ›ç›¾ç±»å‹'] = record['çŸ›ç›¾ç±»å‹']
                        
                        # æ·»åŠ æ•°é‡ä¿¡æ¯
                        self._add_quantity_info(export_record, record, behavior_type)
                        
                        export_data.append(export_record)
        
        return export_data
    
    def _add_quantity_info(self, export_record, record, behavior_type):
        """æ·»åŠ æ•°é‡ä¿¡æ¯åˆ°å¯¼å‡ºè®°å½•"""
        quantity_fields = {
            # å¿«ä¸‰ç›¸å…³
            'å’Œå€¼å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å’Œå€¼çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),  # å’Œå€¼çŸ›ç›¾åªæœ‰æŠ•æ³¨å†…å®¹
            'å’Œå€¼å¤§å°çŸ›ç›¾': ('çŸ›ç›¾å€¼', 'æŠ•æ³¨å†…å®¹'),  # å’Œå€¼å¤§å°çŸ›ç›¾æœ‰çŸ›ç›¾å€¼
            'ç‹¬èƒ†å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ä¸åŒå·å…¨åŒ…': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ä¸¤é¢çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),

            # PK10æ–°å¢
            'åä¸ªä½ç½®å…¨æŠ•': ('æŠ•æ³¨ä½ç½®æ•°', 'æŠ•æ³¨å†…å®¹'),
            
            # å…­åˆå½©ç›¸å…³
            'æ•°å­—ç±»å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç‰¹ç å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç 1-6å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç‰¹å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç”Ÿè‚–ç±»å¤šç ': ('ç”Ÿè‚–æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å¹³ç‰¹å¤šè‚–': ('ç”Ÿè‚–æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç‰¹è‚–å¤šè‚–': ('ç”Ÿè‚–æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ä¸€è‚–å¤šè‚–': ('ç”Ÿè‚–æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å°¾æ•°å¤šç ': ('å°¾æ•°æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å°¾æ•°å¤´å°¾å¤šç ': ('å°¾æ•°æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'ç‰¹å°¾å¤šå°¾': ('å°¾æ•°æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å…¨å°¾å¤šå°¾': ('å°¾æ•°æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'è¿è‚–å¤šè‚–': ('ç”Ÿè‚–æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'è¿å°¾å¤šå°¾': ('å°¾æ•°æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'åŒºé—´å¤šç»„': ('æŠ•æ³¨åŒºé—´æ•°', 'æŠ•æ³¨å†…å®¹'),
            'æ³¢è‰²ä¸‰ç»„': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),
            'è‰²æ³¢ä¸‰ç»„': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),
            # ä¿®æ”¹ä¸ºåªè®°å½•å…¨åŒ…æƒ…å†µ
            'è‰²æ³¢å…¨åŒ…': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),
            'åŠæ³¢å•åŒå…¨åŒ…': ('æŠ•æ³¨åŠæ³¢æ•°', 'æŠ•æ³¨å†…å®¹'),
            'åŠæ³¢å¤§å°å…¨åŒ…': ('æŠ•æ³¨åŠæ³¢æ•°', 'æŠ•æ³¨å†…å®¹'),
            'äº”è¡Œå¤šç»„': ('æŠ•æ³¨äº”è¡Œæ•°', 'æŠ•æ³¨å†…å®¹'),
            'ä¸¤é¢ç©æ³•çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç 1-6çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç‰¹çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),

            # åŠæ³¢ç›¸å…³
            'åŠæ³¢å…¨åŒ…': (None, 'æŠ•æ³¨å†…å®¹'),
            'åŠæ³¢å¤šç»„æŠ•æ³¨': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),       
            
             # ä¸‰è‰²å½©ç›¸å…³
            'è‰²æ³¢å…¨åŒ…': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),
            'è‰²æ³¢çº¢ç»¿æŠ•æ³¨': ('æŠ•æ³¨æ³¢è‰²æ•°', 'æŠ•æ³¨å†…å®¹'),

             # 3Dç³»åˆ—ç›¸å…³
            'ä¸¤é¢çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'å®šä½èƒ†å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),

             # æ—¶æ—¶å½©ç›¸å…³
            'æ–—ç‰›å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å®šä½èƒ†å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            
            # PK10ç›¸å…³
            'è¶…ç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å† äºšå’Œå¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å‰ä¸€å¤šç ': ('å·ç æ•°é‡', 'æŠ•æ³¨å†…å®¹'),
            'å† äºšå’ŒçŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'ä¸¤é¢çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'ç‹¬ç«‹ç©æ³•çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'é¾™è™çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'æ€»å’ŒçŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'è‰²æ³¢çŸ›ç›¾æŠ•æ³¨': (None, 'æŠ•æ³¨å†…å®¹'),
            'ä¸¤é¢ç©æ³•çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç 1-6çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
            'æ­£ç‰¹çŸ›ç›¾': (None, 'æŠ•æ³¨å†…å®¹'),
        }
        
        if behavior_type in quantity_fields:
            count_field, content_field = quantity_fields[behavior_type]
            if count_field and count_field in record:
                export_record[count_field] = record[count_field]
            
            if content_field and record.get(content_field):
                export_record[content_field] = str(record[content_field])
            
            # æ·»åŠ ä½ç½®ä¿¡æ¯ï¼ˆ3Dç³»åˆ—ä¸“ç”¨ï¼‰
            if record.get('ä½ç½®'):
                export_record['ä½ç½®'] = record['ä½ç½®']
    
    def export_to_excel(self, account_summary, filename_prefix="å½©ç¥¨åˆ†æç»“æœ"):
        """å¯¼å‡ºåˆ†æç»“æœåˆ°Excelæ–‡ä»¶"""
        try:
            export_data = self.prepare_export_data(account_summary)
            
            if not export_data:
                st.warning("æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®")
                return
            
            # åˆ›å»ºDataFrame
            df_export = pd.DataFrame(export_data)
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
            output_filename = f"{filename_prefix}_{timestamp}.xlsx"
            
            with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:
                # å†™å…¥è¯¦ç»†æ•°æ®
                df_export.to_excel(writer, sheet_name='è¯¦ç»†åˆ†æç»“æœ', index=False)
                
                # åˆ›å»ºç»Ÿè®¡å·¥ä½œè¡¨
                self._create_summary_sheets(writer, account_summary, export_data)
            
            st.success(f"âœ… åˆ†æç»“æœå·²æˆåŠŸå¯¼å‡ºåˆ°: {output_filename}")
            st.info(f"ğŸ“Š å¯¼å‡ºå†…å®¹åŒ…å« {len(export_data)} æ¡è®°å½•")
            
            # æä¾›ä¸‹è½½
            with open(output_filename, "rb") as file:
                btn = st.download_button(
                    label="ğŸ“¥ ä¸‹è½½åˆ†æç»“æœ",
                    data=file,
                    file_name=output_filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            
        except Exception as e:
            st.error(f"âŒ å¯¼å‡ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
    
    def _create_summary_sheets(self, writer, account_summary, export_data):
        """åˆ›å»ºç»Ÿè®¡å·¥ä½œè¡¨"""
        # è´¦æˆ·ç»Ÿè®¡
        account_stats = []
        for account, summary in account_summary.items():
            account_stats.append({
                'ä¼šå‘˜è´¦å·': account,
                'æ€»å¯ç–‘æœŸå·æ•°': len(summary['periods']),
                'æ¶‰åŠå½©ç§æ•°': len(summary['lottery_types']),
                'è¡Œä¸ºç±»å‹æ•°': len(summary['violation_types'])
            })
        
        if account_stats:
            df_account_stats = pd.DataFrame(account_stats)
            df_account_stats.to_excel(writer, sheet_name='è´¦æˆ·ç»Ÿè®¡', index=False)
        
        # è¡Œä¸ºç±»å‹ç»Ÿè®¡
        if export_data:
            behavior_stats = pd.DataFrame(export_data)['è¡Œä¸ºç±»å‹'].value_counts().reset_index()
            behavior_stats.columns = ['è¡Œä¸ºç±»å‹', 'è®°å½•æ•°']
            behavior_stats.to_excel(writer, sheet_name='è¡Œä¸ºç±»å‹ç»Ÿè®¡', index=False)
        
        # å½©ç§ç»Ÿè®¡
        if export_data:
            lottery_stats = pd.DataFrame(export_data)['å½©ç§'].value_counts().reset_index()
            lottery_stats.columns = ['å½©ç§', 'è®°å½•æ•°']
            lottery_stats.to_excel(writer, sheet_name='å½©ç§ç»Ÿè®¡', index=False)

# ==================== Streamlitç•Œé¢ ====================
def main():
    st.title("ğŸ¯ æ™ºèƒ½å½©ç¥¨åˆ†ææ£€æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    
    st.sidebar.title("ç³»ç»Ÿé…ç½®")
    
    uploaded_file = st.sidebar.file_uploader(
        "ä¸Šä¼ Excelæ–‡ä»¶", 
        type=['xlsx', 'xls'],
        help="è¯·ä¸Šä¼ åŒ…å«å½©ç¥¨æŠ•æ³¨æ•°æ®çš„Excelæ–‡ä»¶"
    )
    
    st.sidebar.subheader("æ£€æµ‹é˜ˆå€¼é…ç½®")
    
    with st.sidebar.expander("PKæ‹¾ç³»åˆ—é˜ˆå€¼"):
        pk10_multi = st.slider("è¶…ç é˜ˆå€¼", 5, 15, THRESHOLD_CONFIG['PK10']['multi_number'])
        pk10_gyh = st.slider("å† äºšå’Œå¤šç é˜ˆå€¼", 8, 20, THRESHOLD_CONFIG['PK10']['gyh_multi_number'])
        THRESHOLD_CONFIG['PK10']['multi_number'] = pk10_multi
        THRESHOLD_CONFIG['PK10']['gyh_multi_number'] = pk10_gyh
    
    with st.sidebar.expander("æ—¶æ—¶å½©ç³»åˆ—é˜ˆå€¼"):
        ssc_dingwei = st.slider("å®šä½èƒ†å¤šç é˜ˆå€¼", 5, 15, THRESHOLD_CONFIG['SSC']['dingwei_multi'])
        ssc_douniu = st.slider("æ–—ç‰›å¤šç é˜ˆå€¼", 5, 15, THRESHOLD_CONFIG['SSC']['douniu_multi'])
        THRESHOLD_CONFIG['SSC']['dingwei_multi'] = ssc_dingwei
        THRESHOLD_CONFIG['SSC']['douniu_multi'] = ssc_douniu
    
    with st.sidebar.expander("å…­åˆå½©ç³»åˆ—é˜ˆå€¼"):
        lhc_numbers = st.slider("æ•°å­—ç±»å¤šç é˜ˆå€¼", 20, 50, THRESHOLD_CONFIG['LHC']['number_play'])
        lhc_zodiacs = st.slider("ç”Ÿè‚–ç±»å¤šç é˜ˆå€¼", 5, 15, THRESHOLD_CONFIG['LHC']['zodiac_play'])
        lhc_tails = st.slider("å°¾æ•°å¤šç é˜ˆå€¼", 5, 15, THRESHOLD_CONFIG['LHC']['tail_play'])
        THRESHOLD_CONFIG['LHC']['number_play'] = lhc_numbers
        THRESHOLD_CONFIG['LHC']['zodiac_play'] = lhc_zodiacs
        THRESHOLD_CONFIG['LHC']['tail_play'] = lhc_tails
    
    with st.sidebar.expander("å¿«ä¸‰ç³»åˆ—é˜ˆå€¼"):
        k3_hezhi = st.slider("å’Œå€¼å¤šç é˜ˆå€¼", 5, 20, THRESHOLD_CONFIG['K3']['hezhi_multi_number'])
        k3_dudan_threshold = st.slider("ç‹¬èƒ†å¤šç é˜ˆå€¼", 2, 6, 5)
        THRESHOLD_CONFIG['K3']['hezhi_multi_number'] = k3_hezhi
        THRESHOLD_CONFIG['K3']['dudan_multi_number'] = k3_dudan_threshold
    
    with st.sidebar.expander("ä¸‰è‰²å½©ç³»åˆ—é˜ˆå€¼"):
        three_color_zhengma = st.slider("æ­£ç å¤šç é˜ˆå€¼", 5, 15, THRESHOLD_CONFIG['THREE_COLOR']['zhengma_multi'])
        THRESHOLD_CONFIG['THREE_COLOR']['zhengma_multi'] = three_color_zhengma

    with st.sidebar.expander("3Dç³»åˆ—é˜ˆå€¼"):
        three_d_dingwei = st.slider("3Då®šä½èƒ†å¤šç é˜ˆå€¼", 5, 10, THRESHOLD_CONFIG['3D']['dingwei_multi'])
        THRESHOLD_CONFIG['3D']['dingwei_multi'] = three_d_dingwei
    
    if uploaded_file is not None:
        try:
            with st.spinner('æ­£åœ¨å¤„ç†æ•°æ®...'):
                # åˆå§‹åŒ–ç»„ä»¶
                processor = DataProcessor()
                analyzer = UnifiedAnalyzer()
                result_processor = ResultProcessor()
                exporter = Exporter()
                
                # æ•°æ®æ¸…æ´—
                df_clean = processor.clean_data(uploaded_file)
                
                if df_clean is not None and len(df_clean) > 0:
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("æ€»è®°å½•æ•°", len(df_clean))
                    with col2:
                        st.metric("å”¯ä¸€ä¼šå‘˜æ•°", df_clean['ä¼šå‘˜è´¦å·'].nunique())
                    with col3:
                        st.metric("å½©ç§æ•°é‡", df_clean['å½©ç§'].nunique())
                    
                    # ç»Ÿä¸€ç©æ³•åˆ†ç±»
                    play_normalizer = PlayCategoryNormalizer()
                    if 'ç©æ³•' in df_clean.columns:
                        df_clean['ç©æ³•åˆ†ç±»'] = df_clean['ç©æ³•'].apply(play_normalizer.normalize_categ
                    
                    # åˆ†ææŠ•æ³¨æ¨¡å¼ - ä½¿ç”¨æ–°çš„ç»Ÿä¸€åˆ†æå™¨
                    all_results = analyzer.analyze_all_patterns(df_clean)
                    # ä½¿ç”¨è¿›åº¦æ¡
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    all_results = {}
                    # æ˜ç¡®å®šä¹‰ lottery_types å˜é‡ - æ·»åŠ 3Dç³»åˆ—
                    lottery_types = ['PKæ‹¾èµ›è½¦', 'æ—¶æ—¶å½©', 'å…­åˆå½©', 'å¿«ä¸‰', 'ä¸‰è‰²å½©', '3Dç³»åˆ—']
                    
                    for i, lottery_type in enumerate(lottery_types):
                        status_text.text(f"æ­£åœ¨åˆ†æ {lottery_type}...")
                        
                        if lottery_type == 'PKæ‹¾èµ›è½¦':
                            all_results[lottery_type] = analyzer.analyze_pk10_patterns(df_normalized)
                        elif lottery_type == 'æ—¶æ—¶å½©':
                            all_results[lottery_type] = analyzer.analyze_ssc_patterns(df_normalized)
                        elif lottery_type == 'å…­åˆå½©':
                            all_results[lottery_type] = analyzer.analyze_lhc_patterns(df_normalized)
                        elif lottery_type == 'å¿«ä¸‰':
                            all_results[lottery_type] = analyzer.analyze_k3_patterns(df_normalized)
                        elif lottery_type == 'ä¸‰è‰²å½©':
                            all_results[lottery_type] = analyzer.analyze_three_color_patterns(df_normalized)
                        # æ·»åŠ 3Dç³»åˆ—åˆ†æè°ƒç”¨
                        elif lottery_type == '3Dç³»åˆ—':
                            all_results[lottery_type] = analyzer.analyze_3d_patterns(df_normalized)
                        
                        progress_bar.progress((i + 1) / len(lottery_types))
                    
                    status_text.text("åˆ†æå®Œæˆï¼")
                    
                    # ç»Ÿè®¡ç»“æœ
                    total_findings = 0
                    for lottery_type, results in all_results.items():
                        type_count = sum(len(records) for records in results.values())
                        total_findings += type_count
                    
                    with col4:
                        st.metric("å¯ç–‘è®°å½•æ•°", total_findings)
                    
                    with st.expander("ğŸ“Š æ•°æ®é¢„è§ˆ", expanded=False):
                        st.dataframe(df_clean.head(10))
                    
                    if total_findings == 0:
                        st.success("ğŸ‰ æœªå‘ç°å¯ç–‘æŠ•æ³¨è¡Œä¸º")
                    else:
                        # å¤„ç†å¹¶æ˜¾ç¤ºç»“æœ
                        account_results = result_processor.organize_results_by_account(all_results)
                        
                        summary_stats = result_processor.create_summary_stats(account_results, df_clean)
                        result_processor.display_summary(summary_stats)
                        
                        result_processor.display_account_results(account_results)
                        
                        # å¯¼å‡ºç»“æœ
                        st.subheader("ğŸ“¥ ç»“æœå¯¼å‡º")
                        exporter.export_to_excel(account_results, "æ™ºèƒ½å½©ç¥¨åˆ†æ")
                
                else:
                    st.error("âŒ æ•°æ®æ¸…æ´—åæ— æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
        
        except Exception as e:
            st.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
    
    else:
        st.markdown("""
        ## ğŸ“‹ ä½¿ç”¨è¯´æ˜
        
        1. **ä¸Šä¼ æ–‡ä»¶**: åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ Excelæ ¼å¼çš„å½©ç¥¨æŠ•æ³¨æ•°æ®æ–‡ä»¶
        2. **é…ç½®é˜ˆå€¼**: æ ¹æ®éœ€è¦è°ƒæ•´å„ç±»å½©ç¥¨çš„æ£€æµ‹é˜ˆå€¼
        3. **æŸ¥çœ‹ç»“æœ**: ç³»ç»Ÿå°†è‡ªåŠ¨åˆ†æå¹¶æ˜¾ç¤ºå¯ç–‘æŠ•æ³¨è¡Œä¸º
        4. **å¯¼å‡ºç»“æœ**: ä¸‹è½½è¯¦ç»†çš„æ£€æµ‹æŠ¥å‘Š
        
        ### ğŸ¯ ç³»ç»Ÿç‰¹è‰²
        
        **ğŸ” å…¨é¢æ£€æµ‹èƒ½åŠ›**
        - âœ… PKæ‹¾/èµ›è½¦ç³»åˆ—ï¼šè¶…ç ã€å† äºšå’ŒçŸ›ç›¾ã€ä¸¤é¢çŸ›ç›¾ã€é¾™è™çŸ›ç›¾
        - âœ… æ—¶æ—¶å½©ç³»åˆ—ï¼šå®šä½èƒ†å¤šç ã€æ–—ç‰›å¤šç ã€ä¸¤é¢çŸ›ç›¾ã€æ€»å’ŒçŸ›ç›¾  
        - âœ… å…­åˆå½©ç³»åˆ—ï¼šç‰¹ç /æ­£ç å¤šç ã€ç”Ÿè‚–å¤šå·ç ã€å°¾æ•°å¤šç ã€æ³¢è‰²äº”è¡ŒçŸ›ç›¾
        - âœ… å¿«ä¸‰ç³»åˆ—ï¼šå’Œå€¼å¤šç ã€å’Œå€¼çŸ›ç›¾ã€å’Œå€¼å¤§å°çŸ›ç›¾ã€ç‹¬èƒ†å¤šç ã€ä¸åŒå·å…¨åŒ…ã€ä¸¤é¢çŸ›ç›¾
        - âœ… ä¸‰è‰²å½©ç³»åˆ—ï¼šæ­£ç å¤šç ã€ä¸¤é¢çŸ›ç›¾ã€è‰²æ³¢çŸ›ç›¾
        
        **ğŸš€ æŠ€æœ¯ä¼˜åŠ¿**
        - ğŸ“Š å®Œæ•´çš„å°¾æ•°æ£€æµ‹
        - âš¡ ç¼“å­˜ä¼˜åŒ–çš„å·ç æå–ç®—æ³•
        - ğŸ¯ æ™ºèƒ½çš„ç©æ³•åˆ†ç±»æ˜ å°„
        - ğŸ“ˆ è¯¦ç»†çš„æ•°æ®è´¨é‡éªŒè¯
        - ğŸ”„ å®æ—¶è¿›åº¦æ˜¾ç¤ºå’Œæ€§èƒ½ç›‘æ§
        
        **ğŸ’¡ ç”¨æˆ·ä½“éªŒ**
        - ğŸ¨ ç°ä»£åŒ–çš„Streamlitç•Œé¢
        - âš™ï¸ å®æ—¶å¯è°ƒçš„æ£€æµ‹é˜ˆå€¼
        - ğŸ“± å“åº”å¼å¸ƒå±€è®¾è®¡
        - ğŸ“¥ ä¸€é”®å¯¼å‡ºå®Œæ•´æŠ¥å‘Š
        
        ### ğŸ“ æ”¯æŒçš„æ•°æ®æ ¼å¼
        
        ç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«ä»¥ä¸‹åˆ—åå˜ä½“ï¼š
        
        - **ä¼šå‘˜è´¦å·**: ä¼šå‘˜è´¦å·ã€ä¼šå‘˜è´¦æˆ·ã€è´¦å·ã€è´¦æˆ·ã€ç”¨æˆ·è´¦å·ã€ç©å®¶è´¦å·ã€ç”¨æˆ·IDã€ç©å®¶ID
        - **å½©ç§**: å½©ç§ã€å½©ç¥ã€å½©ç¥¨ç§ç±»ã€æ¸¸æˆç±»å‹ã€å½©ç¥¨ç±»å‹ã€æ¸¸æˆå½©ç§ã€å½©ç¥¨åç§°
        - **æœŸå·**: æœŸå·ã€æœŸæ•°ã€æœŸæ¬¡ã€æœŸã€å¥–æœŸã€æœŸå·ä¿¡æ¯ã€æœŸå·ç¼–å·
        - **ç©æ³•**: ç©æ³•ã€ç©æ³•åˆ†ç±»ã€æŠ•æ³¨ç±»å‹ã€ç±»å‹ã€æŠ•æ³¨ç©æ³•ã€ç©æ³•ç±»å‹ã€åˆ†ç±»
        - **å†…å®¹**: å†…å®¹ã€æŠ•æ³¨å†…å®¹ã€ä¸‹æ³¨å†…å®¹ã€æ³¨å•å†…å®¹ã€æŠ•æ³¨å·ç ã€å·ç å†…å®¹ã€æŠ•æ³¨ä¿¡æ¯
        - **é‡‘é¢**: é‡‘é¢ã€ä¸‹æ³¨æ€»é¢ã€æŠ•æ³¨é‡‘é¢ã€æ€»é¢ã€ä¸‹æ³¨é‡‘é¢ã€æŠ•æ³¨é¢ã€é‡‘é¢æ•°å€¼
        
        ### ğŸ² æ”¯æŒçš„å½©ç§
        
        **PKæ‹¾/èµ›è½¦ç³»åˆ—**
        - åˆ†åˆ†PKæ‹¾ã€ä¸‰åˆ†PKæ‹¾ã€äº”åˆ†PKæ‹¾ã€æ–°å¹¸è¿é£è‰‡ã€æ¾³æ´²å¹¸è¿10
        - ä¸€åˆ†PK10ã€å®¾æœPK10ã€æé€Ÿé£è‰‡ã€æ¾³æ´²é£è‰‡ã€å¹¸è¿èµ›è½¦
        - åˆ†åˆ†èµ›è½¦ã€åŒ—äº¬PK10ã€æ—§åŒ—äº¬PK10ã€æé€Ÿèµ›è½¦ã€å¹¸è¿èµ›è»Šã€åŒ—äº¬èµ›è½¦ã€æé€ŸPK10ã€å¹¸è¿PK10ã€èµ›è½¦ã€èµ›è»Š
        
        **æ—¶æ—¶å½©ç³»åˆ—**
        - åˆ†åˆ†æ—¶æ—¶å½©ã€ä¸‰åˆ†æ—¶æ—¶å½©ã€äº”åˆ†æ—¶æ—¶å½©ã€å®¾æœæ—¶æ—¶å½©
        - 1åˆ†æ—¶æ—¶å½©ã€3åˆ†æ—¶æ—¶å½©ã€5åˆ†æ—¶æ—¶å½©ã€æ—§é‡åº†æ—¶æ—¶å½©
        - å¹¸è¿æ—¶æ—¶å½©ã€è…¾è®¯åˆ†åˆ†å½©ã€æ–°ç–†æ—¶æ—¶å½©ã€å¤©æ´¥æ—¶æ—¶å½©ã€é‡åº†æ—¶æ—¶å½©ã€ä¸Šæµ·æ—¶æ—¶å½©ã€å¹¿ä¸œæ—¶æ—¶å½©ã€åˆ†åˆ†å½©ã€æ—¶æ—¶å½©ã€æ™‚æ™‚å½©
        
        **å…­åˆå½©ç³»åˆ—**
        - æ–°æ¾³é—¨å…­åˆå½©ã€æ¾³é—¨å…­åˆå½©ã€é¦™æ¸¯å…­åˆå½©ã€ä¸€åˆ†å…­åˆå½©
        - äº”åˆ†å…­åˆå½©ã€ä¸‰åˆ†å…­åˆå½©ã€é¦™æ¸¯â‘¥åˆå½©ã€åˆ†åˆ†å…­åˆå½©
        - å¿«ä¹6åˆå½©ã€æ¸¯â‘¥åˆå½©ã€å°æ¹¾å¤§ä¹é€ã€å…­åˆã€lhcã€å…­åˆå½©ã€â‘¥åˆã€6åˆ
        
        **å¿«ä¸‰ç³»åˆ—**
        - åˆ†åˆ†å¿«ä¸‰ã€ä¸‰åˆ†å¿«3ã€äº”åˆ†å¿«3ã€æ¾³æ´²å¿«ä¸‰ã€å®¾æœå¿«ä¸‰
        - 1åˆ†å¿«ä¸‰ã€3åˆ†å¿«ä¸‰ã€5åˆ†å¿«ä¸‰ã€10åˆ†å¿«ä¸‰ã€åŠ å·å¿«ä¸‰
        - å¹¸è¿å¿«ä¸‰ã€å¤§å‘å¿«ä¸‰ã€å¿«ä¸‰ã€å¿«3ã€k3ã€kä¸‰

        **3Dç³»åˆ—**
        - æ’åˆ—ä¸‰ã€æ’åˆ—3ã€å¹¸è¿æ’åˆ—3ã€ä¸€åˆ†æ’åˆ—3ã€äºŒåˆ†æ’åˆ—3ã€ä¸‰åˆ†æ’åˆ—3
        - äº”åˆ†æ’åˆ—3ã€ååˆ†æ’åˆ—3ã€å¤§å‘æ’åˆ—3ã€å¥½è¿æ’åˆ—3ã€ç¦å½©3Dã€æé€Ÿ3D
        - æé€Ÿæ’åˆ—3ã€å¹¸è¿3Dã€ä¸€åˆ†3Dã€äºŒåˆ†3Dã€ä¸‰åˆ†3Dã€äº”åˆ†3Dã€ååˆ†3Dã€å¤§å‘3Dã€å¥½è¿3D
        
        **ä¸‰è‰²å½©ç³»åˆ—**
        - ä¸€åˆ†ä¸‰è‰²å½©ã€30ç§’ä¸‰è‰²å½©ã€äº”åˆ†ä¸‰è‰²å½©ã€ä¸‰åˆ†ä¸‰è‰²å½©ã€ä¸‰è‰²ã€ä¸‰è‰²å½©ã€ä¸‰è‰²çƒ
        
        ---
        
        **æ³¨æ„**: è¯·ç¡®ä¿ä¸Šä¼ çš„Excelæ–‡ä»¶åŒ…å«å¿…è¦çš„åˆ—ä¿¡æ¯ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«å¸¸è§çš„åˆ—åå˜ä½“ã€‚
        
        """)

# ç¡®ä¿ä¸»å‡½æ•°è¢«è°ƒç”¨
if __name__ == "__main__":
    main()
